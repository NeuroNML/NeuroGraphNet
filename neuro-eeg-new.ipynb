{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97b998b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric.loader import DataLoader as GeoDataLoader\n",
    "from torch.utils.data import Subset, WeightedRandomSampler\n",
    "# from torch.utils.data import DataLoader\n",
    "from src.utils.seeder import seed_everything\n",
    "\n",
    "# set seaborn theme\n",
    "sns.set_theme()\n",
    "\n",
    "# create useful constants\n",
    "RANDOM_SEED = 42\n",
    "IS_SCITAS = True # set to True if running on SCITAS cluster\n",
    "LOCAL_DATA_ROOT = Path(\"./data\")\n",
    "DATA_ROOT = Path(\"/home/ogut/data\") if IS_SCITAS else LOCAL_DATA_ROOT\n",
    "CHECKPOINT_ROOT = Path(\"./.checkpoints\")\n",
    "SUBMISSION_ROOT = Path(\"./.submissions\")\n",
    "\n",
    "# create directories if they do not exist\n",
    "CHECKPOINT_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "SUBMISSION_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# set dataset root\n",
    "seed_everything(RANDOM_SEED)\n",
    "\n",
    "# setup torch device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78d28586",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sessions: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 177/177 [00:09<00:00, 19.18it/s]\n",
      "Processing sessions: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:00<00:00, 306.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dataset shapes:\n",
      "X_train: (12993, 95)\n",
      "y_train: (12993,)\n",
      "X_test: (3614, 95)\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "# execute feature extraction script\n",
    "try:\n",
    "    process = subprocess.Popen([\"python3\", \"scripts/feature_extractor.py\"])\n",
    "    process.wait()\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Process interrupted, terminating...\")\n",
    "    process.terminate()\n",
    "    process.wait()\n",
    "except Exception as e:\n",
    "    print(f\"Error occurred: {e}\")\n",
    "    if 'process' in locals():\n",
    "        process.terminate()\n",
    "        process.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45999291",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = DATA_ROOT / \"train\"\n",
    "train_dir_metadata = train_dir / \"segments.parquet\"\n",
    "train_dataset_dir = LOCAL_DATA_ROOT / \"graph_dataset_train\"\n",
    "spatial_distance_file = LOCAL_DATA_ROOT / \"distances_3d.csv\"\n",
    "extracted_features_dir = LOCAL_DATA_ROOT / \"extracted_features\"\n",
    "embeddings_dir =  LOCAL_DATA_ROOT / \"embeddings\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "638b7e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd45b398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:39:06] Processing sessions\n",
      "Length of train_dataset: 12993\n",
      " Eliminated IDs:[]\n"
     ]
    }
   ],
   "source": [
    "from src.data.dataset_graph import GraphEEGDataset\n",
    "from src.utils.index import ensure_eeg_multiindex \n",
    "\n",
    "# ----------------- Prepare training data -----------------#\n",
    "clips_tr = pd.read_parquet(train_dir_metadata)\n",
    "\n",
    "# Ensure multiindex is correct\n",
    "clips_tr = ensure_eeg_multiindex(clips_tr)\n",
    "\n",
    "clips_tr = clips_tr[~clips_tr.label.isna()].reset_index()  # Filter NaN values out of clips_tr\n",
    "\n",
    "# dataset settings\n",
    "batch_size = 512\n",
    "selected_features = []\n",
    "embeddings = []\n",
    "edge_strategy = \"spatial\"\n",
    "correlation_threshold = 0.5\n",
    "top_k = None\n",
    "low_bandpass_frequency = 0.5\n",
    "high_bandpass_frequency = 50\n",
    "\n",
    "# additional settings\n",
    "oversampling_power = 1.0\n",
    "\n",
    "# -------------- Dataset definition -------------- #\n",
    "dataset = GraphEEGDataset(\n",
    "    root=train_dataset_dir,\n",
    "    clips=clips_tr,\n",
    "    signal_folder=train_dir,\n",
    "    extracted_features_dir=extracted_features_dir,\n",
    "    selected_features_train=selected_features,\n",
    "    embeddings_dir=embeddings_dir,\n",
    "    embeddings_train=embeddings,\n",
    "    edge_strategy=edge_strategy,\n",
    "    spatial_distance_file=(\n",
    "        spatial_distance_file if edge_strategy == \"spatial\" else None\n",
    "    ),\n",
    "    top_k=top_k,\n",
    "    correlation_threshold=correlation_threshold,\n",
    "    force_reprocess=True,\n",
    "    bandpass_frequencies=(\n",
    "        low_bandpass_frequency,\n",
    "        high_bandpass_frequency,\n",
    "    ),\n",
    "    segment_length=3000,\n",
    "    apply_filtering=True,\n",
    "    apply_rereferencing=False,\n",
    "    apply_normalization=False,\n",
    "    sampling_rate=250,\n",
    ")\n",
    "\n",
    "# Check the length of the dataset\n",
    "print(f\"Length of train_dataset: {len(dataset)}\")\n",
    "print(f' Eliminated IDs:{dataset.ids_to_eliminate}')\n",
    "\n",
    "# Eliminate ids that did not have electrodes above correlation threshols\n",
    "clips_tr = clips_tr[~clips_tr.index.isin(dataset.ids_to_eliminate)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f368519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels before Kfold\n",
      "[1 1 1 ... 1 1 0]\n",
      "[09:45:28] Train labels: 0 -> 8389, 1 -> 2093\n",
      "[09:45:28] Val labels:   0 -> 2087, 1 -> 424\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "from src.utils.general_funcs import labels_stats\n",
    "\n",
    "cv = GroupKFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
    "groups = clips_tr.patient.values\n",
    "y = clips_tr[\"label\"].values\n",
    "X = np.zeros(len(y))  # Dummy X (not used); just placeholder for the Kfold\n",
    "train_ids, val_ids = next(cv.split(X, y, groups=groups))  # Just select one split\n",
    "print('Labels before Kfold', flush=True)\n",
    "print(y,flush=True)\n",
    "\n",
    "# Print stats for class 0 and 1\n",
    "labels_stats(y, train_ids, val_ids)\n",
    "\n",
    "# 2. From dataset generate train and val datasets\n",
    "train_dataset = Subset(dataset, train_ids)\n",
    "val_dataset = Subset(dataset, val_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6943f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batches: 21\n",
      "Val batches: 5\n"
     ]
    }
   ],
   "source": [
    "# 3. Compute sample weights for oversampling\n",
    "train_labels = [clips_tr.iloc[i][\"label\"] for i in train_ids]\n",
    "class_counts = np.bincount(train_labels)\n",
    "class_weights = (1. / class_counts) ** oversampling_power # Higher weights for not frequent classes\n",
    "sample_weights = [class_weights[label] for label in train_labels] # Assign weight to each sample based on its class\n",
    "\n",
    "# 4. Define sampler\n",
    "sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True) # Still train on N samples per epoch, but instead of sampling uniformly takes more from minority class\n",
    "\n",
    "# Define dataloaders\n",
    "train_loader = GeoDataLoader(train_dataset, batch_size=batch_size, sampler=sampler, shuffle=False)\n",
    "val_loader = GeoDataLoader(val_dataset, batch_size=batch_size)\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Val batches: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1427c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 2 GPUs for this combination.\n",
      "pos_weight:tensor([1.5000], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "from src.layers.gat import EEGGAT\n",
    "\n",
    "SAVE_PATH = CHECKPOINT_ROOT / \"lstm_gnn_best_model.pt\"\n",
    "SUBMISSION_PATH = SUBMISSION_ROOT / \"lstm_gnn_submission.csv\"\n",
    "\n",
    "config = {\n",
    "    \"learning_rate\": 3e-4,\n",
    "    \"weight_decay\": 1e-5,\n",
    "    \"patience\": 5,\n",
    "    \"epochs\": 100,\n",
    "}\n",
    "\n",
    "# build model with current parameters\n",
    "model = EEGGAT(\n",
    "    in_channels = 3000,\n",
    ")\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"Using {torch.cuda.device_count()} GPUs for this combination.\")\n",
    "    model = nn.DataParallel(model)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()  # Assuming this remains constant\n",
    "optimizer = optim.Adam(model.parameters(), lr=config[\"learning_rate\"], weight_decay=config[\"weight_decay\"])\n",
    "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=config[\"patience\"], factor=0.5)\n",
    "\n",
    "adjusted_pos_weight = torch.tensor([1.5], dtype=torch.float32).to(device)\n",
    "print(f'pos_weight:{adjusted_pos_weight}')\n",
    "loss_fn = nn.BCEWithLogitsLoss(pos_weight=adjusted_pos_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41a924c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modules to reload:\n",
      "\n",
      "\n",
      "Modules to skip:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to True."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">clean-haze-2</strong> at: <a href='https://wandb.ai/lucadibello-epfl/neuro-graph-net/runs/6q66zxnx' target=\"_blank\">https://wandb.ai/lucadibello-epfl/neuro-graph-net/runs/6q66zxnx</a><br> View project at: <a href='https://wandb.ai/lucadibello-epfl/neuro-graph-net' target=\"_blank\">https://wandb.ai/lucadibello-epfl/neuro-graph-net</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250605_094939-6q66zxnx/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.20.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ldibello/NeuroGraphNet/wandb/run-20250605_095214-ch6z9y0d</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/lucadibello-epfl/neuro-graph-net/runs/ch6z9y0d' target=\"_blank\">major-water-3</a></strong> to <a href='https://wandb.ai/lucadibello-epfl/neuro-graph-net' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/lucadibello-epfl/neuro-graph-net' target=\"_blank\">https://wandb.ai/lucadibello-epfl/neuro-graph-net</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/lucadibello-epfl/neuro-graph-net/runs/ch6z9y0d' target=\"_blank\">https://wandb.ai/lucadibello-epfl/neuro-graph-net/runs/ch6z9y0d</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”— Wandb initialized: major-water-3\n",
      "ðŸ’ª Starting training from epoch 1 to 100...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   1%|â–Š                                                                                  | 1/100 [00:11<?, ?it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Caught IndexError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/home/ldibello/venvs/neuro/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py\", line 96, in _worker\n    output = module(*input, **kwargs)\n  File \"/home/ldibello/venvs/neuro/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/ldibello/venvs/neuro/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/ldibello/NeuroGraphNet/src/layers/gat.py\", line 20, in forward\n    x = self.gat1(x, edge_index)\n  File \"/home/ldibello/venvs/neuro/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/ldibello/venvs/neuro/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/ldibello/venvs/neuro/lib/python3.10/site-packages/torch_geometric/nn/conv/gat_conv.py\", line 347, in forward\n    edge_index, edge_attr = remove_self_loops(\n  File \"/home/ldibello/venvs/neuro/lib/python3.10/site-packages/torch_geometric/utils/loop.py\", line 112, in remove_self_loops\n    mask = edge_index[0] != edge_index[1]\nIndexError: index 1 is out of bounds for dimension 0 with size 1\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maimport\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrain\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_model\n\u001b[0;32m----> 4\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mepochs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpatience\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSAVE_PATH\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/NeuroGraphNet/src/utils/train.py:310\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, criterion, optimizer, device, save_path, scheduler, monitor, patience, num_epochs, grad_clip, overwrite, use_gnn, use_oversampling, wandb_config, wandb_project, wandb_run_name, log_wandb)\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mhasattr\u001b[39m(curr_batch, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(curr_batch, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_index\u001b[39m\u001b[38;5;124m'\u001b[39m)):\n\u001b[1;32m    309\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor GNN mode, batch_data must have \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_index\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 310\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurr_batch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mcurr_batch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mcurr_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m: \u001b[38;5;66;03m# Non-GNN\u001b[39;00m\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_batch_item, (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m)) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data_batch_item) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[0;32m~/venvs/neuro/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venvs/neuro/lib/python3.10/site-packages/torch/nn/modules/module.py:1845\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[1;32m   1844\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1845\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1847\u001b[0m     \u001b[38;5;66;03m# run always called hooks if they have not already been run\u001b[39;00m\n\u001b[1;32m   1848\u001b[0m     \u001b[38;5;66;03m# For now only forward hooks have the always_call option but perhaps\u001b[39;00m\n\u001b[1;32m   1849\u001b[0m     \u001b[38;5;66;03m# this functionality should be added to full backward hooks as well.\u001b[39;00m\n\u001b[1;32m   1850\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m _global_forward_hooks\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/venvs/neuro/lib/python3.10/site-packages/torch/nn/modules/module.py:1793\u001b[0m, in \u001b[0;36mModule._call_impl.<locals>.inner\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1790\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m BackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1791\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1793\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1794\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1795\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m   1796\u001b[0m         \u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1797\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1798\u001b[0m     ):\n\u001b[1;32m   1799\u001b[0m         \u001b[38;5;66;03m# mark that always called hook is run\u001b[39;00m\n",
      "File \u001b[0;32m~/venvs/neuro/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py:193\u001b[0m, in \u001b[0;36mDataParallel.forward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule(\u001b[38;5;241m*\u001b[39minputs[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodule_kwargs[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    192\u001b[0m replicas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplicate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_ids[: \u001b[38;5;28mlen\u001b[39m(inputs)])\n\u001b[0;32m--> 193\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparallel_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather(outputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_device)\n",
      "File \u001b[0;32m~/venvs/neuro/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py:212\u001b[0m, in \u001b[0;36mDataParallel.parallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mparallel_apply\u001b[39m(\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;28mself\u001b[39m, replicas: Sequence[T], inputs: Sequence[Any], kwargs: Any\n\u001b[1;32m    211\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Any]:\n\u001b[0;32m--> 212\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparallel_apply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venvs/neuro/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:126\u001b[0m, in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m    124\u001b[0m     output \u001b[38;5;241m=\u001b[39m results[i]\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, ExceptionWrapper):\n\u001b[0;32m--> 126\u001b[0m         \u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m     outputs\u001b[38;5;241m.\u001b[39mappend(output)\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/venvs/neuro/lib/python3.10/site-packages/torch/_utils.py:733\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    729\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    730\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    731\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 733\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mIndexError\u001b[0m: Caught IndexError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/home/ldibello/venvs/neuro/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py\", line 96, in _worker\n    output = module(*input, **kwargs)\n  File \"/home/ldibello/venvs/neuro/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/ldibello/venvs/neuro/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/ldibello/NeuroGraphNet/src/layers/gat.py\", line 20, in forward\n    x = self.gat1(x, edge_index)\n  File \"/home/ldibello/venvs/neuro/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/ldibello/venvs/neuro/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/ldibello/venvs/neuro/lib/python3.10/site-packages/torch_geometric/nn/conv/gat_conv.py\", line 347, in forward\n    edge_index, edge_attr = remove_self_loops(\n  File \"/home/ldibello/venvs/neuro/lib/python3.10/site-packages/torch_geometric/utils/loop.py\", line 112, in remove_self_loops\n    mask = edge_index[0] != edge_index[1]\nIndexError: index 1 is out of bounds for dimension 0 with size 1\n"
     ]
    }
   ],
   "source": [
    "%aimport\n",
    "from src.utils.train import train_model\n",
    "\n",
    "train_model(\n",
    "    clips=clips_tr,\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    criterion=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    num_epochs=config[\"epochs\"],\n",
    "    patience=config[\"patience\"],\n",
    "    save_path=SAVE_PATH,\n",
    "    use_gnn=True,\n",
    "    use_oversampling=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3887a39b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ldibello/venvs/neuro/lib/python3.10/site-packages/torch_geometric/nn/dense/linear.py:147: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:180.)\n",
      "  return F.linear(x, self.weight, self.bias)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Caught IndexError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/home/ldibello/venvs/neuro/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py\", line 96, in _worker\n    output = module(*input, **kwargs)\n  File \"/home/ldibello/venvs/neuro/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/ldibello/venvs/neuro/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/ldibello/NeuroGraphNet/src/layers/gat.py\", line 20, in forward\n    x = self.gat1(x, edge_index)\n  File \"/home/ldibello/venvs/neuro/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/ldibello/venvs/neuro/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/ldibello/venvs/neuro/lib/python3.10/site-packages/torch_geometric/nn/conv/gat_conv.py\", line 347, in forward\n    edge_index, edge_attr = remove_self_loops(\n  File \"/home/ldibello/venvs/neuro/lib/python3.10/site-packages/torch_geometric/utils/loop.py\", line 112, in remove_self_loops\n    mask = edge_index[0] != edge_index[1]\nIndexError: index 1 is out of bounds for dimension 0 with size 1\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m batch \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mto(device)  \u001b[38;5;66;03m# Move batch to GPU\u001b[39;00m\n\u001b[1;32m     21\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 22\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(\n\u001b[1;32m     24\u001b[0m     out, batch\u001b[38;5;241m.\u001b[39my\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     25\u001b[0m )  \u001b[38;5;66;03m# y: [batch_size] ->[batch_size, 1]\u001b[39;00m\n\u001b[1;32m     26\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/venvs/neuro/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venvs/neuro/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/venvs/neuro/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py:193\u001b[0m, in \u001b[0;36mDataParallel.forward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule(\u001b[38;5;241m*\u001b[39minputs[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodule_kwargs[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    192\u001b[0m replicas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplicate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_ids[: \u001b[38;5;28mlen\u001b[39m(inputs)])\n\u001b[0;32m--> 193\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparallel_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather(outputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_device)\n",
      "File \u001b[0;32m~/venvs/neuro/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py:212\u001b[0m, in \u001b[0;36mDataParallel.parallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mparallel_apply\u001b[39m(\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;28mself\u001b[39m, replicas: Sequence[T], inputs: Sequence[Any], kwargs: Any\n\u001b[1;32m    211\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Any]:\n\u001b[0;32m--> 212\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparallel_apply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venvs/neuro/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:126\u001b[0m, in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m    124\u001b[0m     output \u001b[38;5;241m=\u001b[39m results[i]\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, ExceptionWrapper):\n\u001b[0;32m--> 126\u001b[0m         \u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m     outputs\u001b[38;5;241m.\u001b[39mappend(output)\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/venvs/neuro/lib/python3.10/site-packages/torch/_utils.py:733\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    729\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    730\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    731\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 733\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mIndexError\u001b[0m: Caught IndexError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/home/ldibello/venvs/neuro/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py\", line 96, in _worker\n    output = module(*input, **kwargs)\n  File \"/home/ldibello/venvs/neuro/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/ldibello/venvs/neuro/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/ldibello/NeuroGraphNet/src/layers/gat.py\", line 20, in forward\n    x = self.gat1(x, edge_index)\n  File \"/home/ldibello/venvs/neuro/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/ldibello/venvs/neuro/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/ldibello/venvs/neuro/lib/python3.10/site-packages/torch_geometric/nn/conv/gat_conv.py\", line 347, in forward\n    edge_index, edge_attr = remove_self_loops(\n  File \"/home/ldibello/venvs/neuro/lib/python3.10/site-packages/torch_geometric/utils/loop.py\", line 112, in remove_self_loops\n    mask = edge_index[0] != edge_index[1]\nIndexError: index 1 is out of bounds for dimension 0 with size 1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "import wandb\n",
    "\n",
    "from src.utils.general_funcs import confusion_matrix_plot\n",
    "\n",
    "best_val_loss = float(\"inf\")\n",
    "best_val_f1 = 0\n",
    "best_val_f1_epoch = 0\n",
    "patience = 10\n",
    "counter = 0\n",
    "num_epochs = 100\n",
    "print(\"Training started\")\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    # ------- Training ------- #\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    # for batch in tqdm(train_loader,desc=f\"Epoch {epoch} â€” Training\" ):\n",
    "    for batch in train_loader:\n",
    "        batch = batch.to(device)  # Move batch to GPU\n",
    "        optimizer.zero_grad()\n",
    "        out = model(batch.x, batch.edge_index, batch.batch)\n",
    "        loss = loss_fn(\n",
    "            out, batch.y.reshape(-1, 1)\n",
    "        )  # y: [batch_size] ->[batch_size, 1]\n",
    "        loss.backward()\n",
    "        # for name, param in model.named_parameters():\n",
    "        #     if param.grad is not None:\n",
    "        #         print(f\"{name}: grad norm = {param.grad.norm().item():.2e}\")\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    avg_train_loss = total_loss / len(train_loader)  # Average loss per batch\n",
    "\n",
    "    # ------- Validation ------- #\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            batch = batch.to(device)  # Move batch to GPU\n",
    "            out = model(\n",
    "                batch.x, batch.edge_index, batch.batch\n",
    "            )  # batch.batch: [num_nodes_batch] = 19*batch_size -> tells the model which graph each node belongs to\n",
    "            loss = loss_fn(out, batch.y.reshape(-1, 1))\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "\n",
    "            probs = torch.sigmoid(out).squeeze()  # [batch_size, 1] -> [batch_size]\n",
    "            preds = (probs > 0.5).int()\n",
    "            all_preds.extend(preds.cpu().numpy().ravel())\n",
    "            all_labels.extend(\n",
    "                batch.y.int().cpu().numpy().ravel()\n",
    "            )  # Labels: stored as float in dataset\n",
    "            # print(f\"Val logits stats â€” min: {out.min().item():.4f}, max: {out.max().item():.4f}, mean: {out.mean().item():.4f}, std: {out.std().item():.4f}\")\n",
    "            # print(f\"Predictions:{preds.cpu().numpy()}\")\n",
    "            # print(f\"Sigmoid outputs: { torch.sigmoid(out).detach().cpu().numpy()}\")\n",
    "            # print(f\"Labels:{batch.y}\")\n",
    "            \n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)  # Average loss per batch\n",
    "    #scheduler.step(avg_val_loss)\n",
    "    val_f1 = f1_score(all_labels, all_preds, average=\"macro\")\n",
    "\n",
    "    all_labels = np.array(all_labels).astype(int)\n",
    "    all_preds = np.array(all_preds).astype(int)\n",
    "\n",
    "    # for name, param in model.named_parameters():\n",
    "    #     if param.grad is not None:\n",
    "    #         print(f\"{name} grad mean: {param.grad.abs().mean()}\")\n",
    "    \n",
    "    # Monitor progress\n",
    "    print(f\"Epoch {epoch} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f} | Val F1: {val_f1:.4f}\")\n",
    "    \n",
    "    # Additional metrics\n",
    "\n",
    "    # Confusion matrix\n",
    "    confusion_matrix_plot(all_preds, all_labels)\n",
    "    # Compute metrics per class (0 and 1)\n",
    "    precision = precision_score(all_labels, all_preds, average=None)\n",
    "    recall = recall_score(all_labels, all_preds, average=None)\n",
    "    f1 = f1_score(all_labels, all_preds, average=None)\n",
    "\n",
    "    # Print only for class 1\n",
    "    print(f\"Class 1 â€” Precision: {precision[1]:.2f}, Recall: {recall[1]:.2f}, F1: {f1[1]:.2f}\")\n",
    "    \n",
    "\n",
    "    # W&B\n",
    "    # wandb.log(\n",
    "    #     {\n",
    "    #         \"epoch\": epoch,\n",
    "    #         \"train_loss\": avg_train_loss,\n",
    "    #         \"val_loss\": avg_val_loss,\n",
    "    #         \"val_f1\": val_f1,\n",
    "    #         \"val_f1_class_1\":f1[1],\n",
    "    #             \"val_f1_class_0\":f1[0]\n",
    "    #     }\n",
    "    # )\n",
    "    print(f\"Epoch {epoch} â€” Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, Val F1: {val_f1:.4f}\", flush=True)\n",
    "    # ------- Record best F1 score ------- #\n",
    "    if val_f1 > best_val_f1:\n",
    "        best_val_f1 = val_f1\n",
    "        best_val_f1_epoch = epoch\n",
    "        best_preds = all_preds.copy()\n",
    "        best_labels = all_labels.copy()\n",
    "        # Load best stats in wandb\n",
    "        wandb.summary[\"best_f1_score\"] = val_f1\n",
    "        wandb.summary[\"f1_score_epoch\"] = epoch\n",
    "    # ------- Early Stopping ------- #\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        # Save best statistics and model\n",
    "        best_val_loss = avg_val_loss\n",
    "        counter = 0\n",
    "        best_state_dict = model.state_dict().copy()  # Save the best model state\n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "print(f\"Best validation F1: {best_val_f1:.4f} at epoch {best_val_f1_epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c08a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
