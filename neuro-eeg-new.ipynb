{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97b998b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric.loader import DataLoader as GeoDataLoader\n",
    "from torch.utils.data import Subset, WeightedRandomSampler\n",
    "# from torch.utils.data import DataLoader\n",
    "from src.utils.seeder import seed_everything\n",
    "\n",
    "# set seaborn theme\n",
    "sns.set_theme()\n",
    "\n",
    "# create useful constants\n",
    "RANDOM_SEED = 42\n",
    "IS_SCITAS = True # set to True if running on SCITAS cluster\n",
    "LOCAL_DATA_ROOT = Path(\"./data\")\n",
    "DATA_ROOT = Path(\"/home/ogut/data\") if IS_SCITAS else LOCAL_DATA_ROOT\n",
    "CHECKPOINT_ROOT = Path(\"./.checkpoints\")\n",
    "SUBMISSION_ROOT = Path(\"./.submissions\")\n",
    "\n",
    "# create directories if they do not exist\n",
    "CHECKPOINT_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "SUBMISSION_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# set dataset root\n",
    "seed_everything(RANDOM_SEED)\n",
    "\n",
    "# setup torch device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78d28586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import subprocess\n",
    "\n",
    "# # execute feature extraction script\n",
    "# try:\n",
    "#     process = subprocess.Popen([\"python3\", \"scripts/feature_extractor.py\"])\n",
    "#     process.wait()\n",
    "# except KeyboardInterrupt:\n",
    "#     print(\"Process interrupted, terminating...\")\n",
    "#     process.terminate()\n",
    "#     process.wait()\n",
    "# except Exception as e:\n",
    "#     print(f\"Error occurred: {e}\")\n",
    "#     if 'process' in locals():\n",
    "#         process.terminate()\n",
    "#         process.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45999291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spacial distance matrix between sensors\n",
    "spatial_distance_file = LOCAL_DATA_ROOT / \"distances_3d.csv\"\n",
    "\n",
    "# training data\n",
    "train_dir = DATA_ROOT / \"train\"\n",
    "train_dir_metadata = train_dir / \"segments.parquet\"\n",
    "train_dataset_dir = LOCAL_DATA_ROOT / \"graph_dataset_train\"\n",
    "\n",
    "# test data\n",
    "test_dir = DATA_ROOT / \"test\"\n",
    "test_dir_metadata = test_dir / \"segments.parquet\"\n",
    "test_dataset_dir = LOCAL_DATA_ROOT / \"graph_dataset_test\"\n",
    "\n",
    "# additional features\n",
    "extracted_features_dir = LOCAL_DATA_ROOT / \"extracted_features\"\n",
    "embeddings_dir =  LOCAL_DATA_ROOT / \"embeddings\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83d93851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient   session    segment\n",
      "pqejgcvm  s001_t000  0          pqejgcvm_s001_t000_0\n",
      "                     1          pqejgcvm_s001_t000_1\n",
      "                     2          pqejgcvm_s001_t000_2\n",
      "                     3          pqejgcvm_s001_t000_3\n",
      "                     4          pqejgcvm_s001_t000_4\n",
      "Name: id, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from src.utils.index import ensure_eeg_multiindex \n",
    "\n",
    "# Load clips from datasets\n",
    "clips_tr = pd.read_parquet(train_dir_metadata)\n",
    "clips_tr = ensure_eeg_multiindex(clips_tr)\n",
    "clips_tr = clips_tr[~clips_tr.label.isna()].reset_index()  # Filter NaN values out of clips_tr\n",
    "\n",
    "# Load clips from datasets\n",
    "clips_te = pd.read_parquet(test_dir_metadata)\n",
    "clips_te = ensure_eeg_multiindex(clips_te)\n",
    "\n",
    "# Create unique IDs by converting all index components to strings and store in new column\n",
    "clips_te['id'] = clips_te.index.map(lambda x: '_'.join(str(i) for i in x))\n",
    "assert clips_te.id.nunique() == len(clips_te), \"There are duplicate IDs\"\n",
    "print(clips_te[\"id\"].head())\n",
    "\n",
    "# sort in order to maintain the same submission order\n",
    "clips_te = clips_te.sort_values(by=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd45b398",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-05 17:31:02 - INFO - Initializing GraphEEGDataset...\n",
      "2025-06-05 17:31:02 - INFO - Dataset parameters:\n",
      "2025-06-05 17:31:02 - INFO -   - Root directory: data/graph_dataset_train\n",
      "2025-06-05 17:31:02 - INFO -   - Edge strategy: spatial\n",
      "2025-06-05 17:31:02 - INFO -   - Top-k neighbors: None\n",
      "2025-06-05 17:31:02 - INFO -   - Correlation threshold: 0.5\n",
      "2025-06-05 17:31:02 - INFO -   - Force reprocess: False\n",
      "2025-06-05 17:31:02 - INFO -   - Bandpass frequencies: (0.5, 50)\n",
      "2025-06-05 17:31:02 - INFO -   - Segment length: 3000\n",
      "2025-06-05 17:31:02 - INFO -   - Apply filtering: True\n",
      "2025-06-05 17:31:02 - INFO -   - Apply rereferencing: False\n",
      "2025-06-05 17:31:02 - INFO -   - Apply normalization: False\n",
      "2025-06-05 17:31:02 - INFO -   - Sampling rate: 250\n",
      "2025-06-05 17:31:02 - INFO -   - Test mode: False\n",
      "2025-06-05 17:31:02 - INFO - Number of EEG channels: 19\n",
      "2025-06-05 17:31:02 - INFO - Setting up signal filters...\n",
      "2025-06-05 17:31:02 - INFO - Loading spatial distances from data/distances_3d.csv\n",
      "2025-06-05 17:31:02 - INFO - Loading spatial distances from data/distances_3d.csv\n",
      "2025-06-05 17:31:02 - INFO - Loaded 361 spatial distances in 0.01s\n",
      "2025-06-05 17:31:02 - INFO - Loaded 361 spatial distance pairs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modules to reload:\n",
      "\n",
      "\n",
      "Modules to skip:\n",
      "\n",
      "Length of train_dataset: 12993\n",
      " Eliminated IDs: []\n"
     ]
    }
   ],
   "source": [
    "%aimport\n",
    "from src.data.dataset_graph import GraphEEGDataset\n",
    "\n",
    "# dataset settings\n",
    "batch_size = 64\n",
    "selected_features = []\n",
    "embeddings = []\n",
    "edge_strategy = \"spatial\"\n",
    "correlation_threshold = 0.5\n",
    "top_k = None\n",
    "low_bandpass_frequency = 0.5\n",
    "high_bandpass_frequency = 50\n",
    "\n",
    "# additional settings\n",
    "oversampling_power = 1.0\n",
    "\n",
    "# load training dataset\n",
    "dataset_tr = GraphEEGDataset(\n",
    "    root=train_dataset_dir,\n",
    "    clips=clips_tr,\n",
    "    signal_folder=train_dir,\n",
    "    extracted_features_dir=extracted_features_dir,\n",
    "    selected_features_train=selected_features,\n",
    "    embeddings_dir=embeddings_dir,\n",
    "    embeddings_train=embeddings,\n",
    "    edge_strategy=edge_strategy,\n",
    "    spatial_distance_file=(\n",
    "        spatial_distance_file if edge_strategy == \"spatial\" else None\n",
    "    ),\n",
    "    top_k=top_k,\n",
    "    correlation_threshold=correlation_threshold,\n",
    "    force_reprocess=False,\n",
    "    bandpass_frequencies=(\n",
    "        low_bandpass_frequency,\n",
    "        high_bandpass_frequency,\n",
    "    ),\n",
    "    segment_length=3000,\n",
    "    apply_filtering=True,\n",
    "    apply_rereferencing=False,\n",
    "    apply_normalization=False,\n",
    "    sampling_rate=250,\n",
    ")\n",
    "\n",
    "# Check the length of the dataset\n",
    "print(f\"Length of train_dataset: {len(dataset_tr)}\")\n",
    "print(f' Eliminated IDs: {dataset_tr.ids_to_eliminate}')\n",
    "\n",
    "# Eliminate ids that did not have electrodes above correlation threshols\n",
    "clips_tr = clips_tr[~clips_tr.index.isin(dataset_tr.ids_to_eliminate)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a32d044",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-05 17:31:03 - INFO - Initializing GraphEEGDataset...\n",
      "2025-06-05 17:31:03 - INFO - Dataset parameters:\n",
      "2025-06-05 17:31:03 - INFO -   - Root directory: data/graph_dataset_test\n",
      "2025-06-05 17:31:03 - INFO -   - Edge strategy: spatial\n",
      "2025-06-05 17:31:03 - INFO -   - Top-k neighbors: None\n",
      "2025-06-05 17:31:03 - INFO -   - Correlation threshold: 0.5\n",
      "2025-06-05 17:31:03 - INFO -   - Force reprocess: True\n",
      "2025-06-05 17:31:03 - INFO -   - Bandpass frequencies: (0.5, 50)\n",
      "2025-06-05 17:31:03 - INFO -   - Segment length: 3000\n",
      "2025-06-05 17:31:03 - INFO -   - Apply filtering: True\n",
      "2025-06-05 17:31:03 - INFO -   - Apply rereferencing: False\n",
      "2025-06-05 17:31:03 - INFO -   - Apply normalization: False\n",
      "2025-06-05 17:31:03 - INFO -   - Sampling rate: 250\n",
      "2025-06-05 17:31:03 - INFO -   - Test mode: True\n",
      "2025-06-05 17:31:03 - INFO - Number of EEG channels: 19\n",
      "2025-06-05 17:31:03 - INFO - Setting up signal filters...\n",
      "2025-06-05 17:31:03 - INFO - Loading spatial distances from data/distances_3d.csv\n",
      "2025-06-05 17:31:03 - INFO - Loading spatial distances from data/distances_3d.csv\n",
      "2025-06-05 17:31:03 - INFO - Loaded 361 spatial distances in 0.01s\n",
      "2025-06-05 17:31:03 - INFO - Loaded 361 spatial distance pairs\n",
      "2025-06-05 17:31:03 - INFO - Force reprocessing enabled - cleaning up existing processed files\n",
      "2025-06-05 17:31:03 - INFO - Deleted 0 existing processed files\n",
      "2025-06-05 17:31:03 - INFO - Starting session processing...\n",
      "2025-06-05 17:31:03 - INFO - Starting session processing...\n",
      "2025-06-05 17:31:03 - INFO - Processing session 1/50 (Patient pqejgcvm, Session s001_t000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modules to reload:\n",
      "\n",
      "\n",
      "Modules to skip:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-05 17:31:03 - INFO - Preprocessed signal shape: (75250, 19)\n",
      "2025-06-05 17:31:03 - INFO - Processed 0 segments so far\n",
      "2025-06-05 17:31:03 - INFO - Session 1 processed in 0.15s\n",
      "2025-06-05 17:31:03 - INFO - Processing session 2/50 (Patient pqejgcvm, Session s001_t001)\n",
      "2025-06-05 17:31:03 - INFO - Preprocessed signal shape: (59000, 19)\n",
      "2025-06-05 17:31:03 - INFO - Session 2 processed in 0.09s\n",
      "2025-06-05 17:31:03 - INFO - Processing session 3/50 (Patient pqejgcvm, Session s002_t000)\n",
      "2025-06-05 17:31:03 - INFO - Preprocessed signal shape: (65500, 19)\n",
      "2025-06-05 17:31:03 - INFO - Session 3 processed in 0.10s\n",
      "2025-06-05 17:31:03 - INFO - Processing session 4/50 (Patient pqejgdix, Session s002_t001)\n",
      "2025-06-05 17:31:03 - INFO - Preprocessed signal shape: (88500, 19)\n",
      "2025-06-05 17:31:03 - INFO - Session 4 processed in 0.16s\n",
      "2025-06-05 17:31:03 - INFO - Processing session 5/50 (Patient pqejgdix, Session s002_t002)\n",
      "2025-06-05 17:31:03 - INFO - Preprocessed signal shape: (69250, 19)\n",
      "2025-06-05 17:31:03 - INFO - Processed 100 segments so far\n",
      "2025-06-05 17:31:03 - INFO - Session 5 processed in 0.14s\n",
      "2025-06-05 17:31:03 - INFO - Processing session 6/50 (Patient pqejgdix, Session s002_t004)\n",
      "2025-06-05 17:31:03 - INFO - Preprocessed signal shape: (76000, 19)\n",
      "2025-06-05 17:31:03 - INFO - Session 6 processed in 0.11s\n",
      "2025-06-05 17:31:03 - INFO - Processing session 7/50 (Patient pqejgdix, Session s002_t005)\n",
      "2025-06-05 17:31:03 - INFO - Preprocessed signal shape: (73500, 19)\n",
      "2025-06-05 17:31:03 - INFO - Session 7 processed in 0.12s\n",
      "2025-06-05 17:31:03 - INFO - Processing session 8/50 (Patient pqejgdyf, Session s001_t001)\n",
      "2025-06-05 17:31:04 - INFO - Preprocessed signal shape: (310000, 19)\n",
      "2025-06-05 17:31:04 - INFO - Processed 200 segments so far\n",
      "2025-06-05 17:31:04 - INFO - Session 8 processed in 0.50s\n",
      "2025-06-05 17:31:04 - INFO - Processing session 9/50 (Patient pqejgfkt, Session s005_t000)\n",
      "2025-06-05 17:31:04 - INFO - Preprocessed signal shape: (130250, 19)\n",
      "2025-06-05 17:31:04 - INFO - Processed 300 segments so far\n",
      "2025-06-05 17:31:04 - INFO - Session 9 processed in 0.20s\n",
      "2025-06-05 17:31:04 - INFO - Processing session 10/50 (Patient pqejgfkt, Session s005_t001)\n",
      "2025-06-05 17:31:04 - INFO - Preprocessed signal shape: (23750, 19)\n",
      "2025-06-05 17:31:04 - INFO - Session 10 processed in 0.04s\n",
      "2025-06-05 17:31:04 - INFO - Processing session 11/50 (Patient pqejgfkt, Session s005_t002)\n",
      "2025-06-05 17:31:04 - INFO - Preprocessed signal shape: (11250, 19)\n",
      "2025-06-05 17:31:04 - INFO - Session 11 processed in 0.03s\n",
      "2025-06-05 17:31:04 - INFO - Processing session 12/50 (Patient pqejgfkt, Session s005_t003)\n",
      "2025-06-05 17:31:04 - INFO - Preprocessed signal shape: (12750, 19)\n",
      "2025-06-05 17:31:04 - INFO - Session 12 processed in 0.05s\n",
      "2025-06-05 17:31:04 - INFO - Processing session 13/50 (Patient pqejgfkt, Session s005_t004)\n",
      "2025-06-05 17:31:04 - INFO - Preprocessed signal shape: (150250, 19)\n",
      "2025-06-05 17:31:05 - INFO - Session 13 processed in 0.28s\n",
      "2025-06-05 17:31:05 - INFO - Processing session 14/50 (Patient pqejgfkt, Session s005_t005)\n",
      "2025-06-05 17:31:05 - INFO - Preprocessed signal shape: (50000, 19)\n",
      "2025-06-05 17:31:05 - INFO - Session 14 processed in 0.08s\n",
      "2025-06-05 17:31:05 - INFO - Processing session 15/50 (Patient pqejgfll, Session s002_t000)\n",
      "2025-06-05 17:31:05 - INFO - Preprocessed signal shape: (167500, 19)\n",
      "2025-06-05 17:31:05 - INFO - Processed 400 segments so far\n",
      "2025-06-05 17:31:05 - INFO - Session 15 processed in 0.30s\n",
      "2025-06-05 17:31:05 - INFO - Processing session 16/50 (Patient pqejggiv, Session s001_t001)\n",
      "2025-06-05 17:31:05 - INFO - Preprocessed signal shape: (367750, 19)\n",
      "2025-06-05 17:31:05 - INFO - Processed 500 segments so far\n",
      "2025-06-05 17:31:06 - INFO - Session 16 processed in 0.62s\n",
      "2025-06-05 17:31:06 - INFO - Processing session 17/50 (Patient pqejghgm, Session s001_t001)\n",
      "2025-06-05 17:31:06 - INFO - Preprocessed signal shape: (315000, 19)\n",
      "2025-06-05 17:31:06 - INFO - Processed 600 segments so far\n",
      "2025-06-05 17:31:06 - INFO - Session 17 processed in 0.47s\n",
      "2025-06-05 17:31:06 - INFO - Processing session 18/50 (Patient pqejgjsa, Session s004_t000)\n",
      "2025-06-05 17:31:06 - INFO - Preprocessed signal shape: (86250, 19)\n",
      "2025-06-05 17:31:06 - INFO - Processed 700 segments so far\n",
      "2025-06-05 17:31:06 - INFO - Session 18 processed in 0.19s\n",
      "2025-06-05 17:31:06 - INFO - Processing session 19/50 (Patient pqejgkzk, Session s004_t004)\n",
      "2025-06-05 17:31:06 - INFO - Preprocessed signal shape: (70250, 19)\n",
      "2025-06-05 17:31:06 - INFO - Session 19 processed in 0.14s\n",
      "2025-06-05 17:31:06 - INFO - Processing session 20/50 (Patient pqejglig, Session s002_t000)\n",
      "2025-06-05 17:31:06 - INFO - Preprocessed signal shape: (60250, 19)\n",
      "2025-06-05 17:31:07 - INFO - Session 20 processed in 0.16s\n",
      "2025-06-05 17:31:07 - INFO - Processing session 21/50 (Patient pqejgmhe, Session s001_t000)\n",
      "2025-06-05 17:31:07 - INFO - Preprocessed signal shape: (334250, 19)\n",
      "2025-06-05 17:31:07 - INFO - Processed 800 segments so far\n",
      "2025-06-05 17:31:07 - INFO - Session 21 processed in 0.69s\n",
      "2025-06-05 17:31:07 - INFO - Processing session 22/50 (Patient pqejgmjq, Session s002_t000)\n",
      "2025-06-05 17:31:07 - INFO - Preprocessed signal shape: (303750, 19)\n",
      "2025-06-05 17:31:08 - INFO - Processed 900 segments so far\n",
      "2025-06-05 17:31:08 - INFO - Session 22 processed in 0.48s\n",
      "2025-06-05 17:31:08 - INFO - Processing session 23/50 (Patient pqejgmni, Session s001_t001)\n",
      "2025-06-05 17:31:08 - INFO - Preprocessed signal shape: (497000, 19)\n",
      "2025-06-05 17:31:08 - INFO - Processed 1000 segments so far\n",
      "2025-06-05 17:31:08 - INFO - Processed 1100 segments so far\n",
      "2025-06-05 17:31:08 - INFO - Session 23 processed in 0.80s\n",
      "2025-06-05 17:31:08 - INFO - Processing session 24/50 (Patient pqejgnhh, Session s002_t000)\n",
      "2025-06-05 17:31:10 - INFO - Preprocessed signal shape: (1410000, 19)\n",
      "2025-06-05 17:31:10 - INFO - Processed 1200 segments so far\n",
      "2025-06-05 17:31:11 - INFO - Processed 1300 segments so far\n",
      "2025-06-05 17:31:11 - INFO - Processed 1400 segments so far\n",
      "2025-06-05 17:31:11 - INFO - Processed 1500 segments so far\n",
      "2025-06-05 17:31:11 - INFO - Session 24 processed in 2.67s\n",
      "2025-06-05 17:31:11 - INFO - Processing session 25/50 (Patient pqejgnih, Session s003_t000)\n",
      "2025-06-05 17:31:11 - INFO - Preprocessed signal shape: (75000, 19)\n",
      "2025-06-05 17:31:11 - INFO - Processed 1600 segments so far\n",
      "2025-06-05 17:31:11 - INFO - Session 25 processed in 0.18s\n",
      "2025-06-05 17:31:11 - INFO - Processing session 26/50 (Patient pqejgnih, Session s003_t006)\n",
      "2025-06-05 17:31:11 - INFO - Preprocessed signal shape: (75000, 19)\n",
      "2025-06-05 17:31:11 - INFO - Session 26 processed in 0.14s\n",
      "2025-06-05 17:31:11 - INFO - Processing session 27/50 (Patient pqejgnkt, Session s002_t001)\n",
      "2025-06-05 17:31:12 - INFO - Preprocessed signal shape: (375750, 19)\n",
      "2025-06-05 17:31:12 - INFO - Processed 1700 segments so far\n",
      "2025-06-05 17:31:12 - INFO - Session 27 processed in 0.57s\n",
      "2025-06-05 17:31:12 - INFO - Processing session 28/50 (Patient pqejgnog, Session s001_t001)\n",
      "2025-06-05 17:31:12 - INFO - Preprocessed signal shape: (318500, 19)\n",
      "2025-06-05 17:31:12 - INFO - Processed 1800 segments so far\n",
      "2025-06-05 17:31:13 - INFO - Session 28 processed in 0.51s\n",
      "2025-06-05 17:31:13 - INFO - Processing session 29/50 (Patient pqejgqxi, Session s001_t002)\n",
      "2025-06-05 17:31:13 - INFO - Preprocessed signal shape: (291750, 19)\n",
      "2025-06-05 17:31:13 - INFO - Processed 1900 segments so far\n",
      "2025-06-05 17:31:13 - INFO - Session 29 processed in 0.51s\n",
      "2025-06-05 17:31:13 - INFO - Processing session 30/50 (Patient pqejgrff, Session s001_t000)\n",
      "2025-06-05 17:31:14 - INFO - Preprocessed signal shape: (469750, 19)\n",
      "2025-06-05 17:31:14 - INFO - Processed 2000 segments so far\n",
      "2025-06-05 17:31:14 - INFO - Processed 2100 segments so far\n",
      "2025-06-05 17:31:14 - INFO - Session 30 processed in 0.76s\n",
      "2025-06-05 17:31:14 - INFO - Processing session 31/50 (Patient pqejgrhn, Session s001_t000)\n",
      "2025-06-05 17:31:15 - INFO - Preprocessed signal shape: (878250, 19)\n",
      "2025-06-05 17:31:15 - INFO - Processed 2200 segments so far\n",
      "2025-06-05 17:31:15 - INFO - Processed 2300 segments so far\n",
      "2025-06-05 17:31:15 - INFO - Processed 2400 segments so far\n",
      "2025-06-05 17:31:15 - INFO - Session 31 processed in 1.39s\n",
      "2025-06-05 17:31:15 - INFO - Processing session 32/50 (Patient pqejgrhn, Session s003_t000)\n",
      "2025-06-05 17:31:15 - INFO - Preprocessed signal shape: (18250, 19)\n",
      "2025-06-05 17:31:15 - INFO - Session 32 processed in 0.03s\n",
      "2025-06-05 17:31:15 - INFO - Processing session 33/50 (Patient pqejgrhn, Session s003_t001)\n",
      "2025-06-05 17:31:16 - INFO - Preprocessed signal shape: (374000, 19)\n",
      "2025-06-05 17:31:16 - INFO - Processed 2500 segments so far\n",
      "2025-06-05 17:31:16 - INFO - Session 33 processed in 0.69s\n",
      "2025-06-05 17:31:16 - INFO - Processing session 34/50 (Patient pqejgsfr, Session s002_t002)\n",
      "2025-06-05 17:31:16 - INFO - Preprocessed signal shape: (196750, 19)\n",
      "2025-06-05 17:31:16 - INFO - Processed 2600 segments so far\n",
      "2025-06-05 17:31:16 - INFO - Session 34 processed in 0.32s\n",
      "2025-06-05 17:31:16 - INFO - Processing session 35/50 (Patient pqejgsfr, Session s002_t003)\n",
      "2025-06-05 17:31:16 - INFO - Preprocessed signal shape: (192000, 19)\n",
      "2025-06-05 17:31:17 - INFO - Session 35 processed in 0.29s\n",
      "2025-06-05 17:31:17 - INFO - Processing session 36/50 (Patient pqejgsfr, Session s003_t000)\n",
      "2025-06-05 17:31:17 - INFO - Preprocessed signal shape: (179750, 19)\n",
      "2025-06-05 17:31:17 - INFO - Processed 2700 segments so far\n",
      "2025-06-05 17:31:17 - INFO - Session 36 processed in 0.29s\n",
      "2025-06-05 17:31:17 - INFO - Processing session 37/50 (Patient pqejgsfr, Session s003_t003)\n",
      "2025-06-05 17:31:17 - INFO - Preprocessed signal shape: (197250, 19)\n",
      "2025-06-05 17:31:17 - INFO - Processed 2800 segments so far\n",
      "2025-06-05 17:31:17 - INFO - Session 37 processed in 0.34s\n",
      "2025-06-05 17:31:17 - INFO - Processing session 38/50 (Patient pqejgsfr, Session s003_t004)\n",
      "2025-06-05 17:31:17 - INFO - Preprocessed signal shape: (182750, 19)\n",
      "2025-06-05 17:31:18 - INFO - Session 38 processed in 0.32s\n",
      "2025-06-05 17:31:18 - INFO - Processing session 39/50 (Patient pqejgsfr, Session s003_t006)\n",
      "2025-06-05 17:31:18 - INFO - Preprocessed signal shape: (182250, 19)\n",
      "2025-06-05 17:31:18 - INFO - Processed 2900 segments so far\n",
      "2025-06-05 17:31:18 - INFO - Session 39 processed in 0.27s\n",
      "2025-06-05 17:31:18 - INFO - Processing session 40/50 (Patient pqejgsfr, Session s003_t007)\n",
      "2025-06-05 17:31:18 - INFO - Preprocessed signal shape: (221250, 19)\n",
      "2025-06-05 17:31:18 - INFO - Session 40 processed in 0.37s\n",
      "2025-06-05 17:31:18 - INFO - Processing session 41/50 (Patient pqejgsmy, Session s003_t006)\n",
      "2025-06-05 17:31:18 - INFO - Preprocessed signal shape: (150250, 19)\n",
      "2025-06-05 17:31:18 - INFO - Processed 3000 segments so far\n",
      "2025-06-05 17:31:18 - INFO - Session 41 processed in 0.24s\n",
      "2025-06-05 17:31:18 - INFO - Processing session 42/50 (Patient pqejgtld, Session s003_t000)\n",
      "2025-06-05 17:31:19 - INFO - Preprocessed signal shape: (75000, 19)\n",
      "2025-06-05 17:31:19 - INFO - Session 42 processed in 0.15s\n",
      "2025-06-05 17:31:19 - INFO - Processing session 43/50 (Patient pqejgtld, Session s003_t001)\n",
      "2025-06-05 17:31:19 - INFO - Preprocessed signal shape: (150250, 19)\n",
      "2025-06-05 17:31:19 - INFO - Processed 3100 segments so far\n",
      "2025-06-05 17:31:19 - INFO - Session 43 processed in 0.27s\n",
      "2025-06-05 17:31:19 - INFO - Processing session 44/50 (Patient pqejguho, Session s001_t000)\n",
      "2025-06-05 17:31:19 - INFO - Preprocessed signal shape: (229500, 19)\n",
      "2025-06-05 17:31:19 - INFO - Session 44 processed in 0.39s\n",
      "2025-06-05 17:31:19 - INFO - Processing session 45/50 (Patient pqejguho, Session s003_t001)\n",
      "2025-06-05 17:31:19 - INFO - Preprocessed signal shape: (75000, 19)\n",
      "2025-06-05 17:31:19 - INFO - Processed 3200 segments so far\n",
      "2025-06-05 17:31:19 - INFO - Session 45 processed in 0.15s\n",
      "2025-06-05 17:31:19 - INFO - Processing session 46/50 (Patient pqejguho, Session s003_t002)\n",
      "2025-06-05 17:31:20 - INFO - Preprocessed signal shape: (309000, 19)\n",
      "2025-06-05 17:31:20 - INFO - Processed 3300 segments so far\n",
      "2025-06-05 17:31:20 - INFO - Session 46 processed in 0.59s\n",
      "2025-06-05 17:31:20 - INFO - Processing session 47/50 (Patient pqejguho, Session s003_t006)\n",
      "2025-06-05 17:31:20 - INFO - Preprocessed signal shape: (161250, 19)\n",
      "2025-06-05 17:31:20 - INFO - Session 47 processed in 0.30s\n",
      "2025-06-05 17:31:20 - INFO - Processing session 48/50 (Patient pqejguho, Session s004_t003)\n",
      "2025-06-05 17:31:20 - INFO - Preprocessed signal shape: (165000, 19)\n",
      "2025-06-05 17:31:20 - INFO - Processed 3400 segments so far\n",
      "2025-06-05 17:31:21 - INFO - Session 48 processed in 0.24s\n",
      "2025-06-05 17:31:21 - INFO - Processing session 49/50 (Patient pqejguho, Session s004_t005)\n",
      "2025-06-05 17:31:21 - INFO - Preprocessed signal shape: (75000, 19)\n",
      "2025-06-05 17:31:21 - INFO - Session 49 processed in 0.13s\n",
      "2025-06-05 17:31:21 - INFO - Processing session 50/50 (Patient pqejgvej, Session s001_t000)\n",
      "2025-06-05 17:31:21 - INFO - Preprocessed signal shape: (474500, 19)\n",
      "2025-06-05 17:31:21 - INFO - Processed 3500 segments so far\n",
      "2025-06-05 17:31:22 - INFO - Processed 3600 segments so far\n",
      "2025-06-05 17:31:22 - INFO - Session 50 processed in 0.90s\n",
      "2025-06-05 17:31:22 - INFO - Session processing completed in 18.98s\n",
      "2025-06-05 17:31:22 - INFO - Processed 3614 segments, skipped 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train_dataset: 3614\n",
      " Eliminated IDs:[]\n"
     ]
    }
   ],
   "source": [
    "%aimport\n",
    "from src.data.dataset_graph import GraphEEGDataset\n",
    "\n",
    "# load test dataset\n",
    "te_dataset = GraphEEGDataset(\n",
    "    root=test_dataset_dir,\n",
    "    clips=clips_te,\n",
    "    signal_folder=test_dir,\n",
    "    extracted_features_dir=extracted_features_dir,\n",
    "    selected_features_train=False,\n",
    "    embeddings_dir=embeddings_dir,\n",
    "    embeddings_train=False,\n",
    "    edge_strategy=\"spatial\",\n",
    "    spatial_distance_file=spatial_distance_file,\n",
    "    top_k=None,\n",
    "    correlation_threshold=0.5,\n",
    "    force_reprocess=True,\n",
    "    bandpass_frequencies=(\n",
    "        low_bandpass_frequency,\n",
    "        high_bandpass_frequency,\n",
    "    ),\n",
    "    segment_length=3000,\n",
    "    apply_filtering=True,\n",
    "    apply_rereferencing=False,\n",
    "    apply_normalization=False,\n",
    "    sampling_rate=250,\n",
    "    is_test = True,\n",
    ")\n",
    "\n",
    "# Check the length of the dataset\n",
    "print(f\"Length of train_dataset: {len(dataset_te)}\")\n",
    "print(f' Eliminated IDs:{dataset_te.ids_to_eliminate}')\n",
    "\n",
    "# Eliminate ids that did not have electrodes above correlation threshols\n",
    "clips_te = clips_te[~clips_te.index.isin(dataset_te.ids_to_eliminate)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a52b6bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[19, 3000], edge_index=[2, 342], id='pqejgcvm_s001_t000_0')\n"
     ]
    }
   ],
   "source": [
    "for batch in te_dataset:\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f368519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels before Kfold\n",
      "[1 1 1 ... 1 1 0]\n",
      "[17:31:22] Train labels: 0 -> 8389, 1 -> 2093\n",
      "[17:31:22] Val labels:   0 -> 2087, 1 -> 424\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "from src.utils.general_funcs import labels_stats\n",
    "\n",
    "cv = GroupKFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
    "groups = clips_tr.patient.values\n",
    "y = clips_tr[\"label\"].values\n",
    "X = np.zeros(len(y))  # Dummy X (not used); just placeholder for the Kfold\n",
    "train_ids, val_ids = next(cv.split(X, y, groups=groups))  # Just select one split\n",
    "print('Labels before Kfold', flush=True)\n",
    "print(y,flush=True)\n",
    "\n",
    "# Print stats for class 0 and 1\n",
    "labels_stats(y, train_ids, val_ids)\n",
    "\n",
    "# 2. From dataset generate train and val datasets\n",
    "train_dataset = Subset(dataset_tr, train_ids)\n",
    "val_dataset = Subset(dataset_tr, val_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e6943f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batches: 164\n",
      "Val batches: 40\n",
      "Test batches: 57\n"
     ]
    }
   ],
   "source": [
    "# 3. Compute sample weights for oversampling\n",
    "train_labels = [clips_tr.iloc[i][\"label\"] for i in train_ids]\n",
    "class_counts = np.bincount(train_labels)\n",
    "class_weights = (1. / class_counts) ** oversampling_power # Higher weights for not frequent classes\n",
    "sample_weights = [class_weights[label] for label in train_labels] # Assign weight to each sample based on its class\n",
    "\n",
    "# 4. Define sampler\n",
    "sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True) # Still train on N samples per epoch, but instead of sampling uniformly takes more from minority class\n",
    "\n",
    "# Define dataloaders\n",
    "BATCH_SIZE = 64\n",
    "train_loader = GeoDataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=sampler, shuffle=False)\n",
    "val_loader = GeoDataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "te_loader = GeoDataLoader(te_dataset, batch_size=BATCH_SIZE)\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Val batches: {len(val_loader)}\")\n",
    "print(f\"Test batches: {len(te_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4e3d2ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(x=[1216, 3000], edge_index=[2, 21888], y=[64], batch=[1216], ptr=[65])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_loader:\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1427c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-05 18:04:00 - INFO - Starting training setup...\n",
      "2025-06-05 18:04:00 - INFO - Model type: GNN\n",
      "2025-06-05 18:04:00 - INFO - Device: cuda\n",
      "2025-06-05 18:04:00 - INFO - Batch size: 64\n",
      "2025-06-05 18:04:00 - INFO - Number of epochs: 100\n",
      "2025-06-05 18:04:00 - INFO - Patience: 20\n",
      "2025-06-05 18:04:00 - INFO - Monitor metric: val_f1\n",
      "2025-06-05 18:04:00 - INFO - Total training batches per epoch: 164\n",
      "2025-06-05 18:04:00 - INFO - Starting training from epoch 26 to 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modules to reload:\n",
      "src.utils.train\n",
      "\n",
      "Modules to skip:\n",
      "\n",
      "pos_weight:tensor([1.5000], device='cuda:0')\n",
      "ðŸš€ Attempting to load checkpoint from .checkpoints/lstm_gnn_best_model.pt...\n",
      "   - Loading checkpoint from: .checkpoints/lstm_gnn_best_model.pt\n",
      "   - Detected full checkpoint dictionary.\n",
      "   - Optimizer state loaded from checkpoint.\n",
      "   - Model state successfully loaded.\n",
      " âœ… Checkpoint loaded. Resuming from epoch 26. Best 'val_f1' score: 0.6800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                            | 26/100 [00:00<?, ?it/s]2025-06-05 18:04:00 - INFO - \n",
      "Epoch 26/100 - Training phase\n",
      "2025-06-05 18:04:01 - INFO - Processing batch 1/164\n",
      "2025-06-05 18:04:01 - INFO - Batch shapes - x: torch.Size([1216, 3000]), edge_index: torch.Size([2, 21888]), y: torch.Size([64, 1])\n",
      "2025-06-05 18:04:01 - INFO - Batch 1/164 - Loss: 0.5183 - Avg batch time: 0.25s\n",
      "2025-06-05 18:04:14 - INFO - Processing batch 11/164\n",
      "2025-06-05 18:04:14 - INFO - Batch 11/164 - Loss: 0.4198 - Avg batch time: 0.25s\n",
      "2025-06-05 18:04:26 - INFO - Processing batch 21/164\n",
      "2025-06-05 18:04:26 - INFO - Batch 21/164 - Loss: 0.3264 - Avg batch time: 0.25s\n",
      "2025-06-05 18:04:37 - INFO - Processing batch 31/164\n",
      "2025-06-05 18:04:38 - INFO - Batch 31/164 - Loss: 0.3854 - Avg batch time: 0.25s\n",
      "2025-06-05 18:04:49 - INFO - Processing batch 41/164\n",
      "2025-06-05 18:04:50 - INFO - Batch 41/164 - Loss: 0.5118 - Avg batch time: 0.25s\n",
      "2025-06-05 18:05:01 - INFO - Processing batch 51/164\n",
      "2025-06-05 18:05:01 - INFO - Batch 51/164 - Loss: 0.5384 - Avg batch time: 0.25s\n",
      "2025-06-05 18:05:12 - INFO - Processing batch 61/164\n",
      "2025-06-05 18:05:13 - INFO - Batch 61/164 - Loss: 0.4325 - Avg batch time: 0.25s\n",
      "2025-06-05 18:05:24 - INFO - Processing batch 71/164\n",
      "2025-06-05 18:05:24 - INFO - Batch 71/164 - Loss: 0.5367 - Avg batch time: 0.25s\n",
      "2025-06-05 18:05:35 - INFO - Processing batch 81/164\n",
      "2025-06-05 18:05:35 - INFO - Batch 81/164 - Loss: 0.5202 - Avg batch time: 0.25s\n",
      "2025-06-05 18:05:46 - INFO - Processing batch 91/164\n",
      "2025-06-05 18:05:46 - INFO - Batch 91/164 - Loss: 0.3719 - Avg batch time: 0.25s\n",
      "2025-06-05 18:05:57 - INFO - Processing batch 101/164\n",
      "2025-06-05 18:05:57 - INFO - Batch 101/164 - Loss: 0.4118 - Avg batch time: 0.25s\n",
      "2025-06-05 18:06:08 - INFO - Processing batch 111/164\n",
      "2025-06-05 18:06:08 - INFO - Batch 111/164 - Loss: 0.4642 - Avg batch time: 0.25s\n",
      "2025-06-05 18:06:19 - INFO - Processing batch 121/164\n",
      "2025-06-05 18:06:19 - INFO - Batch 121/164 - Loss: 0.3684 - Avg batch time: 0.25s\n",
      "2025-06-05 18:06:29 - INFO - Processing batch 131/164\n",
      "2025-06-05 18:06:29 - INFO - Batch 131/164 - Loss: 0.4648 - Avg batch time: 0.25s\n",
      "2025-06-05 18:06:39 - INFO - Processing batch 141/164\n",
      "2025-06-05 18:06:40 - INFO - Batch 141/164 - Loss: 0.2874 - Avg batch time: 0.25s\n",
      "2025-06-05 18:06:50 - INFO - Processing batch 151/164\n",
      "2025-06-05 18:06:50 - INFO - Batch 151/164 - Loss: 0.3541 - Avg batch time: 0.25s\n",
      "2025-06-05 18:07:00 - INFO - Processing batch 161/164\n",
      "2025-06-05 18:07:00 - INFO - Batch 161/164 - Loss: 0.4573 - Avg batch time: 0.25s\n",
      "2025-06-05 18:07:03 - INFO - \n",
      "Epoch 26 training completed in 183.37s\n",
      "2025-06-05 18:07:03 - INFO - Average training loss: 0.4413\n",
      "Epochs:  27%|â–Ž| 27/100 [04:14<5:09:03, 254.01s/it, train_loss=0.4413, val_loss=0.4406, best_val_f1=0.6800, lr=3.00e-04, 2025-06-05 18:08:14 - INFO - \n",
      "Epoch 27/100 - Training phase\n",
      "2025-06-05 18:08:15 - INFO - Processing batch 1/164\n",
      "2025-06-05 18:08:15 - INFO - Batch shapes - x: torch.Size([1216, 3000]), edge_index: torch.Size([2, 21888]), y: torch.Size([64, 1])\n",
      "2025-06-05 18:08:15 - INFO - Batch 1/164 - Loss: 0.4881 - Avg batch time: 0.25s\n",
      "2025-06-05 18:08:25 - INFO - Processing batch 11/164\n",
      "2025-06-05 18:08:25 - INFO - Batch 11/164 - Loss: 0.4486 - Avg batch time: 0.25s\n",
      "2025-06-05 18:08:35 - INFO - Processing batch 21/164\n",
      "2025-06-05 18:08:35 - INFO - Batch 21/164 - Loss: 0.5297 - Avg batch time: 0.25s\n",
      "2025-06-05 18:08:45 - INFO - Processing batch 31/164\n",
      "2025-06-05 18:08:46 - INFO - Batch 31/164 - Loss: 0.5267 - Avg batch time: 0.25s\n",
      "2025-06-05 18:08:55 - INFO - Processing batch 41/164\n",
      "2025-06-05 18:08:56 - INFO - Batch 41/164 - Loss: 0.4241 - Avg batch time: 0.25s\n",
      "2025-06-05 18:09:05 - INFO - Processing batch 51/164\n",
      "2025-06-05 18:09:06 - INFO - Batch 51/164 - Loss: 0.4428 - Avg batch time: 0.25s\n",
      "2025-06-05 18:09:15 - INFO - Processing batch 61/164\n",
      "2025-06-05 18:09:15 - INFO - Batch 61/164 - Loss: 0.5593 - Avg batch time: 0.25s\n",
      "2025-06-05 18:09:25 - INFO - Processing batch 71/164\n",
      "2025-06-05 18:09:25 - INFO - Batch 71/164 - Loss: 0.6035 - Avg batch time: 0.25s\n",
      "2025-06-05 18:09:35 - INFO - Processing batch 81/164\n",
      "2025-06-05 18:09:35 - INFO - Batch 81/164 - Loss: 0.4893 - Avg batch time: 0.25s\n",
      "2025-06-05 18:09:45 - INFO - Processing batch 91/164\n",
      "2025-06-05 18:09:45 - INFO - Batch 91/164 - Loss: 0.3041 - Avg batch time: 0.25s\n",
      "2025-06-05 18:09:54 - INFO - Processing batch 101/164\n",
      "2025-06-05 18:09:54 - INFO - Batch 101/164 - Loss: 0.4563 - Avg batch time: 0.25s\n",
      "2025-06-05 18:10:04 - INFO - Processing batch 111/164\n",
      "2025-06-05 18:10:04 - INFO - Batch 111/164 - Loss: 0.5123 - Avg batch time: 0.25s\n",
      "2025-06-05 18:10:13 - INFO - Processing batch 121/164\n",
      "2025-06-05 18:10:13 - INFO - Batch 121/164 - Loss: 0.3119 - Avg batch time: 0.25s\n",
      "2025-06-05 18:10:22 - INFO - Processing batch 131/164\n",
      "2025-06-05 18:10:23 - INFO - Batch 131/164 - Loss: 0.3101 - Avg batch time: 0.25s\n",
      "2025-06-05 18:10:32 - INFO - Processing batch 141/164\n",
      "2025-06-05 18:10:32 - INFO - Batch 141/164 - Loss: 0.3807 - Avg batch time: 0.25s\n",
      "2025-06-05 18:10:42 - INFO - Processing batch 151/164\n",
      "2025-06-05 18:10:42 - INFO - Batch 151/164 - Loss: 0.3469 - Avg batch time: 0.25s\n",
      "2025-06-05 18:10:51 - INFO - Processing batch 161/164\n",
      "2025-06-05 18:10:51 - INFO - Batch 161/164 - Loss: 0.3781 - Avg batch time: 0.25s\n",
      "2025-06-05 18:10:54 - INFO - \n",
      "Epoch 27 training completed in 160.03s\n",
      "2025-06-05 18:10:54 - INFO - Average training loss: 0.4408\n",
      "Epochs:  28%|â–Ž| 28/100 [07:23<4:19:09, 215.97s/it, train_loss=0.4408, val_loss=0.4130, best_val_f1=0.6800, lr=3.00e-04, 2025-06-05 18:11:23 - INFO - \n",
      "Epoch 28/100 - Training phase\n",
      "2025-06-05 18:11:24 - INFO - Processing batch 1/164\n",
      "2025-06-05 18:11:24 - INFO - Batch shapes - x: torch.Size([1216, 3000]), edge_index: torch.Size([2, 21888]), y: torch.Size([64, 1])\n",
      "2025-06-05 18:11:24 - INFO - Batch 1/164 - Loss: 0.3730 - Avg batch time: 0.25s\n",
      "2025-06-05 18:11:34 - INFO - Processing batch 11/164\n",
      "2025-06-05 18:11:34 - INFO - Batch 11/164 - Loss: 0.4577 - Avg batch time: 0.25s\n",
      "2025-06-05 18:11:43 - INFO - Processing batch 21/164\n",
      "2025-06-05 18:11:44 - INFO - Batch 21/164 - Loss: 0.7089 - Avg batch time: 0.25s\n",
      "2025-06-05 18:11:53 - INFO - Processing batch 31/164\n",
      "2025-06-05 18:11:53 - INFO - Batch 31/164 - Loss: 0.4330 - Avg batch time: 0.25s\n",
      "2025-06-05 18:12:02 - INFO - Processing batch 41/164\n",
      "2025-06-05 18:12:03 - INFO - Batch 41/164 - Loss: 0.3613 - Avg batch time: 0.25s\n",
      "2025-06-05 18:12:11 - INFO - Processing batch 51/164\n",
      "2025-06-05 18:12:12 - INFO - Batch 51/164 - Loss: 0.4588 - Avg batch time: 0.25s\n",
      "2025-06-05 18:12:21 - INFO - Processing batch 61/164\n",
      "2025-06-05 18:12:21 - INFO - Batch 61/164 - Loss: 0.2951 - Avg batch time: 0.25s\n",
      "2025-06-05 18:12:30 - INFO - Processing batch 71/164\n",
      "2025-06-05 18:12:30 - INFO - Batch 71/164 - Loss: 0.3850 - Avg batch time: 0.25s\n",
      "2025-06-05 18:12:39 - INFO - Processing batch 81/164\n",
      "2025-06-05 18:12:40 - INFO - Batch 81/164 - Loss: 0.3474 - Avg batch time: 0.25s\n",
      "2025-06-05 18:12:48 - INFO - Processing batch 91/164\n",
      "2025-06-05 18:12:49 - INFO - Batch 91/164 - Loss: 0.3655 - Avg batch time: 0.25s\n",
      "2025-06-05 18:12:58 - INFO - Processing batch 101/164\n",
      "2025-06-05 18:12:58 - INFO - Batch 101/164 - Loss: 0.4742 - Avg batch time: 0.25s\n",
      "2025-06-05 18:13:07 - INFO - Processing batch 111/164\n",
      "2025-06-05 18:13:07 - INFO - Batch 111/164 - Loss: 0.4698 - Avg batch time: 0.25s\n",
      "2025-06-05 18:13:16 - INFO - Processing batch 121/164\n",
      "2025-06-05 18:13:16 - INFO - Batch 121/164 - Loss: 0.4218 - Avg batch time: 0.25s\n",
      "2025-06-05 18:13:24 - INFO - Processing batch 131/164\n",
      "2025-06-05 18:13:25 - INFO - Batch 131/164 - Loss: 0.4650 - Avg batch time: 0.25s\n",
      "2025-06-05 18:13:34 - INFO - Processing batch 141/164\n",
      "2025-06-05 18:13:34 - INFO - Batch 141/164 - Loss: 0.2826 - Avg batch time: 0.25s\n",
      "2025-06-05 18:13:42 - INFO - Processing batch 151/164\n",
      "2025-06-05 18:13:43 - INFO - Batch 151/164 - Loss: 0.4573 - Avg batch time: 0.25s\n",
      "2025-06-05 18:13:51 - INFO - Processing batch 161/164\n",
      "2025-06-05 18:13:51 - INFO - Batch 161/164 - Loss: 0.5197 - Avg batch time: 0.25s\n",
      "2025-06-05 18:13:54 - INFO - \n",
      "Epoch 28 training completed in 150.48s\n",
      "2025-06-05 18:13:54 - INFO - Average training loss: 0.4259\n",
      "Epochs:  29%|â–Ž| 29/100 [10:21<3:55:13, 198.79s/it, train_loss=0.4259, val_loss=0.4046, best_val_f1=0.6800, lr=3.00e-04, 2025-06-05 18:14:22 - INFO - \n",
      "Epoch 29/100 - Training phase\n",
      "2025-06-05 18:14:22 - INFO - Processing batch 1/164\n",
      "2025-06-05 18:14:22 - INFO - Batch shapes - x: torch.Size([1216, 3000]), edge_index: torch.Size([2, 21888]), y: torch.Size([64, 1])\n",
      "2025-06-05 18:14:23 - INFO - Batch 1/164 - Loss: 0.3388 - Avg batch time: 0.25s\n",
      "2025-06-05 18:14:31 - INFO - Processing batch 11/164\n",
      "2025-06-05 18:14:32 - INFO - Batch 11/164 - Loss: 0.5026 - Avg batch time: 0.25s\n",
      "2025-06-05 18:14:40 - INFO - Processing batch 21/164\n",
      "2025-06-05 18:14:41 - INFO - Batch 21/164 - Loss: 0.4510 - Avg batch time: 0.25s\n",
      "2025-06-05 18:14:49 - INFO - Processing batch 31/164\n",
      "2025-06-05 18:14:50 - INFO - Batch 31/164 - Loss: 0.3547 - Avg batch time: 0.25s\n",
      "2025-06-05 18:14:58 - INFO - Processing batch 41/164\n",
      "2025-06-05 18:14:59 - INFO - Batch 41/164 - Loss: 0.4623 - Avg batch time: 0.25s\n",
      "2025-06-05 18:15:07 - INFO - Processing batch 51/164\n",
      "2025-06-05 18:15:07 - INFO - Batch 51/164 - Loss: 0.4164 - Avg batch time: 0.25s\n",
      "2025-06-05 18:15:16 - INFO - Processing batch 61/164\n",
      "2025-06-05 18:15:16 - INFO - Batch 61/164 - Loss: 0.7026 - Avg batch time: 0.25s\n",
      "2025-06-05 18:15:25 - INFO - Processing batch 71/164\n",
      "2025-06-05 18:15:25 - INFO - Batch 71/164 - Loss: 0.3995 - Avg batch time: 0.25s\n",
      "2025-06-05 18:15:33 - INFO - Processing batch 81/164\n",
      "2025-06-05 18:15:34 - INFO - Batch 81/164 - Loss: 0.3576 - Avg batch time: 0.25s\n",
      "2025-06-05 18:15:42 - INFO - Processing batch 91/164\n",
      "2025-06-05 18:15:42 - INFO - Batch 91/164 - Loss: 0.5320 - Avg batch time: 0.25s\n",
      "2025-06-05 18:15:51 - INFO - Processing batch 101/164\n",
      "2025-06-05 18:15:51 - INFO - Batch 101/164 - Loss: 0.5664 - Avg batch time: 0.25s\n",
      "2025-06-05 18:16:00 - INFO - Processing batch 111/164\n",
      "2025-06-05 18:16:00 - INFO - Batch 111/164 - Loss: 0.4037 - Avg batch time: 0.25s\n",
      "2025-06-05 18:16:08 - INFO - Processing batch 121/164\n",
      "2025-06-05 18:16:08 - INFO - Batch 121/164 - Loss: 0.3218 - Avg batch time: 0.25s\n",
      "2025-06-05 18:16:17 - INFO - Processing batch 131/164\n",
      "2025-06-05 18:16:17 - INFO - Batch 131/164 - Loss: 0.3680 - Avg batch time: 0.25s\n",
      "2025-06-05 18:16:26 - INFO - Processing batch 141/164\n",
      "2025-06-05 18:16:26 - INFO - Batch 141/164 - Loss: 0.2374 - Avg batch time: 0.25s\n",
      "2025-06-05 18:16:35 - INFO - Processing batch 151/164\n",
      "2025-06-05 18:16:35 - INFO - Batch 151/164 - Loss: 0.4189 - Avg batch time: 0.25s\n",
      "2025-06-05 18:16:44 - INFO - Processing batch 161/164\n",
      "2025-06-05 18:16:44 - INFO - Batch 161/164 - Loss: 0.2425 - Avg batch time: 0.25s\n",
      "2025-06-05 18:16:46 - INFO - \n",
      "Epoch 29 training completed in 144.47s\n",
      "2025-06-05 18:16:46 - INFO - Average training loss: 0.4182\n",
      "Epochs:  30%|â–Ž| 30/100 [13:13<3:39:24, 188.06s/it, train_loss=0.4182, val_loss=0.4614, best_val_f1=0.6800, lr=3.00e-04, 2025-06-05 18:17:13 - INFO - \n",
      "Epoch 30/100 - Training phase\n",
      "2025-06-05 18:17:14 - INFO - Processing batch 1/164\n",
      "2025-06-05 18:17:14 - INFO - Batch shapes - x: torch.Size([1216, 3000]), edge_index: torch.Size([2, 21888]), y: torch.Size([64, 1])\n",
      "2025-06-05 18:17:14 - INFO - Batch 1/164 - Loss: 0.4036 - Avg batch time: 0.25s\n",
      "2025-06-05 18:17:23 - INFO - Processing batch 11/164\n",
      "2025-06-05 18:17:23 - INFO - Batch 11/164 - Loss: 0.2767 - Avg batch time: 0.25s\n",
      "2025-06-05 18:17:31 - INFO - Processing batch 21/164\n",
      "2025-06-05 18:17:32 - INFO - Batch 21/164 - Loss: 0.2989 - Avg batch time: 0.25s\n",
      "2025-06-05 18:17:40 - INFO - Processing batch 31/164\n",
      "2025-06-05 18:17:40 - INFO - Batch 31/164 - Loss: 0.5951 - Avg batch time: 0.25s\n",
      "2025-06-05 18:17:49 - INFO - Processing batch 41/164\n",
      "2025-06-05 18:17:49 - INFO - Batch 41/164 - Loss: 0.4201 - Avg batch time: 0.25s\n",
      "2025-06-05 18:17:58 - INFO - Processing batch 51/164\n",
      "2025-06-05 18:17:58 - INFO - Batch 51/164 - Loss: 0.3444 - Avg batch time: 0.25s\n",
      "2025-06-05 18:18:06 - INFO - Processing batch 61/164\n",
      "2025-06-05 18:18:06 - INFO - Batch 61/164 - Loss: 0.4376 - Avg batch time: 0.25s\n",
      "2025-06-05 18:18:15 - INFO - Processing batch 71/164\n",
      "2025-06-05 18:18:15 - INFO - Batch 71/164 - Loss: 0.5124 - Avg batch time: 0.25s\n",
      "2025-06-05 18:18:23 - INFO - Processing batch 81/164\n",
      "2025-06-05 18:18:24 - INFO - Batch 81/164 - Loss: 0.3369 - Avg batch time: 0.25s\n",
      "2025-06-05 18:18:32 - INFO - Processing batch 91/164\n",
      "2025-06-05 18:18:32 - INFO - Batch 91/164 - Loss: 0.3729 - Avg batch time: 0.25s\n",
      "2025-06-05 18:18:40 - INFO - Processing batch 101/164\n",
      "2025-06-05 18:18:41 - INFO - Batch 101/164 - Loss: 0.6509 - Avg batch time: 0.25s\n",
      "2025-06-05 18:18:49 - INFO - Processing batch 111/164\n",
      "2025-06-05 18:18:49 - INFO - Batch 111/164 - Loss: 0.5794 - Avg batch time: 0.25s\n",
      "2025-06-05 18:18:58 - INFO - Processing batch 121/164\n",
      "2025-06-05 18:18:58 - INFO - Batch 121/164 - Loss: 0.4975 - Avg batch time: 0.25s\n",
      "2025-06-05 18:19:06 - INFO - Processing batch 131/164\n",
      "2025-06-05 18:19:06 - INFO - Batch 131/164 - Loss: 0.3766 - Avg batch time: 0.25s\n",
      "2025-06-05 18:19:15 - INFO - Processing batch 141/164\n",
      "2025-06-05 18:19:15 - INFO - Batch 141/164 - Loss: 0.2729 - Avg batch time: 0.25s\n",
      "2025-06-05 18:19:23 - INFO - Processing batch 151/164\n",
      "2025-06-05 18:19:23 - INFO - Batch 151/164 - Loss: 0.3759 - Avg batch time: 0.25s\n",
      "2025-06-05 18:19:32 - INFO - Processing batch 161/164\n",
      "2025-06-05 18:19:32 - INFO - Batch 161/164 - Loss: 0.3319 - Avg batch time: 0.25s\n",
      "2025-06-05 18:19:34 - INFO - \n",
      "Epoch 30 training completed in 141.03s\n",
      "2025-06-05 18:19:34 - INFO - Average training loss: 0.3969\n",
      "Epochs:  31%|â–Ž| 31/100 [16:02<3:28:31, 181.32s/it, train_loss=0.3969, val_loss=0.4247, best_val_f1=0.6800, lr=3.00e-04, 2025-06-05 18:20:03 - INFO - \n",
      "Epoch 31/100 - Training phase\n",
      "2025-06-05 18:20:03 - INFO - Processing batch 1/164\n",
      "2025-06-05 18:20:03 - INFO - Batch shapes - x: torch.Size([1216, 3000]), edge_index: torch.Size([2, 21888]), y: torch.Size([64, 1])\n",
      "2025-06-05 18:20:04 - INFO - Batch 1/164 - Loss: 0.5471 - Avg batch time: 0.25s\n",
      "2025-06-05 18:20:12 - INFO - Processing batch 11/164\n",
      "2025-06-05 18:20:12 - INFO - Batch 11/164 - Loss: 0.3746 - Avg batch time: 0.25s\n",
      "2025-06-05 18:20:21 - INFO - Processing batch 21/164\n",
      "2025-06-05 18:20:21 - INFO - Batch 21/164 - Loss: 0.4521 - Avg batch time: 0.25s\n",
      "2025-06-05 18:20:30 - INFO - Processing batch 31/164\n",
      "2025-06-05 18:20:30 - INFO - Batch 31/164 - Loss: 0.3314 - Avg batch time: 0.25s\n",
      "2025-06-05 18:20:38 - INFO - Processing batch 41/164\n",
      "2025-06-05 18:20:39 - INFO - Batch 41/164 - Loss: 0.3859 - Avg batch time: 0.25s\n",
      "2025-06-05 18:20:47 - INFO - Processing batch 51/164\n",
      "2025-06-05 18:20:47 - INFO - Batch 51/164 - Loss: 0.4608 - Avg batch time: 0.25s\n",
      "2025-06-05 18:20:56 - INFO - Processing batch 61/164\n",
      "2025-06-05 18:20:56 - INFO - Batch 61/164 - Loss: 0.3665 - Avg batch time: 0.25s\n",
      "2025-06-05 18:21:04 - INFO - Processing batch 71/164\n",
      "2025-06-05 18:21:04 - INFO - Batch 71/164 - Loss: 0.4452 - Avg batch time: 0.25s\n",
      "2025-06-05 18:21:13 - INFO - Processing batch 81/164\n",
      "2025-06-05 18:21:13 - INFO - Batch 81/164 - Loss: 0.4186 - Avg batch time: 0.25s\n",
      "2025-06-05 18:21:21 - INFO - Processing batch 91/164\n",
      "2025-06-05 18:21:22 - INFO - Batch 91/164 - Loss: 0.5017 - Avg batch time: 0.25s\n",
      "2025-06-05 18:21:30 - INFO - Processing batch 101/164\n",
      "2025-06-05 18:21:31 - INFO - Batch 101/164 - Loss: 0.3828 - Avg batch time: 0.25s\n",
      "2025-06-05 18:21:39 - INFO - Processing batch 111/164\n",
      "2025-06-05 18:21:39 - INFO - Batch 111/164 - Loss: 0.3070 - Avg batch time: 0.25s\n",
      "2025-06-05 18:21:47 - INFO - Processing batch 121/164\n",
      "2025-06-05 18:21:48 - INFO - Batch 121/164 - Loss: 0.4288 - Avg batch time: 0.25s\n",
      "2025-06-05 18:21:56 - INFO - Processing batch 131/164\n",
      "2025-06-05 18:21:56 - INFO - Batch 131/164 - Loss: 0.2795 - Avg batch time: 0.25s\n",
      "2025-06-05 18:22:04 - INFO - Processing batch 141/164\n",
      "2025-06-05 18:22:04 - INFO - Batch 141/164 - Loss: 0.3022 - Avg batch time: 0.25s\n",
      "2025-06-05 18:22:13 - INFO - Processing batch 151/164\n",
      "2025-06-05 18:22:13 - INFO - Batch 151/164 - Loss: 0.2810 - Avg batch time: 0.25s\n",
      "2025-06-05 18:22:21 - INFO - Processing batch 161/164\n",
      "2025-06-05 18:22:22 - INFO - Batch 161/164 - Loss: 0.3905 - Avg batch time: 0.25s\n",
      "2025-06-05 18:22:24 - INFO - \n",
      "Epoch 31 training completed in 141.33s\n",
      "2025-06-05 18:22:24 - INFO - Average training loss: 0.3984\n",
      "Epochs:  32%|â–Ž| 32/100 [18:51<3:20:29, 176.90s/it, train_loss=0.3984, val_loss=0.4484, best_val_f1=0.6800, lr=3.00e-04, 2025-06-05 18:22:51 - INFO - \n",
      "Epoch 32/100 - Training phase\n",
      "2025-06-05 18:22:52 - INFO - Processing batch 1/164\n",
      "2025-06-05 18:22:52 - INFO - Batch shapes - x: torch.Size([1216, 3000]), edge_index: torch.Size([2, 21888]), y: torch.Size([64, 1])\n",
      "2025-06-05 18:22:52 - INFO - Batch 1/164 - Loss: 0.4818 - Avg batch time: 0.25s\n",
      "2025-06-05 18:23:00 - INFO - Processing batch 11/164\n",
      "2025-06-05 18:23:01 - INFO - Batch 11/164 - Loss: 0.4149 - Avg batch time: 0.25s\n",
      "2025-06-05 18:23:09 - INFO - Processing batch 21/164\n",
      "2025-06-05 18:23:09 - INFO - Batch 21/164 - Loss: 0.5036 - Avg batch time: 0.25s\n",
      "2025-06-05 18:23:17 - INFO - Processing batch 31/164\n",
      "2025-06-05 18:23:18 - INFO - Batch 31/164 - Loss: 0.3846 - Avg batch time: 0.25s\n",
      "2025-06-05 18:23:26 - INFO - Processing batch 41/164\n",
      "2025-06-05 18:23:26 - INFO - Batch 41/164 - Loss: 0.5341 - Avg batch time: 0.25s\n",
      "2025-06-05 18:23:35 - INFO - Processing batch 51/164\n",
      "2025-06-05 18:23:35 - INFO - Batch 51/164 - Loss: 0.4471 - Avg batch time: 0.25s\n",
      "2025-06-05 18:23:43 - INFO - Processing batch 61/164\n",
      "2025-06-05 18:23:44 - INFO - Batch 61/164 - Loss: 0.4548 - Avg batch time: 0.25s\n",
      "2025-06-05 18:23:52 - INFO - Processing batch 71/164\n",
      "2025-06-05 18:23:53 - INFO - Batch 71/164 - Loss: 0.4091 - Avg batch time: 0.25s\n",
      "2025-06-05 18:24:01 - INFO - Processing batch 81/164\n",
      "2025-06-05 18:24:01 - INFO - Batch 81/164 - Loss: 0.4726 - Avg batch time: 0.25s\n",
      "2025-06-05 18:24:09 - INFO - Processing batch 91/164\n",
      "2025-06-05 18:24:10 - INFO - Batch 91/164 - Loss: 0.4325 - Avg batch time: 0.25s\n",
      "2025-06-05 18:24:18 - INFO - Processing batch 101/164\n",
      "2025-06-05 18:24:18 - INFO - Batch 101/164 - Loss: 0.3280 - Avg batch time: 0.25s\n",
      "2025-06-05 18:24:26 - INFO - Processing batch 111/164\n",
      "2025-06-05 18:24:27 - INFO - Batch 111/164 - Loss: 0.2013 - Avg batch time: 0.25s\n",
      "2025-06-05 18:24:35 - INFO - Processing batch 121/164\n",
      "2025-06-05 18:24:35 - INFO - Batch 121/164 - Loss: 0.3860 - Avg batch time: 0.25s\n",
      "2025-06-05 18:24:44 - INFO - Processing batch 131/164\n",
      "2025-06-05 18:24:44 - INFO - Batch 131/164 - Loss: 0.4948 - Avg batch time: 0.25s\n",
      "2025-06-05 18:24:52 - INFO - Processing batch 141/164\n",
      "2025-06-05 18:24:53 - INFO - Batch 141/164 - Loss: 0.4165 - Avg batch time: 0.25s\n",
      "2025-06-05 18:25:01 - INFO - Processing batch 151/164\n",
      "2025-06-05 18:25:01 - INFO - Batch 151/164 - Loss: 0.3974 - Avg batch time: 0.25s\n",
      "2025-06-05 18:25:09 - INFO - Processing batch 161/164\n",
      "2025-06-05 18:25:10 - INFO - Batch 161/164 - Loss: 0.3313 - Avg batch time: 0.25s\n",
      "2025-06-05 18:25:12 - INFO - \n",
      "Epoch 32 training completed in 140.86s\n",
      "2025-06-05 18:25:12 - INFO - Average training loss: 0.4022\n",
      "Epochs:  33%|â–Ž| 33/100 [21:38<3:14:12, 173.91s/it, train_loss=0.4022, val_loss=0.4487, best_val_f1=0.6800, lr=3.00e-04, 2025-06-05 18:25:39 - INFO - \n",
      "Epoch 33/100 - Training phase\n",
      "2025-06-05 18:25:39 - INFO - Processing batch 1/164\n",
      "2025-06-05 18:25:39 - INFO - Batch shapes - x: torch.Size([1216, 3000]), edge_index: torch.Size([2, 21888]), y: torch.Size([64, 1])\n",
      "2025-06-05 18:25:40 - INFO - Batch 1/164 - Loss: 0.3262 - Avg batch time: 0.25s\n",
      "2025-06-05 18:25:48 - INFO - Processing batch 11/164\n",
      "2025-06-05 18:25:48 - INFO - Batch 11/164 - Loss: 0.2544 - Avg batch time: 0.25s\n",
      "2025-06-05 18:25:57 - INFO - Processing batch 21/164\n",
      "2025-06-05 18:25:57 - INFO - Batch 21/164 - Loss: 0.5445 - Avg batch time: 0.25s\n",
      "2025-06-05 18:26:06 - INFO - Processing batch 31/164\n",
      "2025-06-05 18:26:06 - INFO - Batch 31/164 - Loss: 0.2960 - Avg batch time: 0.25s\n",
      "2025-06-05 18:26:14 - INFO - Processing batch 41/164\n",
      "2025-06-05 18:26:14 - INFO - Batch 41/164 - Loss: 0.3682 - Avg batch time: 0.25s\n",
      "2025-06-05 18:26:22 - INFO - Processing batch 51/164\n",
      "2025-06-05 18:26:23 - INFO - Batch 51/164 - Loss: 0.3030 - Avg batch time: 0.25s\n",
      "2025-06-05 18:26:31 - INFO - Processing batch 61/164\n",
      "2025-06-05 18:26:31 - INFO - Batch 61/164 - Loss: 0.5483 - Avg batch time: 0.25s\n",
      "2025-06-05 18:26:39 - INFO - Processing batch 71/164\n",
      "2025-06-05 18:26:40 - INFO - Batch 71/164 - Loss: 0.3537 - Avg batch time: 0.25s\n",
      "2025-06-05 18:26:48 - INFO - Processing batch 81/164\n",
      "2025-06-05 18:26:48 - INFO - Batch 81/164 - Loss: 0.5415 - Avg batch time: 0.25s\n",
      "2025-06-05 18:26:56 - INFO - Processing batch 91/164\n",
      "2025-06-05 18:26:57 - INFO - Batch 91/164 - Loss: 0.4195 - Avg batch time: 0.25s\n",
      "2025-06-05 18:27:05 - INFO - Processing batch 101/164\n",
      "2025-06-05 18:27:05 - INFO - Batch 101/164 - Loss: 0.4323 - Avg batch time: 0.25s\n",
      "2025-06-05 18:27:13 - INFO - Processing batch 111/164\n",
      "2025-06-05 18:27:14 - INFO - Batch 111/164 - Loss: 0.3744 - Avg batch time: 0.25s\n",
      "2025-06-05 18:27:22 - INFO - Processing batch 121/164\n",
      "2025-06-05 18:27:22 - INFO - Batch 121/164 - Loss: 0.3711 - Avg batch time: 0.25s\n",
      "2025-06-05 18:27:30 - INFO - Processing batch 131/164\n",
      "2025-06-05 18:27:31 - INFO - Batch 131/164 - Loss: 0.3115 - Avg batch time: 0.25s\n",
      "2025-06-05 18:27:39 - INFO - Processing batch 141/164\n",
      "2025-06-05 18:27:39 - INFO - Batch 141/164 - Loss: 0.6468 - Avg batch time: 0.25s\n",
      "2025-06-05 18:27:47 - INFO - Processing batch 151/164\n",
      "2025-06-05 18:27:48 - INFO - Batch 151/164 - Loss: 0.2048 - Avg batch time: 0.25s\n",
      "2025-06-05 18:27:56 - INFO - Processing batch 161/164\n",
      "2025-06-05 18:27:56 - INFO - Batch 161/164 - Loss: 0.4131 - Avg batch time: 0.25s\n",
      "2025-06-05 18:27:58 - INFO - \n",
      "Epoch 33 training completed in 139.57s\n",
      "2025-06-05 18:27:58 - INFO - Average training loss: 0.3872\n",
      "Epochs:  34%|â–Ž| 34/100 [24:25<3:08:50, 171.67s/it, train_loss=0.3872, val_loss=0.4527, best_val_f1=0.6800, lr=3.00e-04, 2025-06-05 18:28:26 - INFO - \n",
      "Epoch 34/100 - Training phase\n",
      "2025-06-05 18:28:26 - INFO - Processing batch 1/164\n",
      "2025-06-05 18:28:26 - INFO - Batch shapes - x: torch.Size([1216, 3000]), edge_index: torch.Size([2, 21888]), y: torch.Size([64, 1])\n",
      "2025-06-05 18:28:27 - INFO - Batch 1/164 - Loss: 0.4238 - Avg batch time: 0.25s\n",
      "2025-06-05 18:28:35 - INFO - Processing batch 11/164\n",
      "2025-06-05 18:28:35 - INFO - Batch 11/164 - Loss: 0.4177 - Avg batch time: 0.25s\n",
      "2025-06-05 18:28:43 - INFO - Processing batch 21/164\n",
      "2025-06-05 18:28:44 - INFO - Batch 21/164 - Loss: 0.3835 - Avg batch time: 0.25s\n",
      "2025-06-05 18:28:52 - INFO - Processing batch 31/164\n",
      "2025-06-05 18:28:52 - INFO - Batch 31/164 - Loss: 0.2386 - Avg batch time: 0.25s\n",
      "2025-06-05 18:29:01 - INFO - Processing batch 41/164\n",
      "2025-06-05 18:29:01 - INFO - Batch 41/164 - Loss: 0.4492 - Avg batch time: 0.25s\n",
      "2025-06-05 18:29:09 - INFO - Processing batch 51/164\n",
      "2025-06-05 18:29:09 - INFO - Batch 51/164 - Loss: 0.3412 - Avg batch time: 0.25s\n",
      "2025-06-05 18:29:18 - INFO - Processing batch 61/164\n",
      "2025-06-05 18:29:18 - INFO - Batch 61/164 - Loss: 0.2741 - Avg batch time: 0.25s\n",
      "2025-06-05 18:29:26 - INFO - Processing batch 71/164\n",
      "2025-06-05 18:29:26 - INFO - Batch 71/164 - Loss: 0.2891 - Avg batch time: 0.25s\n",
      "2025-06-05 18:29:35 - INFO - Processing batch 81/164\n",
      "2025-06-05 18:29:35 - INFO - Batch 81/164 - Loss: 0.3322 - Avg batch time: 0.25s\n",
      "2025-06-05 18:29:43 - INFO - Processing batch 91/164\n",
      "2025-06-05 18:29:43 - INFO - Batch 91/164 - Loss: 0.5093 - Avg batch time: 0.25s\n",
      "2025-06-05 18:29:52 - INFO - Processing batch 101/164\n",
      "2025-06-05 18:29:52 - INFO - Batch 101/164 - Loss: 0.5001 - Avg batch time: 0.25s\n",
      "2025-06-05 18:30:00 - INFO - Processing batch 111/164\n",
      "2025-06-05 18:30:00 - INFO - Batch 111/164 - Loss: 0.3366 - Avg batch time: 0.25s\n",
      "2025-06-05 18:30:09 - INFO - Processing batch 121/164\n",
      "2025-06-05 18:30:09 - INFO - Batch 121/164 - Loss: 0.3744 - Avg batch time: 0.25s\n",
      "2025-06-05 18:30:17 - INFO - Processing batch 131/164\n",
      "2025-06-05 18:30:17 - INFO - Batch 131/164 - Loss: 0.4980 - Avg batch time: 0.25s\n",
      "2025-06-05 18:30:26 - INFO - Processing batch 141/164\n",
      "2025-06-05 18:30:26 - INFO - Batch 141/164 - Loss: 0.3800 - Avg batch time: 0.25s\n",
      "2025-06-05 18:30:34 - INFO - Processing batch 151/164\n",
      "2025-06-05 18:30:34 - INFO - Batch 151/164 - Loss: 0.2989 - Avg batch time: 0.25s\n",
      "2025-06-05 18:30:43 - INFO - Processing batch 161/164\n",
      "2025-06-05 18:30:43 - INFO - Batch 161/164 - Loss: 0.4526 - Avg batch time: 0.25s\n",
      "2025-06-05 18:30:45 - INFO - \n",
      "Epoch 34 training completed in 139.54s\n",
      "2025-06-05 18:30:45 - INFO - Average training loss: 0.3829\n",
      "Epochs:  35%|â–Ž| 35/100 [27:12<3:04:21, 170.18s/it, train_loss=0.3829, val_loss=0.4395, best_val_f1=0.6800, lr=3.00e-04, 2025-06-05 18:31:13 - INFO - \n",
      "Epoch 35/100 - Training phase\n",
      "2025-06-05 18:31:13 - INFO - Processing batch 1/164\n",
      "2025-06-05 18:31:13 - INFO - Batch shapes - x: torch.Size([1216, 3000]), edge_index: torch.Size([2, 21888]), y: torch.Size([64, 1])\n",
      "2025-06-05 18:31:13 - INFO - Batch 1/164 - Loss: 0.4046 - Avg batch time: 0.25s\n",
      "2025-06-05 18:31:22 - INFO - Processing batch 11/164\n",
      "2025-06-05 18:31:22 - INFO - Batch 11/164 - Loss: 0.3800 - Avg batch time: 0.25s\n",
      "2025-06-05 18:31:30 - INFO - Processing batch 21/164\n",
      "2025-06-05 18:31:31 - INFO - Batch 21/164 - Loss: 0.3288 - Avg batch time: 0.25s\n",
      "2025-06-05 18:31:39 - INFO - Processing batch 31/164\n",
      "2025-06-05 18:31:39 - INFO - Batch 31/164 - Loss: 0.3577 - Avg batch time: 0.25s\n",
      "2025-06-05 18:31:48 - INFO - Processing batch 41/164\n",
      "2025-06-05 18:31:48 - INFO - Batch 41/164 - Loss: 0.4784 - Avg batch time: 0.25s\n",
      "2025-06-05 18:31:57 - INFO - Processing batch 51/164\n",
      "2025-06-05 18:31:57 - INFO - Batch 51/164 - Loss: 0.3954 - Avg batch time: 0.25s\n",
      "2025-06-05 18:32:05 - INFO - Processing batch 61/164\n",
      "2025-06-05 18:32:05 - INFO - Batch 61/164 - Loss: 0.3209 - Avg batch time: 0.25s\n",
      "2025-06-05 18:32:14 - INFO - Processing batch 71/164\n",
      "2025-06-05 18:32:14 - INFO - Batch 71/164 - Loss: 0.3022 - Avg batch time: 0.25s\n",
      "2025-06-05 18:32:22 - INFO - Processing batch 81/164\n",
      "2025-06-05 18:32:22 - INFO - Batch 81/164 - Loss: 0.3354 - Avg batch time: 0.25s\n",
      "2025-06-05 18:32:31 - INFO - Processing batch 91/164\n",
      "2025-06-05 18:32:31 - INFO - Batch 91/164 - Loss: 0.4932 - Avg batch time: 0.25s\n",
      "2025-06-05 18:32:39 - INFO - Processing batch 101/164\n",
      "2025-06-05 18:32:39 - INFO - Batch 101/164 - Loss: 0.4471 - Avg batch time: 0.25s\n",
      "2025-06-05 18:32:48 - INFO - Processing batch 111/164\n",
      "2025-06-05 18:32:48 - INFO - Batch 111/164 - Loss: 0.3424 - Avg batch time: 0.25s\n",
      "2025-06-05 18:32:56 - INFO - Processing batch 121/164\n",
      "2025-06-05 18:32:56 - INFO - Batch 121/164 - Loss: 0.2123 - Avg batch time: 0.25s\n",
      "2025-06-05 18:33:05 - INFO - Processing batch 131/164\n",
      "2025-06-05 18:33:05 - INFO - Batch 131/164 - Loss: 0.3657 - Avg batch time: 0.25s\n",
      "2025-06-05 18:33:13 - INFO - Processing batch 141/164\n",
      "2025-06-05 18:33:13 - INFO - Batch 141/164 - Loss: 0.4214 - Avg batch time: 0.25s\n",
      "2025-06-05 18:33:21 - INFO - Processing batch 151/164\n",
      "2025-06-05 18:33:21 - INFO - Batch 151/164 - Loss: 0.2306 - Avg batch time: 0.25s\n",
      "2025-06-05 18:33:30 - INFO - Processing batch 161/164\n",
      "2025-06-05 18:33:30 - INFO - Batch 161/164 - Loss: 0.3214 - Avg batch time: 0.25s\n",
      "2025-06-05 18:33:32 - INFO - \n",
      "Epoch 35 training completed in 139.90s\n",
      "2025-06-05 18:33:32 - INFO - Average training loss: 0.3599\n",
      "Epochs:  36%|â–Ž| 36/100 [29:59<3:00:27, 169.18s/it, train_loss=0.3599, val_loss=0.4174, best_val_f1=0.6800, lr=3.00e-04, 2025-06-05 18:34:00 - INFO - \n",
      "Epoch 36/100 - Training phase\n",
      "2025-06-05 18:34:00 - INFO - Processing batch 1/164\n",
      "2025-06-05 18:34:00 - INFO - Batch shapes - x: torch.Size([1216, 3000]), edge_index: torch.Size([2, 21888]), y: torch.Size([64, 1])\n",
      "2025-06-05 18:34:00 - INFO - Batch 1/164 - Loss: 0.3880 - Avg batch time: 0.25s\n",
      "2025-06-05 18:34:09 - INFO - Processing batch 11/164\n",
      "2025-06-05 18:34:09 - INFO - Batch 11/164 - Loss: 0.2624 - Avg batch time: 0.25s\n",
      "2025-06-05 18:34:17 - INFO - Processing batch 21/164\n",
      "2025-06-05 18:34:17 - INFO - Batch 21/164 - Loss: 0.3440 - Avg batch time: 0.25s\n"
     ]
    }
   ],
   "source": [
    "%aimport\n",
    "from src.layers.cnn_lstm_gnn import LSTM_GNN_Model\n",
    "from src.utils.train import train_model\n",
    "\n",
    "SAVE_PATH = CHECKPOINT_ROOT / \"lstm_gnn_best_model.pt\"\n",
    "SUBMISSION_PATH = SUBMISSION_ROOT / \"lstm_gnn_submission.csv\"\n",
    "\n",
    "config = {\n",
    "    \"learning_rate\": 3e-4,\n",
    "    \"weight_decay\": 1e-5,\n",
    "    \"patience\": 20,\n",
    "    \"epochs\": 100,\n",
    "}\n",
    "\n",
    "# NOTE: model with default parameters\n",
    "model_older = LSTM_GNN_Model(\n",
    "    # Parameters for the CNN_BiLSTM_Encoder (temporal encoder)\n",
    "    cnn_dropout = 0.25,\n",
    "    lstm_hidden_dim = 64,\n",
    "    lstm_out_dim = 64,  # This will be the time_encoder_output_dim for the GCN\n",
    "    lstm_dropout = 0.25,\n",
    "    # Parameters for the EEGGCN (graph neural network)\n",
    "    gcn_hidden_channels = 64,\n",
    "    gcn_out_channels = 32,\n",
    "    num_gcn_layers = 3,\n",
    "    gcn_dropout = 0.5,\n",
    "    num_classes = 1,  # For binary classification (seizure/non-seizure)\n",
    "    num_channels = 19,  # Number of EEG channels\n",
    ")\n",
    "\n",
    "# build model with current parameters\n",
    "# Epochs:   6%| | 6/100 [13:36<4:17:46, 164.54s/it, train_loss=0.6508, val_loss=0.6166, best_val_f1=0.2840, lr=3.00e-04, b2025-06-05 13:20:42 - INFO - \n",
    "# Epochs:   7%| | 7/100 [16:24<4:17:02, 165.83s/it, train_loss=0.6446, val_loss=0.6258, best_val_f1=0.2840, lr=3.00e-04, b2025-06-05 13:23:30 - INFO - \n",
    "model_improved = LSTM_GNN_Model(\n",
    "    # Parameters for the CNN_BiLSTM_Encoder (temporal encoder)\n",
    "    cnn_dropout = 0.25,\n",
    "    lstm_hidden_dim = 96, # 96 original\n",
    "    lstm_out_dim = 96,  # This will be the time_encoder_output_dim for the GCN\n",
    "    lstm_dropout = 0.25,\n",
    "    # Parameters for the EEGGCN (graph neural network)\n",
    "    gcn_hidden_channels = 96,\n",
    "    gcn_out_channels = 64,\n",
    "    num_gcn_layers = 3,\n",
    "    gcn_dropout = 0.5,\n",
    "    num_classes = 1,  # For binary classification (seizure/non-seizure)\n",
    "    num_channels = 19,  # Number of EEG channels\n",
    ")\n",
    "\n",
    "\n",
    "# build model with current parameters\n",
    "# Epochs:   2%| | 2/100 [03:21<5:28:40, 201.23s/it, train_loss=0.7174, val_loss=0.5724, best_val_f1=0.0848, lr=3.00e-04, b2025-06-05 13:32:42 - INFO - \n",
    "# Epochs:   3%| | 3/100 [06:28<5:12:31, 193.31s/it, train_loss=0.6813, val_loss=0.5767, best_val_f1=0.1734, lr=3.00e-04, b2025-06-05 13:35:50 - INFO - \n",
    "# Epochs:   4%| | 4/100 [09:26<4:57:36, 186.00s/it, train_loss=0.6638, val_loss=0.6072, best_val_f1=0.1734, lr=3.00e-04, b2025-06-05 13:38:47 - INFO - \n",
    "# Epochs:   5%| | 5/100 [12:26<4:50:40, 183.58s/it, train_loss=0.6704, val_loss=0.5754, best_val_f1=0.2178, lr=3.00e-04, b2025-06-05 13:41:47 - INFO - \n",
    "# ...\n",
    "# Epochs:   7%| | 7/100 [19:21<5:10:58, 200.62s/it, train_loss=0.6333, val_loss=0.5949, best_val_f1=0.3921, lr=3.00e-04, b2025-06-05 13:48:43 - INFO - \n",
    "# Epochs:   8%| | 8/100 [23:11<5:22:14, 210.15s/it, train_loss=0.6261, val_loss=0.5993, best_val_f1=0.3921, lr=3.00e-04, b2025-06-05 13:52:33 - INFO - \n",
    "# Epochs:   9%| | 9/100 [26:35<5:15:33, 208.06s/it, train_loss=0.6043, val_loss=0.5743, best_val_f1=0.3921, lr=3.00e-04, b2025-06-05 13:55:56 - INFO - \n",
    "# ...\n",
    "# Epochs:  12%| | 12/100 [36:17<4:49:57, 197.70s/it, train_loss=0.5935, val_loss=0.5691, best_val_f1=0.5043, lr=3.00e-04, 2025-06-05 14:05:38 - INFO - \n",
    "# Epochs:  13%|â–| 13/100 [39:27<4:43:05, 195.24s/it, train_loss=0.5701, val_loss=0.5855, best_val_f1=0.5380, lr=3.00e-04, 2025-06-05 14:08:48 - INFO - \n",
    "# Epochs:  14%|â–| 14/100 [42:32<4:35:35, 192.27s/it, train_loss=0.5329, val_loss=0.6952, best_val_f1=0.5380, lr=3.00e-04, 2025-06-05 14:11:54 - INFO -\n",
    "# Epochs:  18%|â–| 18/100 [55:14<4:22:12, 191.86s/it, train_loss=0.5042, val_loss=0.5616, best_val_f1=0.5623, lr=3.00e-04, 2025-06-05 14:24:36 - INFO -\n",
    "# Epochs:  19%|â–| 19/100 [58:26<4:19:03, 191.89s/it, train_loss=0.5092, val_loss=0.4702, best_val_f1=0.6405, lr=3.00e-04, 2025-06-05 14:27:48 - INFO - \n",
    "# Epochs:  20%|â–| 20/100 [04:25<5:53:37, 265.22s/it, train_loss=0.5077, val_loss=0.4850, best_val_f1=0.6405, lr=3.00e-04, 2025-06-05 15:35:20 - INFO - \n",
    "# Epochs:  21%|â–| 21/100 [07:55<5:06:16, 232.62s/it, train_loss=0.4657, val_loss=0.4666, best_val_f1=0.6405, lr=3.00e-04, 2025-06-05 15:38:49 - INFO - \n",
    "# ...\n",
    "# Epochs:  23%|â–| 23/100 [16:40<5:02:39, 235.83s/it, train_loss=0.4786, val_loss=0.4441, best_val_f1=0.6405, lr=3.00e-04, 2025-06-05 15:24:57 - INFO -\n",
    "# Epochs:  24%|â–| 24/100 [18:00<4:20:53, 205.96s/it, train_loss=0.4688, val_loss=0.5586, best_val_f1=0.6405, lr=3.00e-04, 2025-06-05 15:48:55 - INFO - \n",
    "# Epochs:  25%|â–Ž| 25/100 [21:08<4:09:36, 199.69s/it, train_loss=0.4521, val_loss=0.4014, best_val_f1=0.6484, lr=3.00e-04, 2025-06-05 15:52:02 - INFO - \n",
    "# Epochs:  26%|â–Ž| 26/100 [24:09<3:58:50, 193.65s/it, train_loss=0.4378, val_loss=0.3937, best_val_f1=0.6800, lr=3.00e-04, 2025-06-05 15:55:04 - INFO - \n",
    "# ....\n",
    "#\n",
    "# Epochs:  31%|â–Ž| 31/100 [39:30<3:35:33, 187.44s/it, train_loss=0.4061, val_loss=0.4341, best_val_f1=0.6800, lr=3.00e-04, 2025-06-05 16:10:25 - INFO - \n",
    "#...\n",
    "# (other run)\n",
    "# Epochs:  32%|â–Ž| 32/100 [18:51<3:20:29, 176.90s/it, train_loss=0.3984, val_loss=0.4484, best_val_f1=0.6800, lr=3.00e-04, 2025-06-05 18:22:51 - INFO - \n",
    "# ...\n",
    "# Epochs:  35%|â–Ž| 35/100 [52:42<3:31:23, 195.13s/it, train_loss=0.3835, val_loss=0.4302, best_val_f1=0.6800, lr=3.00e-04, 2025-06-05 16:23:36 - INFO - \n",
    "model_improved_bigger = LSTM_GNN_Model(\n",
    "    # Parameters for the CNN_BiLSTM_Encoder (temporal encoder)\n",
    "    cnn_dropout = 0.25,\n",
    "    lstm_hidden_dim = 128, # 96 original\n",
    "    lstm_out_dim = 128,  # This will be the time_encoder_output_dim for the GCN\n",
    "    lstm_dropout = 0.25,\n",
    "    # Parameters for the EEGGCN (graph neural network)\n",
    "    gcn_hidden_channels = 128,\n",
    "    gcn_out_channels = 64,\n",
    "    num_gcn_layers = 3,\n",
    "    gcn_dropout = 0.5,\n",
    "    num_classes = 1,  # For binary classification (seizure/non-seizure)\n",
    "    num_channels = 19,  # Number of EEG channels\n",
    ")\n",
    "\n",
    "# select model to use\n",
    "model = model_improved_bigger\n",
    "\n",
    "model = model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=config[\"learning_rate\"], weight_decay=config[\"weight_decay\"])\n",
    "\n",
    "adjusted_pos_weight = torch.tensor([1.5], dtype=torch.float32).to(device)\n",
    "print(f'pos_weight:{adjusted_pos_weight}')\n",
    "loss = nn.BCEWithLogitsLoss(pos_weight=adjusted_pos_weight)\n",
    "\n",
    "# /home/ldibello/venvs/neuro/lib/python3.10/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.25 and num_layers=1\n",
    "\n",
    "# train model\n",
    "train_history, val_history = train_model(\n",
    "    wandb_config=None,\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    criterion=loss,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    num_epochs=config[\"epochs\"],\n",
    "    patience=config[\"patience\"],\n",
    "    save_path=SAVE_PATH,\n",
    "    use_gnn=True,\n",
    "    # hidden attribute\n",
    "    try_load_checkpoint=True,\n",
    "    log_wandb=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "63329a79",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m plot_training_loss\n\u001b[0;32m----> 3\u001b[0m plot_training_loss(\u001b[43mtrain_history\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m], val_history[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_history' is not defined"
     ]
    }
   ],
   "source": [
    "from src.utils.plot import plot_training_loss\n",
    "\n",
    "plot_training_loss(train_history[\"loss\"], val_history[\"loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "293bb297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš™ï¸ Evaluating model. Loading model from: .checkpoints/lstm_gnn_best_model.pt\n",
      "   - Loading checkpoint from: .checkpoints/lstm_gnn_best_model.pt\n",
      "   - Detected full checkpoint dictionary.\n",
      "   - Model state successfully loaded.\n",
      "ðŸ§ª Performing inference on the test set...\n",
      "BATCH: DataBatch(x=[1216, 3000], edge_index=[2, 21888], id=[64], batch=[1216], ptr=[65]), feature: tensor([[ 13.7818,  12.0088,  10.9369,  ...,  55.7613,  54.8321,  53.2772],\n",
      "        [ 17.4475,  12.0189,   8.5730,  ...,  25.5270,  23.5848,  20.9486],\n",
      "        [ -1.1044,  -2.4138,  -1.8681,  ...,  12.8679,  12.2525,  11.3361],\n",
      "        ...,\n",
      "        [  4.4002,  -1.2584,  -4.3083,  ..., -25.9106, -30.0391, -37.5544],\n",
      "        [ 26.8536,  24.6873,  23.8955,  ..., -17.1835, -21.8779, -27.2960],\n",
      "        [ 37.8393,  39.9656,  40.4172,  ..., -13.8870, -16.6136, -16.9901]])\n",
      "BATCH: DataBatch(x=[1216, 3000], edge_index=[2, 21888], id=[64], batch=[1216], ptr=[65]), feature: tensor([[-15.3751, -15.9740, -13.1877,  ...,  14.2007,  17.7176,  18.9752],\n",
      "        [-15.1118, -22.0024, -24.6107,  ..., -31.2303, -23.7167, -18.5535],\n",
      "        [-48.2384, -47.3045, -40.8518,  ..., -55.7094, -54.6654, -54.2824],\n",
      "        ...,\n",
      "        [-10.1833,  -8.0958,  -6.3664,  ...,   2.9009,   2.9213,   0.5675],\n",
      "        [-19.2513, -17.7443, -15.2040,  ...,  -0.7109,   0.4171,  -0.6318],\n",
      "        [-16.7416, -15.3205, -14.1273,  ...,   1.4004,   5.1552,   6.4765]])\n",
      "BATCH: DataBatch(x=[1216, 3000], edge_index=[2, 21888], id=[64], batch=[1216], ptr=[65]), feature: tensor([[-17.5601, -24.7429, -23.8394,  ...,  -5.9558,  -1.2985,   1.2526],\n",
      "        [-20.1962, -24.3221, -27.1088,  ...,   3.9662,   3.2620,   0.6461],\n",
      "        [ 10.9332,  12.3759,  11.8396,  ...,   2.0548,   1.8313,   5.4410],\n",
      "        ...,\n",
      "        [ 20.2303,  17.1818,  16.4179,  ...,  -2.8626,  -2.3164,  -1.5223],\n",
      "        [-47.1462, -47.5542, -47.1141,  ...,  26.9326,  28.1487,  29.7391],\n",
      "        [-23.1429, -22.9026, -22.6689,  ...,  39.4230,  41.3294,  43.5083]])\n",
      "BATCH: DataBatch(x=[1216, 3000], edge_index=[2, 21888], id=[64], batch=[1216], ptr=[65]), feature: tensor([[ 20.0648,   0.3884, -19.5247,  ...,  60.2155,  63.2063,  56.4372],\n",
      "        [-15.7369, -26.2935, -36.4932,  ..., -10.2490, -20.8118, -29.1580],\n",
      "        [ 38.4583,  35.2995,  32.0816,  ...,  -2.3830,  -6.5127,  -9.9188],\n",
      "        ...,\n",
      "        [ 34.9709,  33.7413,  33.3130,  ...,  19.6626,  21.1411,  20.7401],\n",
      "        [-26.2434, -27.3785, -27.0290,  ...,  47.6057,  43.7631,  40.7905],\n",
      "        [ 36.7117,  36.6134,  38.6052,  ...,  96.9737,  90.2067,  84.1035]])\n",
      "BATCH: DataBatch(x=[1216, 3000], edge_index=[2, 21888], id=[64], batch=[1216], ptr=[65]), feature: tensor([[  43.3637,   44.7238,   48.3575,  ...,   18.3549,   17.0198,\n",
      "           22.3151],\n",
      "        [  41.1865,   54.6340,   57.3282,  ..., -458.0980, -450.5905,\n",
      "         -446.1565],\n",
      "        [  41.2048,   43.1422,   47.7613,  ...,   50.6715,   47.0928,\n",
      "           46.6608],\n",
      "        ...,\n",
      "        [ -20.4481,  -22.9799,  -24.9577,  ...,    3.8245,    4.3363,\n",
      "            5.0084],\n",
      "        [   0.8187,    2.8980,    3.4496,  ...,    4.2356,    4.6990,\n",
      "            5.0378],\n",
      "        [  14.8853,   18.3976,   20.5481,  ...,    2.0021,    1.7554,\n",
      "            1.2539]])\n",
      "BATCH: DataBatch(x=[1216, 3000], edge_index=[2, 21888], id=[64], batch=[1216], ptr=[65]), feature: tensor([[ 6.1248,  7.3512,  7.7461,  ..., -2.6879, -3.7676, -4.5265],\n",
      "        [-1.0567,  0.7357,  1.4226,  ..., -5.0094, -5.9031, -6.3488],\n",
      "        [13.9702, 12.8054, 11.4575,  ..., -6.9265, -8.0731, -9.3117],\n",
      "        ...,\n",
      "        [ 1.3323,  1.3422,  0.6884,  ..., -1.5118,  0.5600,  2.7218],\n",
      "        [ 3.5061,  3.1946,  2.3408,  ...,  2.4960,  3.9453,  6.3486],\n",
      "        [ 1.3651,  0.9871,  0.8874,  ..., -2.2174, -3.5475, -4.0611]])\n",
      "BATCH: DataBatch(x=[1216, 3000], edge_index=[2, 21888], id=[64], batch=[1216], ptr=[65]), feature: tensor([[-7.8724e+00, -8.0412e+00, -7.0785e+00,  ...,  2.9284e+00,\n",
      "          2.6871e+00,  2.5629e+00],\n",
      "        [-7.7851e+00, -7.4436e+00, -6.1026e+00,  ...,  3.8708e+00,\n",
      "          3.7933e+00,  4.3744e+00],\n",
      "        [ 5.1103e+00,  2.7835e+00,  1.2963e+00,  ...,  1.2592e-01,\n",
      "          1.7761e-01, -6.7741e-01],\n",
      "        ...,\n",
      "        [-2.1990e-02, -2.1859e-02, -2.1721e-02,  ..., -2.2145e+01,\n",
      "         -1.7638e+01, -6.4047e+00],\n",
      "        [ 2.6143e-03,  2.6078e-03,  2.6006e-03,  ...,  5.1807e+00,\n",
      "          6.7172e+00,  7.7730e+00],\n",
      "        [ 1.9971e-02,  1.9888e-02,  1.9799e-02,  ...,  7.7799e+00,\n",
      "          1.1943e+01,  1.4335e+01]])\n",
      "BATCH: DataBatch(x=[1216, 3000], edge_index=[2, 21888], id=[64], batch=[1216], ptr=[65]), feature: tensor([[-11.8446, -19.4161, -23.1567,  ..., 101.4980, 113.3134, 115.2570],\n",
      "        [-42.5267, -51.2791, -53.1964,  ...,  47.1180,  59.2627,  78.4063],\n",
      "        [ 14.2151,  18.9020,  13.7124,  ...,  42.0482,  39.2880,  32.9436],\n",
      "        ...,\n",
      "        [  0.5016,  -1.7849,  -2.6356,  ...,  21.9537,  19.8480,  19.1060],\n",
      "        [ -4.4801,  -7.8305,  -9.4484,  ...,  -0.1201,   0.7990,   2.9581],\n",
      "        [-14.0638, -13.9502, -12.6662,  ..., -13.7269, -13.3187, -11.7541]])\n",
      "BATCH: DataBatch(x=[1216, 3000], edge_index=[2, 21888], id=[64], batch=[1216], ptr=[65]), feature: tensor([[ 25.6187,  22.8521,  13.1580,  ..., -11.0850, -12.8552, -12.8772],\n",
      "        [  9.9303,  13.8071,  14.0920,  ...,   2.7544,   6.7464,  13.3476],\n",
      "        [ 16.8178,  19.9968,  21.5713,  ...,   6.5426,   5.2701,   0.8171],\n",
      "        ...,\n",
      "        [ -7.6472,  -7.5910,  -7.2635,  ...,   6.1226,   4.6260,   2.2206],\n",
      "        [ -4.7605,  -4.4915,  -4.3872,  ...,  10.9165,  10.7582,  10.3559],\n",
      "        [  1.7602,   1.0093,   1.1553,  ...,  -2.9418,  -0.4402,   0.8923]])\n",
      "BATCH: DataBatch(x=[1216, 3000], edge_index=[2, 21888], id=[64], batch=[1216], ptr=[65]), feature: tensor([[  0.6853,  -1.2749,  -3.1045,  ...,   5.2428,   5.7166,   4.6043],\n",
      "        [-11.3701, -12.9082, -13.7424,  ...,   3.3313,   4.1589,   3.4658],\n",
      "        [ 14.9650,  13.4881,  11.7081,  ...,   4.0178,   3.3858,   1.1119],\n",
      "        ...,\n",
      "        [-38.3013, -37.9220, -37.1634,  ..., -46.2931, -47.8607, -49.4814],\n",
      "        [  4.9540,   4.5975,   4.3793,  ...,   5.3795,   5.5549,   5.6223],\n",
      "        [ 17.3796,  18.9531,  21.0001,  ...,  37.3023,  39.0455,  39.9931]])\n",
      "BATCH: DataBatch(x=[1216, 3000], edge_index=[2, 21888], id=[64], batch=[1216], ptr=[65]), feature: tensor([[-22.0372, -24.4611, -25.5835,  ...,  -8.4203,  -6.7188,  -5.0386],\n",
      "        [-74.6908, -74.9301, -75.5182,  ...,  -0.1508,   1.4287,   2.6992],\n",
      "        [ 12.2395,  12.5473,  13.2252,  ...,   2.9176,   3.3698,   3.8590],\n",
      "        ...,\n",
      "        [  5.5725,   6.4640,   7.3531,  ...,   1.5105,   1.6067,   2.0121],\n",
      "        [-10.2084,  -9.9696,  -9.8628,  ...,  -2.1976,  -2.0660,  -1.9274],\n",
      "        [-10.7317, -11.1054, -11.0075,  ...,  -2.0244,  -2.1602,  -3.5905]])\n",
      "BATCH: DataBatch(x=[1216, 3000], edge_index=[2, 21888], id=[64], batch=[1216], ptr=[65]), feature: tensor([[ 3.2228e+00,  1.1985e+00, -6.2408e-01,  ..., -5.8441e+00,\n",
      "         -5.7092e+00, -5.8473e+00],\n",
      "        [-6.0022e+00, -7.6527e+00, -8.2063e+00,  ..., -7.9983e+00,\n",
      "         -7.8780e+00, -7.9510e+00],\n",
      "        [ 1.9080e+00,  4.2426e-01, -9.1062e-01,  ..., -2.3698e-01,\n",
      "         -3.6628e-01, -1.1414e+00],\n",
      "        ...,\n",
      "        [ 7.3189e+01,  7.6012e+01,  7.1097e+01,  ..., -1.3069e+01,\n",
      "         -1.6303e+01, -1.5294e+01],\n",
      "        [ 3.3906e+02,  3.1914e+02,  2.9727e+02,  ...,  9.6584e+00,\n",
      "          1.2191e+01,  7.4849e+00],\n",
      "        [ 9.9916e+01,  8.2212e+01,  7.2244e+01,  ..., -5.9812e+00,\n",
      "         -1.2111e+00,  3.2444e+00]])\n",
      "BATCH: DataBatch(x=[1216, 3000], edge_index=[2, 21888], id=[64], batch=[1216], ptr=[65]), feature: tensor([[ 41.4459,  33.1453,  22.4574,  ...,   5.9966,   6.2686,   8.2730],\n",
      "        [ -6.4440,  -6.4214,  -2.7126,  ...,   0.6301,  -0.8955,  -2.5250],\n",
      "        [ 13.6708,  20.3189,  24.5560,  ..., -18.1477, -18.3427, -19.1964],\n",
      "        ...,\n",
      "        [  6.0361,   8.2208,   9.4903,  ..., -11.8934, -11.4025,  -9.5550],\n",
      "        [ 58.0808,  58.7551,  58.8435,  ...,   6.1701,   5.6528,   6.0191],\n",
      "        [ 18.2367,  16.6630,  17.1859,  ...,  11.0173,   9.5855,   8.8562]])\n",
      "BATCH: DataBatch(x=[1216, 3000], edge_index=[2, 21888], id=[64], batch=[1216], ptr=[65]), feature: tensor([[-15.6210, -13.5878, -12.0405,  ...,  -0.7873,  -2.5487,  -2.4265],\n",
      "        [ -8.3129,  -5.1657,  -3.7311,  ...,  -2.6946,  -2.5588,  -2.1429],\n",
      "        [-13.7036, -11.3302, -13.1857,  ...,  -3.4427,  -2.7525,  -1.8952],\n",
      "        ...,\n",
      "        [  0.3482,   0.2842,   0.1019,  ...,   0.8584,   0.4344,   0.0511],\n",
      "        [ -1.4542,  -1.9184,  -2.3500,  ...,   3.1418,   2.2268,   1.8724],\n",
      "        [ -1.9575,  -2.4187,  -2.9620,  ...,   4.9953,   4.9948,   5.5448]])\n",
      "BATCH: DataBatch(x=[1216, 3000], edge_index=[2, 21888], id=[64], batch=[1216], ptr=[65]), feature: tensor([[-12.9431, -13.1136, -12.7843,  ...,  -6.3535,  -6.7619,  -6.7067],\n",
      "        [-16.1435, -16.9329, -16.3552,  ..., -10.9890, -10.8727, -10.3193],\n",
      "        [  0.3369,   0.1745,   0.0864,  ...,  -4.7268,  -4.8622,  -5.3144],\n",
      "        ...,\n",
      "        [-22.8766, -23.7078, -24.4950,  ...,  41.1238,  37.2184,  33.2719],\n",
      "        [-15.7368, -15.8725, -16.2747,  ...,  -1.7019,  -2.2653,  -3.9651],\n",
      "        [ -3.8701,  -5.2311,  -6.5923,  ..., -34.9587, -35.2011, -35.4081]])\n",
      "BATCH: DataBatch(x=[1216, 3000], edge_index=[2, 21888], id=[64], batch=[1216], ptr=[65]), feature: tensor([[-3.3736e+01, -3.5723e+01, -3.7344e+01,  ...,  3.8804e+01,\n",
      "          3.8933e+01,  3.9354e+01],\n",
      "        [-3.4299e+01, -3.5294e+01, -3.5932e+01,  ...,  3.7439e+01,\n",
      "          3.5226e+01,  3.3166e+01],\n",
      "        [-1.6061e+01, -1.8000e+01, -2.0119e+01,  ...,  3.3718e+01,\n",
      "          3.4703e+01,  3.5448e+01],\n",
      "        ...,\n",
      "        [ 1.2163e+01,  1.4703e+01,  1.7132e+01,  ..., -1.4433e+01,\n",
      "         -1.5002e+01, -1.5951e+01],\n",
      "        [-1.5262e+00,  1.9153e-02,  1.4697e+00,  ..., -4.9926e-02,\n",
      "          5.3018e-01,  1.1556e+00],\n",
      "        [-1.1774e+01, -1.3343e+01, -1.4269e+01,  ...,  2.1315e+01,\n",
      "          2.1609e+01,  2.1438e+01]])\n",
      "BATCH: DataBatch(x=[1216, 3000], edge_index=[2, 21888], id=[64], batch=[1216], ptr=[65]), feature: tensor([[-12.3292, -11.7319,  -9.5587,  ...,  32.5510,  34.0092,  34.3536],\n",
      "        [-22.5897, -22.8600, -21.3172,  ...,  60.3616,  61.7441,  61.7236],\n",
      "        [ -5.9149,  -6.3811,  -5.5672,  ...,   9.2481,  12.4072,  14.3812],\n",
      "        ...,\n",
      "        [-32.3919, -31.9388, -31.5940,  ...,  -4.4505,  -3.3946,  -1.5704],\n",
      "        [  7.3582,   6.8011,   6.6227,  ..., -22.1830, -23.1735, -23.5026],\n",
      "        [ 29.7885,  28.9114,  27.9733,  ...,  -0.4664,  -1.7898,  -3.9555]])\n",
      "BATCH: DataBatch(x=[1216, 3000], edge_index=[2, 21888], id=[64], batch=[1216], ptr=[65]), feature: tensor([[  9.9984,  10.7856,  11.4212,  ...,   5.0519,   8.3906,  11.0457],\n",
      "        [ 21.4846,  21.7229,  21.1373,  ...,  -2.3461,  -1.1700,   0.5896],\n",
      "        [-10.5309,  -8.7684,  -7.1937,  ...,   9.0861,  13.0345,  16.2671],\n",
      "        ...,\n",
      "        [ -6.1736,  -5.6893,  -4.8545,  ...,  15.8254,  14.8659,  13.1523],\n",
      "        [ -1.3262,  -0.8048,  -0.4194,  ...,  24.2147,  21.8233,  19.2496],\n",
      "        [ 10.2553,  10.9477,  10.2689,  ...,  12.1650,   8.6201,   6.6889]])\n",
      "BATCH: DataBatch(x=[1216, 3000], edge_index=[2, 21888], id=[64], batch=[1216], ptr=[65]), feature: tensor([[ -9.1154,  -8.7558,  -8.5245,  ..., -14.4497, -15.0230, -15.8969],\n",
      "        [ -7.8439,  -6.8796,  -5.5980,  ..., -12.2706, -12.5910, -12.6900],\n",
      "        [  1.4697,  -0.6091,  -2.9198,  ...,  -8.8417,  -9.1716,  -9.3831],\n",
      "        ...,\n",
      "        [  0.2887,  -0.3286,  -0.8443,  ...,   1.8072,  -0.8061,  -3.1313],\n",
      "        [  0.2034,   2.0053,   3.3495,  ...,  -6.0637,  -8.9377, -12.0133],\n",
      "        [ -2.7499,  -1.0522,  -0.2962,  ...,  -3.7222,  -5.1434,  -7.2547]])\n",
      "BATCH: DataBatch(x=[1216, 3000], edge_index=[2, 21888], id=[64], batch=[1216], ptr=[65]), feature: tensor([[  1.0614,   2.0891,   3.7980,  ...,  17.9942,  18.2185,  18.3257],\n",
      "        [  0.9210,   2.2109,   2.6468,  ...,  17.7512,  18.9201,  20.0823],\n",
      "        [  2.9436,   2.2676,   1.6776,  ...,  -0.4595,  -1.4662,  -2.0805],\n",
      "        ...,\n",
      "        [ -6.0204,  -7.0100,  -7.8143,  ...,  -2.5549,  -4.0302,  -5.6089],\n",
      "        [-12.7263, -13.4451, -13.8884,  ...,   1.0709,  -0.8856,  -2.2091],\n",
      "        [ -3.6914,  -3.9885,  -3.5690,  ...,  11.6944,  11.0546,  11.9310]])\n",
      "BATCH: DataBatch(x=[1216, 3000], edge_index=[2, 21888], id=[64], batch=[1216], ptr=[65]), feature: tensor([[ -9.4200, -12.1548, -10.9995,  ..., -20.1036, -19.4624, -18.6717],\n",
      "        [ -4.5091,  -2.2332,  -0.2080,  ..., -13.3732, -13.4323, -14.9079],\n",
      "        [  8.9355,   7.4388,   5.6685,  ...,   9.6893,   7.6544,   4.9023],\n",
      "        ...,\n",
      "        [ 11.3993,  11.7533,  11.2096,  ...,  -2.6234,  -0.8058,   0.9513],\n",
      "        [ -2.6509,  -1.3314,   0.0248,  ..., -15.0764, -13.5338, -11.8007],\n",
      "        [ -1.5682,   0.7759,   2.5942,  ...,  -7.8159,  -7.5223,  -6.0938]])\n",
      "BATCH: DataBatch(x=[1216, 3000], edge_index=[2, 21888], id=[64], batch=[1216], ptr=[65]), feature: tensor([[  12.3379,    8.2334,    6.7470,  ...,    9.0353,    7.3713,\n",
      "            6.8198],\n",
      "        [   6.7654,    7.3502,    7.9486,  ...,   35.3161,   34.0328,\n",
      "           30.4360],\n",
      "        [   9.4394,   10.6982,   12.1471,  ...,   -2.3879,   -4.2816,\n",
      "           -5.2655],\n",
      "        ...,\n",
      "        [  21.9270,   14.8171,    8.4160,  ...,   -9.8059,  -10.2613,\n",
      "          -10.7059],\n",
      "        [  26.6656,   24.6604,   22.0521,  ...,   11.6378,   12.0447,\n",
      "           11.3501],\n",
      "        [  11.0132,    8.9378,   11.3000,  ..., -100.2861, -106.4092,\n",
      "         -107.2032]])\n",
      "BATCH: DataBatch(x=[1216, 3000], edge_index=[2, 21888], id=[64], batch=[1216], ptr=[65]), feature: tensor([[-17.6181, -17.1316, -15.7791,  ...,  -6.7720, -10.2848, -12.1114],\n",
      "        [-21.5288, -19.6325, -17.6519,  ...,  11.8711,  10.2520,   8.4891],\n",
      "        [  8.7518,  10.1817,   7.4278,  ..., -21.4479, -23.0469, -24.0434],\n",
      "        ...,\n",
      "        [  4.1711,   3.6364,   3.1422,  ...,  -6.9456,  -6.7804,  -6.8728],\n",
      "        [  2.2859,   2.8642,   3.3001,  ...,   0.5062,   0.4589,   0.3276],\n",
      "        [-55.2761, -51.2001, -50.6931,  ...,  32.1772,  30.5479,  28.6505]])\n",
      "BATCH: DataBatch(x=[1216, 3000], edge_index=[2, 21888], id=[64], batch=[1216], ptr=[65]), feature: tensor([[-16.1721, -17.6871, -19.3279,  ...,  -4.6289,  -4.7555,  -4.7332],\n",
      "        [-14.8135, -15.4684, -15.9717,  ...,  -4.3703,  -4.0391,  -3.8764],\n",
      "        [ -3.2101,  -3.5305,  -4.2760,  ...,  -2.3538,  -2.9061,  -2.9568],\n",
      "        ...,\n",
      "        [ 15.5258,  15.7482,  16.3407,  ...,   2.6656,   4.7897,   6.6912],\n",
      "        [  0.4045,   0.6218,   0.6091,  ...,   9.7511,   9.5426,   9.2984],\n",
      "        [ -8.8212,  -9.3998, -10.8316,  ...,   6.4295,   3.2682,   0.5357]])\n",
      "BATCH: DataBatch(x=[1216, 3000], edge_index=[2, 21888], id=[64], batch=[1216], ptr=[65]), feature: tensor([[ -8.5214,  -8.0536,  -8.4454,  ..., -24.6142, -30.4154, -34.0535],\n",
      "        [-13.9902, -12.1200,  -9.1277,  ..., -25.6612, -28.9393, -32.9959],\n",
      "        [  9.3779,   9.5979,   9.3006,  ...,   3.8820,   5.5373,   7.0974],\n",
      "        ...,\n",
      "        [-10.3672,  -9.5842, -10.5262,  ..., -24.5014, -23.5315, -23.1077],\n",
      "        [ 23.6779,  24.3058,  22.5927,  ..., -12.0375, -12.0150, -12.5102],\n",
      "        [ 30.7070,  28.8308,  26.3846,  ...,   4.9649,   4.7592,   5.0525]])\n",
      "BATCH: DataBatch(x=[1216, 3000], edge_index=[2, 21888], id=[64], batch=[1216], ptr=[65]), feature: tensor([[  6.0621,   6.2956,   6.6344,  ..., -41.7267, -40.6643, -39.9417],\n",
      "        [-40.0401, -38.4849, -36.4719,  ..., -28.9073, -27.1211, -25.5710],\n",
      "        [  4.4618,   1.7680,  -1.0302,  ..., -47.1362, -47.5312, -48.1769],\n",
      "        ...,\n",
      "        [ -2.5946,  -3.0138,  -3.9751,  ...,   2.2230,   2.5319,   0.7903],\n",
      "        [ -0.5954,   0.2064,   0.6251,  ...,   4.9559,   5.8074,   6.1479],\n",
      "        [ -0.1285,   1.0240,   2.6070,  ...,   1.5819,   2.3774,   3.4748]])\n",
      "BATCH: DataBatch(x=[1216, 3000], edge_index=[2, 21888], id=[64], batch=[1216], ptr=[65]), feature: tensor([[-10.4517, -15.5519, -14.0357,  ...,  -5.4586,  -1.9067,  -2.3756],\n",
      "        [ -7.0560,  -6.5026,  -1.0498,  ..., -11.8526,  -7.5748,  -5.9301],\n",
      "        [ -5.7924,  -8.4043,  -7.6975,  ...,   4.6820,   5.9468,   5.9531],\n",
      "        ...,\n",
      "        [ -2.0371,  -3.0740,  -4.4177,  ...,  -4.0863,  -8.9844, -11.9533],\n",
      "        [  6.7117,   8.2966,   9.9828,  ...,   0.4140,  -1.3616,  -1.9238],\n",
      "        [  8.0603,  10.2702,  12.5870,  ...,   6.5056,   6.0220,   4.3566]])\n",
      "BATCH: DataBatch(x=[1216, 3000], edge_index=[2, 21888], id=[64], batch=[1216], ptr=[65]), feature: tensor([[-10.7500, -14.6738, -21.2273,  ..., -21.0420, -26.0004, -29.4369],\n",
      "        [-30.9354, -30.0858, -27.0280,  ..., -24.2032, -27.8823, -34.2052],\n",
      "        [ -1.6634,  -2.5993,  -4.1859,  ...,  -4.8386,  -3.0087,  -2.6014],\n",
      "        ...,\n",
      "        [  4.0043,   3.4193,   2.6841,  ...,  -0.1570,  -0.6696,  -0.3420],\n",
      "        [ -4.0414,  -4.3416,  -4.7843,  ...,  -5.7490,  -6.6904,  -6.7568],\n",
      "        [ -6.0756,  -5.9347,  -5.8992,  ...,  -6.9246,  -7.2706,  -7.8654]])\n",
      "BATCH: DataBatch(x=[1216, 3000], edge_index=[2, 21888], id=[64], batch=[1216], ptr=[65]), feature: tensor([[ 6.0274,  7.4799,  8.2367,  ..., -1.1682, -1.5102, -1.4699],\n",
      "        [ 5.6121,  6.6898,  7.0701,  ..., -1.3423, -1.5179, -1.5802],\n",
      "        [ 1.8108,  3.1076,  4.1488,  ...,  0.4844,  0.4466,  0.4801],\n",
      "        ...,\n",
      "        [ 1.0423,  1.1249,  1.4995,  ..., -0.4805, -0.0249,  0.2185],\n",
      "        [-1.6059, -0.8982, -0.2369,  ...,  2.0601,  2.8630,  3.6124],\n",
      "        [-2.9104, -2.8666, -2.1581,  ...,  3.8462,  4.0154,  4.4987]])\n",
      "BATCH: DataBatch(x=[1216, 3000], edge_index=[2, 21888], id=[64], batch=[1216], ptr=[65]), feature: tensor([[-0.8729, -1.9250, -2.3533,  ...,  3.6564,  3.0560,  3.1752],\n",
      "        [-3.4877, -3.9770, -4.4119,  ...,  6.3397,  5.5382,  5.1522],\n",
      "        [ 6.8543,  6.4071,  5.4534,  ...,  2.8273,  2.3267,  2.0061],\n",
      "        ...,\n",
      "        [ 5.6488,  8.5378, 11.5778,  ..., 16.7501, 19.8542, 22.9055],\n",
      "        [ 0.0543,  0.0908,  0.7418,  ..., 11.9964, 12.7185, 13.9302],\n",
      "        [-6.7715, -7.5044, -7.8375,  ..., -6.3045, -6.9238, -7.1751]])\n",
      "BATCH: DataBatch(x=[1216, 3000], edge_index=[2, 21888], id=[64], batch=[1216], ptr=[65]), feature: tensor([[  3.3883,   0.4972,  -3.6290,  ...,  29.7391,  28.4208,  27.8293],\n",
      "        [  8.1944,   3.9978,  -2.0546,  ...,  18.9797,  16.6425,  13.3604],\n",
      "        [ 18.4740,  20.1436,  21.1122,  ...,  33.2971,  33.2259,  31.9837],\n",
      "        ...,\n",
      "        [  1.3963,  -1.2790,  -3.4833,  ...,   7.8588,   8.0932,   8.8132],\n",
      "        [ -3.5414,  -4.4802,  -5.0482,  ...,  -4.8629,  -4.0646,  -2.5472],\n",
      "        [-14.8032, -13.7347, -12.7556,  ..., -26.4215, -25.6992, -24.1817]])\n",
      "BATCH: DataBatch(x=[1216, 3000], edge_index=[2, 21888], id=[64], batch=[1216], ptr=[65]), feature: tensor([[ 8.4715e+00,  6.6399e+00,  1.2519e+00,  ...,  1.8699e+01,\n",
      "          1.9603e+01,  1.8074e+01],\n",
      "        [ 2.5937e+01,  2.6414e+01,  2.4902e+01,  ..., -2.5298e+00,\n",
      "         -3.3360e+00, -4.8819e+00],\n",
      "        [ 3.8435e+00,  2.9506e+00,  7.6624e-01,  ...,  2.7447e+01,\n",
      "          2.7728e+01,  2.7280e+01],\n",
      "        ...,\n",
      "        [-3.0519e+00, -1.9274e+00, -1.1773e+00,  ...,  8.1097e-01,\n",
      "          1.4402e-02, -3.0324e-01],\n",
      "        [-7.9466e-01,  4.3905e-01,  1.0855e+00,  ...,  2.6747e+00,\n",
      "          1.5511e+00,  5.1938e-01],\n",
      "        [-1.6075e+00, -9.3297e-01, -7.6211e-01,  ...,  1.5131e+00,\n",
      "          3.8420e-01, -6.4241e-01]])\n",
      "BATCH: DataBatch(x=[1216, 3000], edge_index=[2, 21888], id=[64], batch=[1216], ptr=[65]), feature: tensor([[ -9.3122,  -7.1352,  -5.0636,  ...,  13.4692,  11.2665,   8.9032],\n",
      "        [-17.3363, -15.0324, -12.9933,  ...,  18.6995,  17.2080,  16.5819],\n",
      "        [  5.8422,   6.1415,   5.5727,  ...,   0.7678,  -0.4233,  -2.6313],\n",
      "        ...,\n",
      "        [  0.5939,  11.3057,  11.8371,  ...,   0.5929,   0.7648,   6.1298],\n",
      "        [  2.1681,  10.6576,  10.6591,  ...,  -6.0054,  -6.0568,   0.2985],\n",
      "        [ -3.0040,   3.2664,   2.9140,  ...,  -4.7266,  -5.4659,   1.5774]])\n",
      "BATCH: DataBatch(x=[1216, 3000], edge_index=[2, 21888], id=[64], batch=[1216], ptr=[65]), feature: tensor([[ 23.9585,  10.7132, -11.5740,  ...,   2.3399,  -0.3487,  -2.9237],\n",
      "        [ 19.1539,  13.3294,  -2.5510,  ...,  12.8463,   9.9558,   6.8056],\n",
      "        [ 14.8948,   3.3793, -15.2206,  ...,   2.0277,   0.6680,  -3.8844],\n",
      "        ...,\n",
      "        [ -1.8086,  -4.5742,  -6.6884,  ...,   7.6075,   7.4178,   6.7841],\n",
      "        [ -2.8238,  -4.5712,  -5.8386,  ...,   5.9189,   5.7874,   5.2218],\n",
      "        [ -2.4330,  -2.7751,  -2.9631,  ...,   2.4881,   1.8423,   1.3913]])\n",
      "BATCH: DataBatch(x=[1216, 3000], edge_index=[2, 21888], id=[64], batch=[1216], ptr=[65]), feature: tensor([[  0.5488,  -0.8977,  -2.3187,  ...,  10.4517,   9.2697,   7.6350],\n",
      "        [  1.3852,   0.5055,  -0.2831,  ...,   6.7389,   6.1563,   5.1712],\n",
      "        [  3.3978,   1.7139,  -0.1754,  ...,  10.5309,   9.3112,   7.4661],\n",
      "        ...,\n",
      "        [ 10.5441,   7.9259,   4.0274,  ...,  30.2292,  37.6315,  34.5014],\n",
      "        [ -0.7780,  -1.8135,  -3.8886,  ...,  19.6302,  18.3498,  18.0183],\n",
      "        [-10.3581,  -8.4533,  -6.9350,  ...,  -2.1338,  -4.6384,  -1.0032]])\n",
      "BATCH: DataBatch(x=[1216, 3000], edge_index=[2, 21888], id=[64], batch=[1216], ptr=[65]), feature: tensor([[ 2.8549,  2.9860,  3.1638,  ...,  6.2767,  4.3790,  1.9846],\n",
      "        [ 6.0347,  5.3807,  4.5727,  ..., 11.2486,  9.4845,  6.8513],\n",
      "        [-5.9278, -5.1434, -4.0518,  ...,  0.8019, -0.0475, -1.4308],\n",
      "        ...,\n",
      "        [-2.9631, -3.0534, -2.7846,  ...,  2.7482,  2.4334,  2.0460],\n",
      "        [-0.6921,  0.0764,  0.5601,  ...,  5.3297,  7.0870,  8.5416],\n",
      "        [-0.9692, -1.1523, -1.4025,  ...,  2.9661,  5.1515,  6.6856]])\n",
      "BATCH: DataBatch(x=[1216, 3000], edge_index=[2, 21888], id=[64], batch=[1216], ptr=[65]), feature: tensor([[  6.9424,   2.7244,  -2.0109,  ...,   9.4103,   8.4905,   7.5212],\n",
      "        [  4.6686,   1.8246,  -0.8720,  ...,  13.9499,  14.2898,  14.0775],\n",
      "        [  2.0749,   0.8835,  -1.2527,  ..., -21.3525, -21.8961, -21.8031],\n",
      "        ...,\n",
      "        [ 12.4007,  10.1110,   9.1161,  ..., -11.8778, -13.4627, -14.7777],\n",
      "        [ 21.3332,  15.0341,  10.6612,  ..., -10.1064, -12.5188, -14.5779],\n",
      "        [  5.2405,   0.7632,  -1.7440,  ...,   1.2814,  -0.2825,  -1.4121]])\n",
      "BATCH: DataBatch(x=[1216, 3000], edge_index=[2, 21888], id=[64], batch=[1216], ptr=[65]), feature: tensor([[  5.4805,   6.4991,   7.8821,  ..., -15.3930, -18.3958, -21.1830],\n",
      "        [ -2.4724,  -2.8312,  -1.1988,  ..., -15.5350, -18.1172, -21.1926],\n",
      "        [ -6.4619,  -6.9040,  -6.5157,  ...,  -9.1694,  -7.2119,  -5.7309],\n",
      "        ...,\n",
      "        [  0.9142,   0.1772,  -0.1289,  ...,   2.7913,   0.5092,  -1.8904],\n",
      "        [  2.2215,   1.7094,   1.0857,  ...,   2.7778,  -0.7394,  -4.0413],\n",
      "        [  1.4988,   1.5027,   1.3045,  ...,   0.2221,  -1.9514,  -3.4081]])\n",
      "BATCH: DataBatch(x=[1216, 3000], edge_index=[2, 21888], id=[64], batch=[1216], ptr=[65]), feature: tensor([[  2.2340,   0.0484,  -1.8803,  ...,  -1.5669,  -1.8253,  -1.6056],\n",
      "        [  2.7515,   0.8245,  -1.3270,  ...,  -2.2708,  -2.7685,  -2.8900],\n",
      "        [ -5.0703,  -6.4208,  -6.8723,  ...,  -0.3310,  -0.2140,   0.2399],\n",
      "        ...,\n",
      "        [-40.7002, -38.0809, -37.0698,  ...,   4.1214,   2.1689,   0.8474],\n",
      "        [-38.8631, -37.2034, -35.9529,  ...,  -3.5095,  -6.0328,  -7.9198],\n",
      "        [ -6.8349,  -6.4156,  -4.9592,  ..., -10.6504,  -9.7710,  -7.7946]])\n",
      "BATCH: DataBatch(x=[1216, 3000], edge_index=[2, 21888], id=[64], batch=[1216], ptr=[65]), feature: tensor([[ 15.3869,  15.5248,  15.0180,  ...,  -2.7670,  -3.0302,  -1.8069],\n",
      "        [  0.3850,   7.9892,  15.9319,  ...,  26.0320,  17.7672,  12.9677],\n",
      "        [ -3.0692,  -5.1138,  -7.1497,  ...,  18.8115,  26.4746,  30.7487],\n",
      "        ...,\n",
      "        [  9.4340,   9.5250,   9.8238,  ...,  -1.2104,  -0.6704,   2.9957],\n",
      "        [ -2.7323,  -2.2529,  -2.1452,  ...,  -1.5260,  -0.8555,  -1.2736],\n",
      "        [-12.6902, -11.4896, -10.5997,  ...,   7.6464,   6.8639,   1.5644]])\n",
      "BATCH: DataBatch(x=[1216, 3000], edge_index=[2, 21888], id=[64], batch=[1216], ptr=[65]), feature: tensor([[   4.3972,    3.8496,    3.3381,  ...,    2.2067,    2.4540,\n",
      "            2.9378],\n",
      "        [   2.5510,    2.4870,    2.1997,  ...,    4.9974,    5.1069,\n",
      "            5.0891],\n",
      "        [  -2.6653,   -2.7485,   -2.3184,  ...,    3.0374,    3.1973,\n",
      "            3.3046],\n",
      "        ...,\n",
      "        [ -54.1540,   87.2777,  157.5813,  ...,  125.9491,  -50.3839,\n",
      "         -114.0607],\n",
      "        [ -39.1994,   98.6522,  167.4169,  ...,  130.6258,  -46.5653,\n",
      "         -110.7320],\n",
      "        [ -25.6081,  108.4068,  177.3293,  ...,  127.5048,  -51.2403,\n",
      "         -115.7026]])\n",
      "BATCH: DataBatch(x=[1216, 3000], edge_index=[2, 21888], id=[64], batch=[1216], ptr=[65]), feature: tensor([[ 26.7158, 265.4986, 381.8437,  ..., 227.5425, 364.2415, 285.1136],\n",
      "        [  6.4397, 231.6322, 339.8583,  ..., 222.8810, 376.3467, 302.9964],\n",
      "        [ 35.3010, 280.5708, 400.9444,  ..., 232.6276, 372.0609, 283.6110],\n",
      "        ...,\n",
      "        [  1.3418,   1.3645,   2.3470,  ...,   6.1728,   6.9191,   7.3904],\n",
      "        [ -5.5215,  -5.3827,  -4.6701,  ...,   4.0058,   5.2494,   6.3178],\n",
      "        [ -7.0903,  -7.1791,  -7.2200,  ...,   7.2044,   9.0760,  10.3453]])\n",
      "BATCH: DataBatch(x=[1216, 3000], edge_index=[2, 21888], id=[64], batch=[1216], ptr=[65]), feature: tensor([[ 1.0395e+01,  1.1138e+01,  1.1201e+01,  ..., -1.7003e+01,\n",
      "         -1.7572e+01, -1.8263e+01],\n",
      "        [-1.1984e+00,  3.4470e-01,  3.0370e+00,  ..., -1.2445e+01,\n",
      "         -1.2520e+01, -1.4740e+01],\n",
      "        [ 1.2635e+01,  1.2234e+01,  1.1673e+01,  ..., -9.2849e+00,\n",
      "         -9.6960e+00, -1.0197e+01],\n",
      "        ...,\n",
      "        [-5.6555e+00, -4.6810e+00, -3.5064e+00,  ..., -1.0886e-02,\n",
      "          2.7417e+00,  3.3356e+00],\n",
      "        [-1.4364e-01,  3.5057e-01,  8.2429e-01,  ..., -3.5118e+00,\n",
      "         -4.0436e+00, -4.1149e+00],\n",
      "        [ 6.7055e-01,  3.6319e-01,  4.5761e-01,  ..., -3.3496e+00,\n",
      "         -5.2864e+00, -6.3874e+00]])\n",
      "BATCH: DataBatch(x=[1216, 3000], edge_index=[2, 21888], id=[64], batch=[1216], ptr=[65]), feature: tensor([[ -1.7292,  -3.1297,  -4.2992,  ...,   0.5894,   1.7452,   2.4364],\n",
      "        [  5.6106,  -5.8856, -13.2835,  ...,   2.9986,   5.7773,   5.0929],\n",
      "        [ -6.2679,  -6.7320,  -6.6840,  ...,  -1.4768,  -0.9755,  -0.0715],\n",
      "        ...,\n",
      "        [  6.8806,   6.9056,   6.6463,  ...,   6.2484,   5.9710,   5.6515],\n",
      "        [  6.8600,   8.4537,   9.4251,  ...,   4.8495,   4.8749,   4.6291],\n",
      "        [  5.4203,   7.3140,   8.9284,  ...,   1.0865,   1.8324,   1.9987]])\n",
      "BATCH: DataBatch(x=[1216, 3000], edge_index=[2, 21888], id=[64], batch=[1216], ptr=[65]), feature: tensor([[  5.3043,   5.3658,   4.2995,  ..., -17.1548, -18.7924, -19.8465],\n",
      "        [  4.4197,   5.1916,   6.3508,  ..., -17.9360, -19.9587, -20.6461],\n",
      "        [  5.4297,   5.2423,   4.6745,  ...,  -9.9558,  -9.8789,  -9.8443],\n",
      "        ...,\n",
      "        [  0.1212,  -1.7747,  -3.1934,  ...,  -5.4182,  -4.6044,  -3.8398],\n",
      "        [ -1.8860,  -3.3698,  -4.3848,  ...,  -2.9841,  -2.5711,  -2.4196],\n",
      "        [ -3.6379,  -4.0033,  -4.0434,  ...,   0.6006,   0.0579,  -0.4729]])\n",
      "BATCH: DataBatch(x=[1216, 3000], edge_index=[2, 21888], id=[64], batch=[1216], ptr=[65]), feature: tensor([[-0.1326,  0.3688,  1.4190,  ..., -0.4254, -0.3292,  1.9423],\n",
      "        [-0.9588, -2.5112, -3.3047,  ...,  3.1778,  2.7709,  1.7675],\n",
      "        [ 4.9585,  5.1635,  5.4202,  ...,  0.0176, -0.6324, -0.8582],\n",
      "        ...,\n",
      "        [-3.4179, -3.2320, -3.3178,  ...,  0.2269, -0.3826, -1.1068],\n",
      "        [-0.3312, -0.5701, -1.4581,  ..., 14.1232, 14.2169, 14.2997],\n",
      "        [ 2.5224,  1.4236,  0.3088,  ..., 13.5885, 14.3961, 15.0128]])\n",
      "BATCH: DataBatch(x=[1216, 3000], edge_index=[2, 21888], id=[64], batch=[1216], ptr=[65]), feature: tensor([[ 4.3622,  4.6123,  4.5340,  ..., 10.6489, 11.0605,  9.7798],\n",
      "        [ 3.1103,  3.2800,  3.5552,  ..., 14.2094, 15.0575, 13.1960],\n",
      "        [ 5.1218,  4.6656,  4.3085,  ...,  5.0607,  5.1890,  5.2755],\n",
      "        ...,\n",
      "        [ 3.3028,  5.2249,  7.2186,  ...,  6.6433,  7.5286,  7.5145],\n",
      "        [ 5.1838,  6.5212,  7.8608,  ...,  0.5077,  1.9413,  2.7843],\n",
      "        [-0.7384, -1.6943, -2.5365,  ...,  0.2395,  0.4028,  0.9575]])\n",
      "BATCH: DataBatch(x=[1216, 3000], edge_index=[2, 21888], id=[64], batch=[1216], ptr=[65]), feature: tensor([[  6.7418,   7.4550,   8.3292,  ...,   2.6074,   1.8781,   0.7634],\n",
      "        [  1.5424,   0.0663,  -0.6036,  ...,   0.6243,  -0.0280,  -1.3092],\n",
      "        [  5.6008,   6.7331,   8.1407,  ...,   3.5671,   3.6470,   3.2729],\n",
      "        ...,\n",
      "        [-16.3104, -15.8940, -14.6425,  ..., -22.4434, -21.3838, -20.7722],\n",
      "        [ -2.0843,  -1.5947,  -1.1245,  ...,  -6.0850,  -5.5044,  -5.0208],\n",
      "        [ -5.9710,  -6.0186,  -6.2029,  ...,  -2.7955,  -3.1710,  -3.3325]])\n",
      "BATCH: DataBatch(x=[1216, 3000], edge_index=[2, 21888], id=[64], batch=[1216], ptr=[65]), feature: tensor([[-6.2506, -6.2765, -6.0195,  ..., 10.3752, 12.3661, 13.7422],\n",
      "        [ 8.2422,  7.5364,  6.5467,  ...,  2.4025,  5.2811,  7.2272],\n",
      "        [-8.2727, -6.8697, -5.4119,  ..., 32.1389, 31.2935, 31.4046],\n",
      "        ...,\n",
      "        [12.3885, 12.8111, 12.8941,  ...,  2.0000,  1.7913,  1.6836],\n",
      "        [ 7.8971,  8.6603,  8.5156,  ..., -1.8849, -3.0799, -4.1619],\n",
      "        [-4.4687, -4.6218, -4.7985,  ..., -0.7658, -1.4271, -3.0558]])\n",
      "BATCH: DataBatch(x=[1216, 3000], edge_index=[2, 21888], id=[64], batch=[1216], ptr=[65]), feature: tensor([[ 10.5233,  10.7753,  10.4569,  ...,  10.6144,  10.2708,   9.9682],\n",
      "        [  2.1840,   1.9664,   0.4050,  ...,  -3.3917,  -2.1250,  -3.6630],\n",
      "        [  3.0297,   4.4725,   6.0416,  ...,  13.8507,  14.5732,  13.7880],\n",
      "        ...,\n",
      "        [  1.8602,   1.7494,   2.3701,  ...,  -0.8071,  -0.4507,   0.9676],\n",
      "        [  0.1891,   1.9310,   4.3047,  ...,  -7.9949,  -7.1014,  -5.9771],\n",
      "        [ -1.3837,  -0.0262,   1.6064,  ..., -14.5822, -13.2434, -12.3800]])\n",
      "BATCH: DataBatch(x=[1216, 3000], edge_index=[2, 21888], id=[64], batch=[1216], ptr=[65]), feature: tensor([[13.7416, 16.4252, 18.2331,  ..., 10.5525,  7.2544,  3.6692],\n",
      "        [-4.6951,  0.3129,  4.1132,  ..., -3.0355,  0.5555,  4.7053],\n",
      "        [ 5.5624,  4.1742,  2.1973,  ...,  8.1119,  5.2587,  3.9572],\n",
      "        ...,\n",
      "        [-3.6858, -4.3405, -5.2745,  ...,  3.9646,  4.5074,  5.0393],\n",
      "        [-5.9044, -6.5698, -7.0862,  ...,  2.9961,  3.8534,  3.9996],\n",
      "        [-6.1723, -6.2008, -6.7403,  ...,  3.4920,  3.7068,  3.0742]])\n",
      "BATCH: DataBatch(x=[1216, 3000], edge_index=[2, 21888], id=[64], batch=[1216], ptr=[65]), feature: tensor([[ 3.9262,  4.2216,  3.8345,  ..., -2.7239, -2.5167, -2.4372],\n",
      "        [-2.2900, -1.7205, -1.2966,  ..., 10.9643, 11.1376, 11.2396],\n",
      "        [ 7.0873,  7.8341,  7.5202,  ..., -7.7240, -6.5501, -5.8625],\n",
      "        ...,\n",
      "        [-2.7483, -3.2604, -3.4708,  ..., -2.7369, -1.2131,  0.9342],\n",
      "        [ 3.4222,  3.5613,  3.5826,  ..., -4.2639, -4.1143, -3.3863],\n",
      "        [ 2.7527,  3.6634,  4.4959,  ...,  2.9236,  1.8187,  0.5560]])\n",
      "BATCH: DataBatch(x=[1216, 3000], edge_index=[2, 21888], id=[64], batch=[1216], ptr=[65]), feature: tensor([[20.3608, 22.3995, 24.3753,  ...,  4.3151,  3.6773,  2.5898],\n",
      "        [35.1551, 38.6096, 39.4686,  ..., 15.9490, 14.3555, 12.9469],\n",
      "        [-5.3164, -5.4471, -4.9629,  ..., -6.4241, -5.8449, -5.2277],\n",
      "        ...,\n",
      "        [ 2.4898,  1.7290,  0.7809,  ...,  7.4512,  6.5438,  5.2709],\n",
      "        [ 2.6715,  2.1119,  1.5252,  ...,  8.1659,  7.4188,  6.2602],\n",
      "        [-3.3777, -2.7384, -2.2162,  ...,  7.3007,  6.7078,  6.3818]])\n",
      "BATCH: DataBatch(x=[1216, 3000], edge_index=[2, 21888], id=[64], batch=[1216], ptr=[65]), feature: tensor([[  1.7461,   2.1089,   2.7054,  ...,  -2.2070,  -3.7948,  -5.2867],\n",
      "        [  0.1388,   0.2924,   0.9534,  ...,  -3.1542,  -2.2336,  -1.8378],\n",
      "        [  5.9175,   6.7091,   7.2505,  ...,   0.0331,  -2.3853,  -4.6935],\n",
      "        ...,\n",
      "        [-11.1419, -10.3285, -12.7093,  ...,   5.0922,   4.2859,   2.9996],\n",
      "        [ -5.4314,  -5.1381,  -6.9887,  ...,   6.9200,   6.2712,   5.5837],\n",
      "        [-11.7320, -10.7458, -10.1075,  ...,   0.5582,   0.9731,   1.5400]])\n",
      "BATCH: DataBatch(x=[1216, 3000], edge_index=[2, 21888], id=[64], batch=[1216], ptr=[65]), feature: tensor([[ 1.4381e-04,  4.2071e-04,  5.5305e-04,  ..., -6.6330e-09,\n",
      "         -6.5326e-09, -6.4302e-09],\n",
      "        [-7.4436e-04, -2.2713e-03, -3.0014e-03,  ...,  4.4006e-09,\n",
      "          4.6789e-09,  4.9593e-09],\n",
      "        [ 1.0387e-03,  3.1420e-03,  4.1475e-03,  ..., -8.0092e-10,\n",
      "         -6.4249e-10, -4.8266e-10],\n",
      "        ...,\n",
      "        [ 9.7205e+00,  1.0051e+01,  9.9626e+00,  ...,  1.1564e+01,\n",
      "          1.1558e+01,  1.1203e+01],\n",
      "        [ 2.1503e+01,  2.0519e+01,  1.9082e+01,  ..., -2.5758e+00,\n",
      "         -2.1800e+00, -1.9374e+00],\n",
      "        [ 1.0556e+01,  1.0395e+01,  1.0189e+01,  ...,  4.1374e+00,\n",
      "          2.9511e+00,  2.0887e+00]])\n",
      "BATCH: DataBatch(x=[1216, 3000], edge_index=[2, 21888], id=[64], batch=[1216], ptr=[65]), feature: tensor([[ 17.8835,  18.1868,  18.5653,  ...,  15.4043,  15.5648,  16.3559],\n",
      "        [ 27.1565,  28.4588,  27.6870,  ...,   3.0940,   2.1634,   1.3166],\n",
      "        [ 14.6279,  15.2627,  16.0485,  ...,  -9.1713,  -8.9306,  -8.1510],\n",
      "        ...,\n",
      "        [ -6.3672,  -6.7937,  -6.9620,  ...,  -4.2160,  -3.2055,  -3.2397],\n",
      "        [-23.1027, -23.1334, -22.7303,  ...,   8.5382,   7.4493,   5.6917],\n",
      "        [-37.4011, -38.4538, -38.6313,  ...,  -9.3590,  -8.9107,  -8.3396]])\n",
      "BATCH: DataBatch(x=[570, 3000], edge_index=[2, 10260], id=[30], batch=[570], ptr=[31]), feature: tensor([[  4.7333,   4.1031,   3.6731,  ..., -11.9302, -11.1443, -10.6706],\n",
      "        [ -7.7185,  -7.1920,  -5.3239,  ..., -11.5672, -11.6717, -10.7765],\n",
      "        [  0.3256,  -0.0666,  -0.4141,  ...,  -6.8303,  -7.1493,  -7.3195],\n",
      "        ...,\n",
      "        [ -0.2630,  -0.6333,  -1.2967,  ..., -14.9450, -15.0554, -15.2061],\n",
      "        [-17.3858, -17.5110, -17.7429,  ..., -29.0252, -29.9219, -30.3591],\n",
      "        [-13.6386, -13.2790, -12.8792,  ..., -15.6676, -15.8151, -15.9300]])\n",
      "   Generated 3614 predictions for 3614 IDs.\n",
      "ðŸ“„ Saved submission (3614 rows) â†’ .submissions/lstm_gnn_submission.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pqejgcvm_s001_t000_0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pqejgcvm_s001_t000_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pqejgcvm_s001_t000_10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pqejgcvm_s001_t000_11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pqejgcvm_s001_t000_12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3609</th>\n",
       "      <td>pqejgvej_s001_t000_95</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3610</th>\n",
       "      <td>pqejgvej_s001_t000_96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3611</th>\n",
       "      <td>pqejgvej_s001_t000_97</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3612</th>\n",
       "      <td>pqejgvej_s001_t000_98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3613</th>\n",
       "      <td>pqejgvej_s001_t000_99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3614 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id  label\n",
       "0      pqejgcvm_s001_t000_0      0\n",
       "1      pqejgcvm_s001_t000_1      0\n",
       "2     pqejgcvm_s001_t000_10      1\n",
       "3     pqejgcvm_s001_t000_11      1\n",
       "4     pqejgcvm_s001_t000_12      1\n",
       "...                     ...    ...\n",
       "3609  pqejgvej_s001_t000_95      0\n",
       "3610  pqejgvej_s001_t000_96      0\n",
       "3611  pqejgvej_s001_t000_97      1\n",
       "3612  pqejgvej_s001_t000_98      0\n",
       "3613  pqejgvej_s001_t000_99      0\n",
       "\n",
       "[3614 rows x 2 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%aimport src.utils.train\n",
    "from src.utils.train import evaluate_model\n",
    "\n",
    "evaluate_model(\n",
    "    model=model,\n",
    "    test_loader=te_loader,\n",
    "    device=device,\n",
    "    checkpoint_path=CHECKPOINT_ROOT / \"lstm_gnn_best_model.pt\",\n",
    "    submission_path=SUBMISSION_ROOT / \"lstm_gnn_submission.csv\",\n",
    "    use_gnn=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3887a39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%aimport\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "import wandb\n",
    "from src.utils.general_funcs import confusion_matrix_plot\n",
    "\n",
    "best_val_loss = float(\"inf\")\n",
    "best_val_f1 = 0\n",
    "best_val_f1_epoch = 0\n",
    "patience = 10\n",
    "counter = 0\n",
    "num_epochs = 100\n",
    "print(\"Training started\")\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    # ------- Training ------- #\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_targets = batch.y.reshape(-1, 1)\n",
    "        out = model(batch.x, batch.edge_index, batch.batch)\n",
    "        loss = loss_fn(\n",
    "            out, y_targets\n",
    "        )\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    avg_train_loss = total_loss / len(train_loader)  # Average loss per batch\n",
    "\n",
    "    # ------- Validation ------- #\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            batch = batch.to(device)\n",
    "            print(\"Batch batch:\", batch.batch)\n",
    "            out = model(\n",
    "                batch.x, batch.edge_index, batch.batch\n",
    "            )\n",
    "            loss = loss_fn(out, batch.y.reshape(-1, 1))\n",
    "            val_loss += loss.item()\n",
    "            probs = torch.sigmoid(out).squeeze()  # [batch_size, 1] -> [batch_size]\n",
    "            preds = (probs > 0.5).int()\n",
    "            all_preds.extend(preds.cpu().numpy().ravel())\n",
    "            all_labels.extend(\n",
    "                batch.y.int().cpu().numpy().ravel()\n",
    "            )\n",
    "            \n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)  # Average loss per batch\n",
    "    #scheduler.step(avg_val_loss)\n",
    "    val_f1 = f1_score(all_labels, all_preds, average=\"macro\")\n",
    "\n",
    "    all_labels = np.array(all_labels).astype(int)\n",
    "    all_preds = np.array(all_preds).astype(int)\n",
    "\n",
    "    # for name, param in model.named_parameters():\n",
    "    #     if param.grad is not None:\n",
    "    #         print(f\"{name} grad mean: {param.grad.abs().mean()}\")\n",
    "    \n",
    "    # Monitor progress\n",
    "    print(f\"Epoch {epoch} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f} | Val F1: {val_f1:.4f}\")\n",
    "    \n",
    "    # Additional metrics\n",
    "\n",
    "    # Confusion matrix\n",
    "    confusion_matrix_plot(all_preds, all_labels)\n",
    "    # Compute metrics per class (0 and 1)\n",
    "    precision = precision_score(all_labels, all_preds, average=None)\n",
    "    recall = recall_score(all_labels, all_preds, average=None)\n",
    "    f1 = f1_score(all_labels, all_preds, average=None)\n",
    "\n",
    "    # Print only for class 1\n",
    "    print(f\"Class 1 â€” Precision: {precision[1]:.2f}, Recall: {recall[1]:.2f}, F1: {f1[1]:.2f}\")\n",
    "    \n",
    "    # W&B\n",
    "    # wandb.log(\n",
    "    #     {\n",
    "    #         \"epoch\": epoch,\n",
    "    #         \"train_loss\": avg_train_loss,\n",
    "    #         \"val_loss\": avg_val_loss,\n",
    "    #         \"val_f1\": val_f1,\n",
    "    #         \"val_f1_class_1\":f1[1],\n",
    "    #             \"val_f1_class_0\":f1[0]\n",
    "    #     }\n",
    "    # )\n",
    "    print(f\"Epoch {epoch} â€” Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, Val F1: {val_f1:.4f}\", flush=True)\n",
    "    # ------- Record best F1 score ------- #\n",
    "    if val_f1 > best_val_f1:\n",
    "        best_val_f1 = val_f1\n",
    "        best_val_f1_epoch = epoch\n",
    "        best_preds = all_preds.copy()\n",
    "        best_labels = all_labels.copy()\n",
    "        # Load best stats in wandb\n",
    "        wandb.summary[\"best_f1_score\"] = val_f1\n",
    "        wandb.summary[\"f1_score_epoch\"] = epoch\n",
    "    # ------- Early Stopping ------- #\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        # Save best statistics and model\n",
    "        best_val_loss = avg_val_loss\n",
    "        counter = 0\n",
    "        best_state_dict = model.state_dict().copy()  # Save the best model state\n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "print(f\"Best validation F1: {best_val_f1:.4f} at epoch {best_val_f1_epoch}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
