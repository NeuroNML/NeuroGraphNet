{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b998b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric.loader import DataLoader as GeoDataLoader\n",
    "from torch.utils.data import Subset, WeightedRandomSampler\n",
    "# from torch.utils.data import DataLoader\n",
    "from src.utils.seeder import seed_everything\n",
    "\n",
    "# set seaborn theme\n",
    "sns.set_theme()\n",
    "\n",
    "# create useful constants\n",
    "RANDOM_SEED = 42\n",
    "IS_SCITAS = True # set to True if running on SCITAS cluster\n",
    "LOCAL_DATA_ROOT = Path(\"./data\")\n",
    "DATA_ROOT = Path(\"/home/ogut/data\") if IS_SCITAS else LOCAL_DATA_ROOT\n",
    "CHECKPOINT_ROOT = Path(\"./.checkpoints\")\n",
    "SUBMISSION_ROOT = Path(\"./.submissions\")\n",
    "\n",
    "# create directories if they do not exist\n",
    "CHECKPOINT_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "SUBMISSION_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# set dataset root\n",
    "seed_everything(RANDOM_SEED)\n",
    "\n",
    "# setup torch device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78d28586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import subprocess\n",
    "\n",
    "# # execute feature extraction script\n",
    "# try:\n",
    "#     process = subprocess.Popen([\"python3\", \"scripts/feature_extractor.py\"])\n",
    "#     process.wait()\n",
    "# except KeyboardInterrupt:\n",
    "#     print(\"Process interrupted, terminating...\")\n",
    "#     process.terminate()\n",
    "#     process.wait()\n",
    "# except Exception as e:\n",
    "#     print(f\"Error occurred: {e}\")\n",
    "#     if 'process' in locals():\n",
    "#         process.terminate()\n",
    "#         process.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45999291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spacial distance matrix between sensors\n",
    "spatial_distance_file = LOCAL_DATA_ROOT / \"distances_3d.csv\"\n",
    "\n",
    "# training data\n",
    "train_dir = DATA_ROOT / \"train\"\n",
    "train_dir_metadata = train_dir / \"segments.parquet\"\n",
    "train_dataset_dir = LOCAL_DATA_ROOT / \"graph_dataset_train\"\n",
    "\n",
    "# test data\n",
    "test_dir = DATA_ROOT / \"test\"\n",
    "test_dir_metadata = test_dir / \"segments.parquet\"\n",
    "test_dataset_dir = LOCAL_DATA_ROOT / \"graph_dataset_test\"\n",
    "\n",
    "# additional features\n",
    "extracted_features_dir = LOCAL_DATA_ROOT / \"extracted_features\"\n",
    "embeddings_dir =  LOCAL_DATA_ROOT / \"embeddings\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d93851",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.index import ensure_eeg_multiindex \n",
    "\n",
    "# Load clips from datasets\n",
    "clips_tr = pd.read_parquet(train_dir_metadata)\n",
    "clips_tr = ensure_eeg_multiindex(clips_tr)\n",
    "clips_tr = clips_tr[~clips_tr.label.isna()].reset_index()  # Filter NaN values out of clips_tr\n",
    "\n",
    "# Load clips from datasets\n",
    "clips_te = pd.read_parquet(test_dir_metadata)\n",
    "clips_te = ensure_eeg_multiindex(clips_te)\n",
    "\n",
    "# Create unique IDs by converting all index components to strings and store in new column\n",
    "clips_te['id'] = clips_te.index.map(lambda x: '_'.join(str(i) for i in x))\n",
    "assert clips_te.id.nunique() == len(clips_te), \"There are duplicate IDs\"\n",
    "print(clips_te[\"id\"].head())\n",
    "\n",
    "# sort in order to maintain the same submission order\n",
    "clips_te = clips_te.sort_values(by=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd45b398",
   "metadata": {},
   "outputs": [],
   "source": [
    "%aimport\n",
    "from src.data.dataset_graph import GraphEEGDataset\n",
    "\n",
    "# dataset settings\n",
    "batch_size = 64\n",
    "selected_features = []\n",
    "embeddings = []\n",
    "edge_strategy = \"spatial\"\n",
    "correlation_threshold = 0.5\n",
    "top_k = None\n",
    "low_bandpass_frequency = 0.5\n",
    "high_bandpass_frequency = 50\n",
    "\n",
    "# additional settings\n",
    "oversampling_power = 1.0\n",
    "\n",
    "# load training dataset\n",
    "dataset_tr = GraphEEGDataset(\n",
    "    root=train_dataset_dir,\n",
    "    clips=clips_tr,\n",
    "    signal_folder=train_dir,\n",
    "    extracted_features_dir=extracted_features_dir,\n",
    "    selected_features_train=selected_features,\n",
    "    embeddings_dir=embeddings_dir,\n",
    "    embeddings_train=embeddings,\n",
    "    edge_strategy=edge_strategy,\n",
    "    spatial_distance_file=(\n",
    "        spatial_distance_file if edge_strategy == \"spatial\" else None\n",
    "    ),\n",
    "    top_k=top_k,\n",
    "    correlation_threshold=correlation_threshold,\n",
    "    force_reprocess=False,\n",
    "    bandpass_frequencies=(\n",
    "        low_bandpass_frequency,\n",
    "        high_bandpass_frequency,\n",
    "    ),\n",
    "    segment_length=3000,\n",
    "    apply_filtering=True,\n",
    "    apply_rereferencing=False,\n",
    "    apply_normalization=False,\n",
    "    sampling_rate=250,\n",
    ")\n",
    "\n",
    "# Check the length of the dataset\n",
    "print(f\"Length of train_dataset: {len(dataset_tr)}\")\n",
    "print(f' Eliminated IDs: {dataset_tr.ids_to_eliminate}')\n",
    "\n",
    "# Eliminate ids that did not have electrodes above correlation threshols\n",
    "clips_tr = clips_tr[~clips_tr.index.isin(dataset_tr.ids_to_eliminate)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a32d044",
   "metadata": {},
   "outputs": [],
   "source": [
    "%aimport\n",
    "from src.data.dataset_graph import GraphEEGDataset\n",
    "\n",
    "# load test dataset\n",
    "te_dataset = GraphEEGDataset(\n",
    "    root=test_dataset_dir,\n",
    "    clips=clips_te,\n",
    "    signal_folder=test_dir,\n",
    "    extracted_features_dir=extracted_features_dir,\n",
    "    selected_features_train=False,\n",
    "    embeddings_dir=embeddings_dir,\n",
    "    embeddings_train=False,\n",
    "    edge_strategy=\"spatial\",\n",
    "    spatial_distance_file=spatial_distance_file,\n",
    "    top_k=None,\n",
    "    correlation_threshold=0.5,\n",
    "    force_reprocess=False,\n",
    "    bandpass_frequencies=(\n",
    "        low_bandpass_frequency,\n",
    "        high_bandpass_frequency,\n",
    "    ),\n",
    "    segment_length=3000,\n",
    "    apply_filtering=True,\n",
    "    apply_rereferencing=False,\n",
    "    apply_normalization=False,\n",
    "    sampling_rate=250,\n",
    "    is_test = True,\n",
    ")\n",
    "\n",
    "# Check the length of the dataset\n",
    "print(f\"Length of test_dataset: {len(te_dataset)}\")\n",
    "print(f' Eliminated IDs:{te_dataset.ids_to_eliminate}')\n",
    "\n",
    "# Eliminate ids that did not have electrodes above correlation threshols\n",
    "clips_te = clips_te[~clips_te.index.isin(te_dataset.ids_to_eliminate)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a52b6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in te_dataset:\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6943f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "from src.utils.general_funcs import labels_stats\n",
    "\n",
    "# Get total samples and split sizes\n",
    "total_samples = len(dataset_tr)\n",
    "train_size = int(0.8 * total_samples)\n",
    "val_size = total_samples - train_size\n",
    "\n",
    "# Get labels for initial split\n",
    "y = clips_tr[\"label\"].values\n",
    "\n",
    "# Create initial train/val split\n",
    "train_indices, val_indices = random_split(\n",
    "    range(total_samples), \n",
    "    [train_size, val_size],\n",
    "    generator=torch.Generator().manual_seed(RANDOM_SEED)\n",
    ")\n",
    "\n",
    "# Convert to numpy arrays for easier indexing\n",
    "train_indices = np.array(train_indices)\n",
    "val_indices = np.array(val_indices)\n",
    "\n",
    "print('Labels before split', flush=True)\n",
    "print(y, flush=True)\n",
    "\n",
    "# Print stats for class 0 and 1\n",
    "labels_stats(y, train_indices, val_indices)\n",
    "\n",
    "# Create train and val datasets\n",
    "train_dataset = Subset(dataset_tr, train_indices)\n",
    "val_dataset = Subset(dataset_tr, val_indices)\n",
    "\n",
    "# 3. Compute sample weights for oversampling\n",
    "train_labels = [clips_tr.iloc[i][\"label\"] for i in train_indices]\n",
    "class_counts = np.bincount(train_labels)\n",
    "class_weights = (1. / class_counts) ** oversampling_power  # Higher weights for not frequent classes\n",
    "sample_weights = [class_weights[label] for label in train_labels]  # Assign weight to each sample based on its class\n",
    "\n",
    "# 4. Define sampler\n",
    "sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n",
    "\n",
    "# Define dataloaders\n",
    "BATCH_SIZE = 64\n",
    "train_loader = GeoDataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=sampler, shuffle=False)\n",
    "val_loader = GeoDataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "te_loader = GeoDataLoader(te_dataset, batch_size=BATCH_SIZE)\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Val batches: {len(val_loader)}\")\n",
    "print(f\"Test batches: {len(te_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3d2ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_loader:\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1427c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "%aimport\n",
    "from src.layers.cnn_lstm_gnn import LSTM_GNN_Model\n",
    "from src.utils.train import train_model\n",
    "\n",
    "SAVE_PATH = CHECKPOINT_ROOT / \"lstm_gnn_best_model.pt\"\n",
    "SUBMISSION_PATH = SUBMISSION_ROOT / \"lstm_gnn_submission.csv\"\n",
    "\n",
    "config = {\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"weight_decay\": 1e-5,\n",
    "    \"patience\": 15,\n",
    "    \"epochs\": 100,\n",
    "}\n",
    "\n",
    "# NOTE: model with default parameters\n",
    "model_older = LSTM_GNN_Model(\n",
    "    # Parameters for the CNN_BiLSTM_Encoder (temporal encoder)\n",
    "    cnn_dropout = 0.25,\n",
    "    lstm_hidden_dim = 64,\n",
    "    lstm_out_dim = 64,  # This will be the time_encoder_output_dim for the GCN\n",
    "    lstm_dropout = 0.25,\n",
    "    # Parameters for the EEGGCN (graph neural network)\n",
    "    gcn_hidden_channels = 64,\n",
    "    gcn_out_channels = 32,\n",
    "    num_gcn_layers = 3,\n",
    "    gcn_dropout = 0.5,\n",
    "    num_classes = 1,  # For binary classification (seizure/non-seizure)\n",
    "    num_channels = 19,  # Number of EEG channels\n",
    ")\n",
    "\n",
    "# build model with current parameters\n",
    "# Epochs:   6%| | 6/100 [13:36<4:17:46, 164.54s/it, train_loss=0.6508, val_loss=0.6166, best_val_f1=0.2840, lr=3.00e-04, b2025-06-05 13:20:42 - INFO - \n",
    "# Epochs:   7%| | 7/100 [16:24<4:17:02, 165.83s/it, train_loss=0.6446, val_loss=0.6258, best_val_f1=0.2840, lr=3.00e-04, b2025-06-05 13:23:30 - INFO - \n",
    "model_improved = LSTM_GNN_Model(\n",
    "    # Parameters for the CNN_BiLSTM_Encoder (temporal encoder)\n",
    "    cnn_dropout = 0.25,\n",
    "    lstm_hidden_dim = 96, # 96 original\n",
    "    lstm_out_dim = 96,  # This will be the time_encoder_output_dim for the GCN\n",
    "    lstm_dropout = 0.25,\n",
    "    # Parameters for the EEGGCN (graph neural network)\n",
    "    gcn_hidden_channels = 96,\n",
    "    gcn_out_channels = 64,\n",
    "    num_gcn_layers = 3,\n",
    "    gcn_dropout = 0.5,\n",
    "    num_classes = 1,  # For binary classification (seizure/non-seizure)\n",
    "    num_channels = 19,  # Number of EEG channels\n",
    ")\n",
    "\n",
    "\n",
    "# build model with current parameters\n",
    "# Epochs:   2%| | 2/100 [03:21<5:28:40, 201.23s/it, train_loss=0.7174, val_loss=0.5724, best_val_f1=0.0848, lr=3.00e-04, b2025-06-05 13:32:42 - INFO - \n",
    "# Epochs:   3%| | 3/100 [06:28<5:12:31, 193.31s/it, train_loss=0.6813, val_loss=0.5767, best_val_f1=0.1734, lr=3.00e-04, b2025-06-05 13:35:50 - INFO - \n",
    "# Epochs:   4%| | 4/100 [09:26<4:57:36, 186.00s/it, train_loss=0.6638, val_loss=0.6072, best_val_f1=0.1734, lr=3.00e-04, b2025-06-05 13:38:47 - INFO - \n",
    "# Epochs:   5%| | 5/100 [12:26<4:50:40, 183.58s/it, train_loss=0.6704, val_loss=0.5754, best_val_f1=0.2178, lr=3.00e-04, b2025-06-05 13:41:47 - INFO - \n",
    "# ...\n",
    "# Epochs:   7%| | 7/100 [19:21<5:10:58, 200.62s/it, train_loss=0.6333, val_loss=0.5949, best_val_f1=0.3921, lr=3.00e-04, b2025-06-05 13:48:43 - INFO - \n",
    "# Epochs:   8%| | 8/100 [23:11<5:22:14, 210.15s/it, train_loss=0.6261, val_loss=0.5993, best_val_f1=0.3921, lr=3.00e-04, b2025-06-05 13:52:33 - INFO - \n",
    "# Epochs:   9%| | 9/100 [26:35<5:15:33, 208.06s/it, train_loss=0.6043, val_loss=0.5743, best_val_f1=0.3921, lr=3.00e-04, b2025-06-05 13:55:56 - INFO - \n",
    "# ...\n",
    "# Epochs:  12%| | 12/100 [36:17<4:49:57, 197.70s/it, train_loss=0.5935, val_loss=0.5691, best_val_f1=0.5043, lr=3.00e-04, 2025-06-05 14:05:38 - INFO - \n",
    "# Epochs:  13%|▏| 13/100 [39:27<4:43:05, 195.24s/it, train_loss=0.5701, val_loss=0.5855, best_val_f1=0.5380, lr=3.00e-04, 2025-06-05 14:08:48 - INFO - \n",
    "# Epochs:  14%|▏| 14/100 [42:32<4:35:35, 192.27s/it, train_loss=0.5329, val_loss=0.6952, best_val_f1=0.5380, lr=3.00e-04, 2025-06-05 14:11:54 - INFO -\n",
    "# Epochs:  18%|▏| 18/100 [55:14<4:22:12, 191.86s/it, train_loss=0.5042, val_loss=0.5616, best_val_f1=0.5623, lr=3.00e-04, 2025-06-05 14:24:36 - INFO -\n",
    "# Epochs:  19%|▏| 19/100 [58:26<4:19:03, 191.89s/it, train_loss=0.5092, val_loss=0.4702, best_val_f1=0.6405, lr=3.00e-04, 2025-06-05 14:27:48 - INFO - \n",
    "# Epochs:  20%|▏| 20/100 [04:25<5:53:37, 265.22s/it, train_loss=0.5077, val_loss=0.4850, best_val_f1=0.6405, lr=3.00e-04, 2025-06-05 15:35:20 - INFO - \n",
    "# Epochs:  21%|▏| 21/100 [07:55<5:06:16, 232.62s/it, train_loss=0.4657, val_loss=0.4666, best_val_f1=0.6405, lr=3.00e-04, 2025-06-05 15:38:49 - INFO - \n",
    "# ...\n",
    "# Epochs:  23%|▏| 23/100 [16:40<5:02:39, 235.83s/it, train_loss=0.4786, val_loss=0.4441, best_val_f1=0.6405, lr=3.00e-04, 2025-06-05 15:24:57 - INFO -\n",
    "# Epochs:  24%|▏| 24/100 [18:00<4:20:53, 205.96s/it, train_loss=0.4688, val_loss=0.5586, best_val_f1=0.6405, lr=3.00e-04, 2025-06-05 15:48:55 - INFO - \n",
    "# Epochs:  25%|▎| 25/100 [21:08<4:09:36, 199.69s/it, train_loss=0.4521, val_loss=0.4014, best_val_f1=0.6484, lr=3.00e-04, 2025-06-05 15:52:02 - INFO - \n",
    "# Epochs:  26%|▎| 26/100 [24:09<3:58:50, 193.65s/it, train_loss=0.4378, val_loss=0.3937, best_val_f1=0.6800, lr=3.00e-04, 2025-06-05 15:55:04 - INFO - \n",
    "# ---- FROM HERE IT DOES NOT LEARN ANYTHING!!!\n",
    "# ....\n",
    "#\n",
    "# Epochs:  31%|▎| 31/100 [39:30<3:35:33, 187.44s/it, train_loss=0.4061, val_loss=0.4341, best_val_f1=0.6800, lr=3.00e-04, 2025-06-05 16:10:25 - INFO - \n",
    "#...\n",
    "# (other run)\n",
    "# Epochs:  32%|▎| 32/100 [18:51<3:20:29, 176.90s/it, train_loss=0.3984, val_loss=0.4484, best_val_f1=0.6800, lr=3.00e-04, 2025-06-05 18:22:51 - INFO - \n",
    "# ...\n",
    "# Epochs:  35%|▎| 35/100 [52:42<3:31:23, 195.13s/it, train_loss=0.3835, val_loss=0.4302, best_val_f1=0.6800, lr=3.00e-04, 2025-06-05 16:23:36 - INFO - \n",
    "# Epochs:  37%|▎| 37/100 [32:44<2:56:23, 168.00s/it, train_loss=0.3619, val_loss=0.4276, best_val_f1=0.6800, lr=3.00e-04, 2025-06-05 18:36:45 - INFO - \n",
    "# NOTE: BEST MODEL SO FAR!!!\n",
    "# SAVE_PATH = CHECKPOINT_ROOT / \"lstm_gnn_best_model_epochs_.pt\"\n",
    "best_model = LSTM_GNN_Model(\n",
    "    # Parameters for the CNN_BiLSTM_Encoder (temporal encoder)\n",
    "    cnn_dropout = 0.25,\n",
    "    lstm_hidden_dim = 128, # 96 original\n",
    "    lstm_out_dim = 128,  # This will be the time_encoder_output_dim for the GCN\n",
    "    lstm_dropout = 0.25,\n",
    "    # Parameters for the EEGGCN (graph neural network)\n",
    "    gcn_hidden_channels = 128,\n",
    "    gcn_out_channels = 128,\n",
    "    num_gcn_layers = 3,\n",
    "    gcn_dropout = 0.5,\n",
    "    num_classes = 1,  # For binary classification (seizure/non-seizure)\n",
    "    num_channels = 19,  # Number of EEG channels\n",
    ")\n",
    "\n",
    "# Epochs:  29%|▎| 29/100 [2:32:36<6:26:13, 326.39s/it, train_loss=0.3669, val_loss=0.4361, best_val_f1=0.6758, lr=3.00e-042025-06-05 21:22:07 - INFO - \n",
    "# Epochs:  30%|▎| 30/100 [2:38:01<6:20:19, 326.00s/it, train_loss=0.3709, val_loss=0.5588, best_val_f1=0.6758, lr=3.00e-042025-06-05 21:27:32 - INFO - \n",
    "# NOTE: Not performing well....\n",
    "# SAVE_PATH = CHECKPOINT_ROOT / \"lstm_gnn_best_model_even_bigger.pt\"\n",
    "new_model = LSTM_GNN_Model(\n",
    "    # Parameters for the CNN_BiLSTM_Encoder (temporal encoder)\n",
    "    cnn_dropout = 0.25,\n",
    "    lstm_hidden_dim = 128, # 96 original\n",
    "    lstm_out_dim = 128,  # This will be the time_encoder_output_dim for the GCN\n",
    "    lstm_dropout = 0.25,\n",
    "    # Parameters for the EEGGCN (graph neural network)\n",
    "    gcn_hidden_channels = 128,\n",
    "    gcn_out_channels = 64,\n",
    "    num_gcn_layers = 3,\n",
    "    gcn_dropout = 0.5,\n",
    "    num_classes = 1,  # For binary classification (seizure/non-seizure)\n",
    "    num_channels = 19,  # Number of EEG channels\n",
    ")\n",
    "\n",
    "# Same setup as best model, with bigger GCN output channels to check if it can learn something\n",
    "SAVE_PATH = CHECKPOINT_ROOT / \"lstm_gnn_best_model_bigger_gcn_output_channels.pt\"\n",
    "# Epochs:  13%|▏| 13/100 [33:58<4:06:35, 170.07s/it, train_loss=0.5545, val_loss=0.5253, best_val_f1=0.5505, lr=3.00e-04, 2025-06-05 22:20:18 - INFO - \n",
    "# Epochs:  28%|▎| 28/100 [1:16:29<3:23:10, 169.32s/it, train_loss=0.4188, val_loss=0.4747, best_val_f1=0.5817, lr=3.00e-042025-06-05 23:02:49 - INFO - \n",
    "# NOTE: THIS MODEL IS NOT PERFORMING WELL + IT IS SLOW TO TRAIN\n",
    "model_improved_bigger = LSTM_GNN_Model(\n",
    "    # Parameters for the CNN_BiLSTM_Encoder (temporal encoder)\n",
    "    cnn_dropout = 0.25,\n",
    "    lstm_hidden_dim = 128, # original 128\n",
    "    lstm_out_dim = 128,  # original 128\n",
    "    lstm_dropout = 0.25,\n",
    "    # Parameters for the EEGGCN (graph neural network)\n",
    "    gcn_hidden_channels = 192, # original 128\n",
    "    gcn_out_channels = 192, # original 64\n",
    "    num_gcn_layers = 3,\n",
    "    gcn_dropout = 0.5,\n",
    "    num_classes = 1,\n",
    "    num_channels = 19,\n",
    ")\n",
    "\n",
    "# SAVE_PATH = CHECKPOINT_ROOT / \"lstm_gnn_new_best_model.pt\"\n",
    "# Epochs:   2%| | 2/100 [04:54<8:01:46, 294.97s/it, train_loss=0.5635, val_loss=0.6869, best_val_f1=0.5291, lr=1.00e-03, b2025-06-06 00:08:26 - INFO - \n",
    "# Epochs:  26%|▎| 26/100 [1:16:00<3:35:35, 174.81s/it, train_loss=0.2740, val_loss=0.4044, best_val_f1=0.7278, lr=6.25e-052025-06-06 01:19:31 - INFO - \n",
    "new_best_model_test = LSTM_GNN_Model(\n",
    "    # Parameters for the CNN_BiLSTM_Encoder (temporal encoder)\n",
    "    cnn_dropout = 0.25,\n",
    "    lstm_hidden_dim = 128, # 96 original\n",
    "    lstm_out_dim = 128,  # This will be the time_encoder_output_dim for the GCN\n",
    "    lstm_dropout = 0.25,\n",
    "    # Parameters for the EEGGCN (graph neural network)\n",
    "    gcn_hidden_channels = 128,\n",
    "    gcn_out_channels = 64,\n",
    "    num_gcn_layers = 4,\n",
    "    gcn_dropout = 0.5,\n",
    "    num_classes = 1,  # For binary classification (seizure/non-seizure)\n",
    "    num_channels = 19,  # Number of EEG channels\n",
    ")\n",
    "\n",
    "# SAVE_PATH = CHECKPOINT_ROOT / \"lstm_gnn_new_new_best_model.pt\"\n",
    "new_new_best_model_test = LSTM_GNN_Model(\n",
    "    # Parameters for the CNN_BiLSTM_Encoder (temporal encoder)\n",
    "    cnn_dropout = 0.25,\n",
    "    lstm_hidden_dim = 128, # 96 original\n",
    "    lstm_out_dim = 128,  # This will be the time_encoder_output_dim for the GCN\n",
    "    lstm_dropout = 0.25,\n",
    "    # Parameters for the EEGGCN (graph neural network)\n",
    "    gcn_hidden_channels = 128,\n",
    "    gcn_out_channels = 96,\n",
    "    num_gcn_layers = 4,\n",
    "    gcn_dropout = 0.5,\n",
    "    num_classes = 1,  # For binary classification (seizure/non-seizure)\n",
    "    num_channels = 19,  # Number of EEG channels\n",
    ")\n",
    "\n",
    "# select model to use\n",
    "model = new_new_best_model_test\n",
    "\n",
    "model = model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=config[\"learning_rate\"], weight_decay=config[\"weight_decay\"])\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "\n",
    "adjusted_pos_weight = torch.tensor([1.5], dtype=torch.float32).to(device)\n",
    "print(f'pos_weight:{adjusted_pos_weight}')\n",
    "loss = nn.BCEWithLogitsLoss(pos_weight=adjusted_pos_weight)\n",
    "\n",
    "# /home/ldibello/venvs/neuro/lib/python3.10/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.25 and num_layers=1\n",
    "\n",
    "# train model\n",
    "train_history, val_history = train_model(\n",
    "    wandb_config=None,\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    criterion=loss,\n",
    "    scheduler=scheduler,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    num_epochs=config[\"epochs\"],\n",
    "    patience=config[\"patience\"],\n",
    "    save_path=SAVE_PATH,\n",
    "    use_gnn=True,\n",
    "    # hidden attribute\n",
    "    try_load_checkpoint=True,\n",
    "    log_wandb=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63329a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.plot import plot_training_loss\n",
    "\n",
    "plot_training_loss(train_history[\"loss\"], val_history[\"loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293bb297",
   "metadata": {},
   "outputs": [],
   "source": [
    "%aimport src.utils.train\n",
    "from src.utils.train import evaluate_model\n",
    "\n",
    "evaluate_model(\n",
    "    model=model,\n",
    "    test_loader=te_loader,\n",
    "    device=device,\n",
    "    checkpoint_path=SAVE_PATH,\n",
    "    submission_path=SUBMISSION_ROOT / \"lstm_gnn_submission_new_best_model.csv\",\n",
    "    use_gnn=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3887a39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%aimport\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "import wandb\n",
    "from src.utils.general_funcs import confusion_matrix_plot\n",
    "\n",
    "best_val_loss = float(\"inf\")\n",
    "best_val_f1 = 0\n",
    "best_val_f1_epoch = 0\n",
    "patience = 10\n",
    "counter = 0\n",
    "num_epochs = 100\n",
    "print(\"Training started\")\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    # ------- Training ------- #\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_targets = batch.y.reshape(-1, 1)\n",
    "        out = model(batch.x, batch.edge_index, batch.batch)\n",
    "        loss = loss_fn(\n",
    "            out, y_targets\n",
    "        )\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    avg_train_loss = total_loss / len(train_loader)  # Average loss per batch\n",
    "\n",
    "    # ------- Validation ------- #\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            batch = batch.to(device)\n",
    "            print(\"Batch batch:\", batch.batch)\n",
    "            out = model(\n",
    "                batch.x, batch.edge_index, batch.batch\n",
    "            )\n",
    "            loss = loss_fn(out, batch.y.reshape(-1, 1))\n",
    "            val_loss += loss.item()\n",
    "            probs = torch.sigmoid(out).squeeze()  # [batch_size, 1] -> [batch_size]\n",
    "            preds = (probs > 0.5).int()\n",
    "            all_preds.extend(preds.cpu().numpy().ravel())\n",
    "            all_labels.extend(\n",
    "                batch.y.int().cpu().numpy().ravel()\n",
    "            )\n",
    "            \n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)  # Average loss per batch\n",
    "    #scheduler.step(avg_val_loss)\n",
    "    val_f1 = f1_score(all_labels, all_preds, average=\"macro\")\n",
    "\n",
    "    all_labels = np.array(all_labels).astype(int)\n",
    "    all_preds = np.array(all_preds).astype(int)\n",
    "\n",
    "    # for name, param in model.named_parameters():\n",
    "    #     if param.grad is not None:\n",
    "    #         print(f\"{name} grad mean: {param.grad.abs().mean()}\")\n",
    "    \n",
    "    # Monitor progress\n",
    "    print(f\"Epoch {epoch} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f} | Val F1: {val_f1:.4f}\")\n",
    "    \n",
    "    # Additional metrics\n",
    "\n",
    "    # Confusion matrix\n",
    "    confusion_matrix_plot(all_preds, all_labels)\n",
    "    # Compute metrics per class (0 and 1)\n",
    "    precision = precision_score(all_labels, all_preds, average=None)\n",
    "    recall = recall_score(all_labels, all_preds, average=None)\n",
    "    f1 = f1_score(all_labels, all_preds, average=None)\n",
    "\n",
    "    # Print only for class 1\n",
    "    print(f\"Class 1 — Precision: {precision[1]:.2f}, Recall: {recall[1]:.2f}, F1: {f1[1]:.2f}\")\n",
    "    \n",
    "    # W&B\n",
    "    # wandb.log(\n",
    "    #     {\n",
    "    #         \"epoch\": epoch,\n",
    "    #         \"train_loss\": avg_train_loss,\n",
    "    #         \"val_loss\": avg_val_loss,\n",
    "    #         \"val_f1\": val_f1,\n",
    "    #         \"val_f1_class_1\":f1[1],\n",
    "    #             \"val_f1_class_0\":f1[0]\n",
    "    #     }\n",
    "    # )\n",
    "    print(f\"Epoch {epoch} — Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, Val F1: {val_f1:.4f}\", flush=True)\n",
    "    # ------- Record best F1 score ------- #\n",
    "    if val_f1 > best_val_f1:\n",
    "        best_val_f1 = val_f1\n",
    "        best_val_f1_epoch = epoch\n",
    "        best_preds = all_preds.copy()\n",
    "        best_labels = all_labels.copy()\n",
    "        # Load best stats in wandb\n",
    "        wandb.summary[\"best_f1_score\"] = val_f1\n",
    "        wandb.summary[\"f1_score_epoch\"] = epoch\n",
    "    # ------- Early Stopping ------- #\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        # Save best statistics and model\n",
    "        best_val_loss = avg_val_loss\n",
    "        counter = 0\n",
    "        best_state_dict = model.state_dict().copy()  # Save the best model state\n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "print(f\"Best validation F1: {best_val_f1:.4f} at epoch {best_val_f1_epoch}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
