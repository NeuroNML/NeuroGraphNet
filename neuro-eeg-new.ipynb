{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "97b998b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torch_geometric.loader import DataLoader as GeoDataLoader\n",
    "from torch.utils.data import Subset, WeightedRandomSampler\n",
    "# from torch.utils.data import DataLoader\n",
    "from src.utils.seeder import seed_everything\n",
    "\n",
    "# set seaborn theme\n",
    "sns.set_theme()\n",
    "\n",
    "# create useful constants\n",
    "RANDOM_SEED = 42\n",
    "IS_SCITAS = False # set to True if running on SCITAS cluster\n",
    "LOCAL_DATA_ROOT = Path(\"./data\")\n",
    "DATA_ROOT = Path(\"/home/ogut/data\") if IS_SCITAS else LOCAL_DATA_ROOT\n",
    "CHECKPOINT_ROOT = Path(\"./.checkpoints\")\n",
    "SUBMISSION_ROOT = Path(\"./.submissions\")\n",
    "\n",
    "# create directories if they do not exist\n",
    "CHECKPOINT_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "SUBMISSION_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# set dataset root\n",
    "seed_everything(RANDOM_SEED)\n",
    "\n",
    "# setup torch device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78d28586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import subprocess\n",
    "\n",
    "# # execute feature extraction script\n",
    "# try:\n",
    "#     process = subprocess.Popen([\"python3\", \"scripts/feature_extractor.py\"])\n",
    "#     process.wait()\n",
    "# except KeyboardInterrupt:\n",
    "#     print(\"Process interrupted, terminating...\")\n",
    "#     process.terminate()\n",
    "#     process.wait()\n",
    "# except Exception as e:\n",
    "#     print(f\"Error occurred: {e}\")\n",
    "#     if 'process' in locals():\n",
    "#         process.terminate()\n",
    "#         process.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "45999291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spacial distance matrix between sensors\n",
    "spatial_distance_file = LOCAL_DATA_ROOT / \"distances_3d.csv\"\n",
    "\n",
    "# training data\n",
    "train_dir = DATA_ROOT / \"train\"\n",
    "train_dir_metadata = train_dir / \"segments.parquet\"\n",
    "train_dataset_dir = LOCAL_DATA_ROOT / \"graph_dataset_train\"\n",
    "\n",
    "# test data\n",
    "test_dir = DATA_ROOT / \"test\"\n",
    "test_dir_metadata = test_dir / \"segments.parquet\"\n",
    "test_dataset_dir = LOCAL_DATA_ROOT / \"graph_dataset_test\"\n",
    "\n",
    "# additional features\n",
    "extracted_features_dir = LOCAL_DATA_ROOT / \"extracted_features\"\n",
    "embeddings_dir =  LOCAL_DATA_ROOT / \"embeddings\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "83d93851",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.index import ensure_eeg_multiindex \n",
    "\n",
    "# Load clips from datasets\n",
    "clips_tr = pd.read_parquet(train_dir_metadata)\n",
    "clips_tr = ensure_eeg_multiindex(clips_tr)\n",
    "clips_tr['id'] = clips_tr.index.map(lambda x: '_'.join(str(i) for i in x))\n",
    "assert clips_tr.id.nunique() == len(clips_tr), \"There are duplicate IDs\"\n",
    "clips_tr = clips_tr[~clips_tr.label.isna()].reset_index()\n",
    "\n",
    "# Load clips from datasets\n",
    "clips_te = pd.read_parquet(test_dir_metadata)\n",
    "clips_te = ensure_eeg_multiindex(clips_te)\n",
    "clips_te['id'] = clips_te.index.map(lambda x: '_'.join(str(i) for i in x))\n",
    "assert clips_te.id.nunique() == len(clips_te), \"There are duplicate IDs\"\n",
    "clips_te = clips_te.reset_index()\n",
    "\n",
    "# sort in order to maintain the same submission order\n",
    "clips_te = clips_te.sort_values(by=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bd45b398",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-08 00:49:02 - INFO - Initializing GraphEEGDataset...\n",
      "2025-06-08 00:49:02 - INFO - Dataset parameters:\n",
      "2025-06-08 00:49:02 - INFO -   - Root directory: data/graph_dataset_train\n",
      "2025-06-08 00:49:02 - INFO -   - Edge strategy: spatial\n",
      "2025-06-08 00:49:02 - INFO -   - Top-k neighbors: None\n",
      "2025-06-08 00:49:02 - INFO -   - Correlation threshold: 0.5\n",
      "2025-06-08 00:49:02 - INFO -   - Force reprocess: True\n",
      "2025-06-08 00:49:02 - INFO -   - Bandpass frequencies: (0.5, 50)\n",
      "2025-06-08 00:49:02 - INFO -   - Segment length: 3000\n",
      "2025-06-08 00:49:02 - INFO -   - Apply filtering: True\n",
      "2025-06-08 00:49:02 - INFO -   - Apply rereferencing: True\n",
      "2025-06-08 00:49:02 - INFO -   - Apply normalization: True\n",
      "2025-06-08 00:49:02 - INFO -   - Sampling rate: 250\n",
      "2025-06-08 00:49:02 - INFO -   - Test mode: False\n",
      "2025-06-08 00:49:02 - INFO - Number of EEG channels: 19\n",
      "2025-06-08 00:49:02 - INFO - Setting up signal filters...\n",
      "2025-06-08 00:49:02 - INFO - Loading spatial distances from data/distances_3d.csv\n",
      "2025-06-08 00:49:02 - INFO - Loading spatial distances from data/distances_3d.csv\n",
      "2025-06-08 00:49:02 - INFO - Loaded 361 spatial distances in 0.01s\n",
      "2025-06-08 00:49:02 - INFO - Loaded 361 spatial distance pairs\n",
      "2025-06-08 00:49:02 - INFO - Force reprocessing enabled - cleaning up existing processed files\n",
      "2025-06-08 00:49:02 - INFO - Deleted 2271 existing processed files\n",
      "2025-06-08 00:49:02 - INFO - Starting session processing...\n",
      "2025-06-08 00:49:02 - INFO - Starting session processing...\n",
      "2025-06-08 00:49:02 - INFO - Processing session 1/177 (Patient pqejgcff, Session s1_t0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modules to reload:\n",
      "\n",
      "\n",
      "Modules to skip:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-08 00:49:02 - INFO - Preprocessed signal shape: (302250, 19)\n",
      "2025-06-08 00:49:02 - INFO - Processed 0 segments so far\n",
      "2025-06-08 00:49:02 - INFO - Session 1 processed in 0.38s\n",
      "2025-06-08 00:49:02 - INFO - Processing session 2/177 (Patient pqejgcpt, Session s2_t1)\n",
      "2025-06-08 00:49:03 - INFO - Preprocessed signal shape: (328000, 19)\n",
      "2025-06-08 00:49:03 - INFO - Processed 100 segments so far\n",
      "2025-06-08 00:49:03 - INFO - Processed 200 segments so far\n",
      "2025-06-08 00:49:03 - INFO - Session 2 processed in 0.40s\n",
      "2025-06-08 00:49:03 - INFO - Processing session 3/177 (Patient pqejgcpt, Session s3_t1)\n",
      "2025-06-08 00:49:03 - INFO - Preprocessed signal shape: (345750, 19)\n",
      "2025-06-08 00:49:03 - INFO - Processed 300 segments so far\n",
      "2025-06-08 00:49:03 - INFO - Session 3 processed in 0.41s\n",
      "2025-06-08 00:49:03 - INFO - Processing session 4/177 (Patient pqejgcsv, Session s1_t0)\n",
      "2025-06-08 00:49:03 - INFO - Preprocessed signal shape: (128500, 19)\n",
      "2025-06-08 00:49:03 - INFO - Session 4 processed in 0.17s\n",
      "2025-06-08 00:49:03 - INFO - Processing session 5/177 (Patient pqejgctq, Session s2_t1)\n",
      "2025-06-08 00:49:03 - INFO - Preprocessed signal shape: (137500, 19)\n",
      "2025-06-08 00:49:03 - INFO - Processed 400 segments so far\n",
      "2025-06-08 00:49:03 - INFO - Session 5 processed in 0.19s\n",
      "2025-06-08 00:49:03 - INFO - Processing session 6/177 (Patient pqejgcvf, Session s1_t0)\n",
      "2025-06-08 00:49:04 - INFO - Preprocessed signal shape: (498000, 19)\n",
      "2025-06-08 00:49:04 - INFO - Processed 500 segments so far\n",
      "2025-06-08 00:49:04 - INFO - Session 6 processed in 0.60s\n",
      "2025-06-08 00:49:04 - INFO - Processing session 7/177 (Patient pqejgcvq, Session s5_t0)\n",
      "2025-06-08 00:49:04 - INFO - Preprocessed signal shape: (188250, 19)\n",
      "2025-06-08 00:49:04 - INFO - Processed 600 segments so far\n",
      "2025-06-08 00:49:04 - INFO - Session 7 processed in 0.23s\n",
      "2025-06-08 00:49:04 - INFO - Processing session 8/177 (Patient pqejgday, Session s3_t1)\n",
      "2025-06-08 00:49:05 - INFO - Preprocessed signal shape: (331500, 19)\n",
      "2025-06-08 00:49:05 - INFO - Processed 700 segments so far\n",
      "2025-06-08 00:49:05 - INFO - Session 8 processed in 0.37s\n",
      "2025-06-08 00:49:05 - INFO - Processing session 9/177 (Patient pqejgddg, Session s5_t0)\n",
      "2025-06-08 00:49:05 - INFO - Preprocessed signal shape: (150000, 19)\n",
      "2025-06-08 00:49:05 - INFO - Session 9 processed in 0.18s\n",
      "2025-06-08 00:49:05 - INFO - Processing session 10/177 (Patient pqejgdgx, Session s3_t6)\n",
      "2025-06-08 00:49:05 - INFO - Preprocessed signal shape: (171000, 19)\n",
      "2025-06-08 00:49:05 - INFO - Processed 800 segments so far\n",
      "2025-06-08 00:49:05 - INFO - Session 10 processed in 0.23s\n",
      "2025-06-08 00:49:05 - INFO - Processing session 11/177 (Patient pqejgdjw, Session s5_t4)\n",
      "2025-06-08 00:49:05 - INFO - Preprocessed signal shape: (20250, 19)\n",
      "2025-06-08 00:49:05 - INFO - Session 11 processed in 0.03s\n",
      "2025-06-08 00:49:05 - INFO - Processing session 12/177 (Patient pqejgdli, Session s1_t1)\n",
      "2025-06-08 00:49:05 - INFO - Preprocessed signal shape: (298000, 19)\n",
      "2025-06-08 00:49:05 - INFO - Processed 900 segments so far\n",
      "2025-06-08 00:49:05 - INFO - Session 12 processed in 0.35s\n",
      "2025-06-08 00:49:05 - INFO - Processing session 13/177 (Patient pqejgect, Session s1_t0)\n",
      "2025-06-08 00:49:06 - INFO - Preprocessed signal shape: (302000, 19)\n",
      "2025-06-08 00:49:06 - INFO - Processed 1000 segments so far\n",
      "2025-06-08 00:49:06 - INFO - Session 13 processed in 0.35s\n",
      "2025-06-08 00:49:06 - INFO - Processing session 14/177 (Patient pqejgecy, Session s2_t0)\n",
      "2025-06-08 00:49:06 - INFO - Preprocessed signal shape: (423750, 19)\n",
      "2025-06-08 00:49:06 - INFO - Processed 1100 segments so far\n",
      "2025-06-08 00:49:06 - INFO - Processed 1200 segments so far\n",
      "2025-06-08 00:49:06 - INFO - Session 14 processed in 0.47s\n",
      "2025-06-08 00:49:06 - INFO - Processing session 15/177 (Patient pqejgeel, Session s1_t1)\n",
      "2025-06-08 00:49:07 - INFO - Preprocessed signal shape: (626000, 19)\n",
      "2025-06-08 00:49:07 - INFO - Processed 1300 segments so far\n",
      "2025-06-08 00:49:07 - INFO - Processed 1400 segments so far\n",
      "2025-06-08 00:49:07 - INFO - Session 15 processed in 0.74s\n",
      "2025-06-08 00:49:07 - INFO - Processing session 16/177 (Patient pqejgekv, Session s4_t4)\n",
      "2025-06-08 00:49:07 - INFO - Preprocessed signal shape: (138750, 19)\n",
      "2025-06-08 00:49:07 - INFO - Session 16 processed in 0.17s\n",
      "2025-06-08 00:49:07 - INFO - Processing session 17/177 (Patient pqejgepd, Session s1_t0)\n",
      "2025-06-08 00:49:08 - INFO - Preprocessed signal shape: (856250, 19)\n",
      "2025-06-08 00:49:08 - INFO - Processed 1500 segments so far\n",
      "2025-06-08 00:49:08 - INFO - Processed 1600 segments so far\n",
      "2025-06-08 00:49:08 - INFO - Processed 1700 segments so far\n",
      "2025-06-08 00:49:08 - INFO - Session 17 processed in 0.99s\n",
      "2025-06-08 00:49:08 - INFO - Processing session 18/177 (Patient pqejgetp, Session s11_t1)\n",
      "2025-06-08 00:49:08 - INFO - Preprocessed signal shape: (232000, 19)\n",
      "2025-06-08 00:49:08 - INFO - Processed 1800 segments so far\n",
      "2025-06-08 00:49:08 - INFO - Session 18 processed in 0.32s\n",
      "2025-06-08 00:49:08 - INFO - Processing session 19/177 (Patient pqejgetp, Session s9_t1)\n",
      "2025-06-08 00:49:09 - INFO - Preprocessed signal shape: (211500, 19)\n",
      "2025-06-08 00:49:09 - INFO - Session 19 processed in 0.25s\n",
      "2025-06-08 00:49:09 - INFO - Processing session 20/177 (Patient pqejgevp, Session s1_t0)\n",
      "2025-06-08 00:49:09 - INFO - Preprocessed signal shape: (301750, 19)\n",
      "2025-06-08 00:49:09 - INFO - Processed 1900 segments so far\n",
      "2025-06-08 00:49:09 - INFO - Session 20 processed in 0.35s\n",
      "2025-06-08 00:49:09 - INFO - Processing session 21/177 (Patient pqejgezh, Session s1_t1)\n",
      "2025-06-08 00:49:09 - INFO - Preprocessed signal shape: (299750, 19)\n",
      "2025-06-08 00:49:09 - INFO - Processed 2000 segments so far\n",
      "2025-06-08 00:49:09 - INFO - Session 21 processed in 0.34s\n",
      "2025-06-08 00:49:09 - INFO - Processing session 22/177 (Patient pqejgflo, Session s1_t1)\n",
      "2025-06-08 00:49:10 - INFO - Preprocessed signal shape: (135750, 19)\n",
      "2025-06-08 00:49:10 - INFO - Processed 2100 segments so far\n",
      "2025-06-08 00:49:10 - INFO - Session 22 processed in 0.16s\n",
      "2025-06-08 00:49:10 - INFO - Processing session 23/177 (Patient pqejgflo, Session s1_t2)\n",
      "2025-06-08 00:49:10 - INFO - Preprocessed signal shape: (120500, 19)\n",
      "2025-06-08 00:49:10 - INFO - Session 23 processed in 0.14s\n",
      "2025-06-08 00:49:10 - INFO - Processing session 24/177 (Patient pqejgflo, Session s1_t3)\n",
      "2025-06-08 00:49:10 - INFO - Preprocessed signal shape: (64000, 19)\n",
      "2025-06-08 00:49:10 - INFO - Session 24 processed in 0.11s\n",
      "2025-06-08 00:49:10 - INFO - Processing session 25/177 (Patient pqejgflo, Session s1_t4)\n",
      "2025-06-08 00:49:10 - INFO - Preprocessed signal shape: (235000, 19)\n",
      "2025-06-08 00:49:10 - INFO - Processed 2200 segments so far\n",
      "2025-06-08 00:49:10 - INFO - Session 25 processed in 0.27s\n",
      "2025-06-08 00:49:10 - INFO - Processing session 26/177 (Patient pqejgfmy, Session s2_t0)\n",
      "2025-06-08 00:49:10 - INFO - Preprocessed signal shape: (308000, 19)\n",
      "2025-06-08 00:49:10 - INFO - Processed 2300 segments so far\n",
      "2025-06-08 00:49:10 - INFO - Session 26 processed in 0.35s\n",
      "2025-06-08 00:49:10 - INFO - Processing session 27/177 (Patient pqejgfvy, Session s3_t1)\n",
      "2025-06-08 00:49:10 - INFO - Preprocessed signal shape: (46250, 19)\n",
      "2025-06-08 00:49:11 - INFO - Session 27 processed in 0.06s\n",
      "2025-06-08 00:49:11 - INFO - Processing session 28/177 (Patient pqejggbs, Session s3_t0)\n",
      "2025-06-08 00:49:11 - INFO - Preprocessed signal shape: (357000, 19)\n",
      "2025-06-08 00:49:11 - INFO - Processed 2400 segments so far\n",
      "2025-06-08 00:49:11 - INFO - Processed 2500 segments so far\n",
      "2025-06-08 00:49:11 - INFO - Session 28 processed in 0.41s\n",
      "2025-06-08 00:49:11 - INFO - Processing session 29/177 (Patient pqejggou, Session s1_t1)\n",
      "2025-06-08 00:49:11 - INFO - Preprocessed signal shape: (77500, 19)\n",
      "2025-06-08 00:49:11 - INFO - Session 29 processed in 0.09s\n",
      "2025-06-08 00:49:11 - INFO - Processing session 30/177 (Patient pqejggou, Session s1_t2)\n",
      "2025-06-08 00:49:11 - INFO - Preprocessed signal shape: (308500, 19)\n",
      "2025-06-08 00:49:11 - INFO - Processed 2600 segments so far\n",
      "2025-06-08 00:49:11 - INFO - Session 30 processed in 0.37s\n",
      "2025-06-08 00:49:11 - INFO - Processing session 31/177 (Patient pqejggsb, Session s2_t1)\n",
      "2025-06-08 00:49:11 - INFO - Preprocessed signal shape: (100250, 19)\n",
      "2025-06-08 00:49:11 - INFO - Session 31 processed in 0.12s\n",
      "2025-06-08 00:49:11 - INFO - Processing session 32/177 (Patient pqejggxo, Session s1_t0)\n",
      "2025-06-08 00:49:12 - INFO - Preprocessed signal shape: (301500, 19)\n",
      "2025-06-08 00:49:12 - INFO - Processed 2700 segments so far\n",
      "2025-06-08 00:49:12 - INFO - Session 32 processed in 0.34s\n",
      "2025-06-08 00:49:12 - INFO - Processing session 33/177 (Patient pqejghbu, Session s2_t1)\n",
      "2025-06-08 00:49:12 - INFO - Preprocessed signal shape: (302500, 19)\n",
      "2025-06-08 00:49:12 - INFO - Processed 2800 segments so far\n",
      "2025-06-08 00:49:12 - INFO - Session 33 processed in 0.34s\n",
      "2025-06-08 00:49:12 - INFO - Processing session 34/177 (Patient pqejghja, Session s1_t0)\n",
      "2025-06-08 00:49:12 - INFO - Preprocessed signal shape: (301250, 19)\n",
      "2025-06-08 00:49:12 - INFO - Processed 2900 segments so far\n",
      "2025-06-08 00:49:13 - INFO - Session 34 processed in 0.34s\n",
      "2025-06-08 00:49:13 - INFO - Processing session 35/177 (Patient pqejghou, Session s2_t1)\n",
      "2025-06-08 00:49:13 - INFO - Preprocessed signal shape: (289500, 19)\n",
      "2025-06-08 00:49:13 - INFO - Processed 3000 segments so far\n",
      "2025-06-08 00:49:13 - INFO - Session 35 processed in 0.36s\n",
      "2025-06-08 00:49:13 - INFO - Processing session 36/177 (Patient pqejghrj, Session s1_t0)\n",
      "2025-06-08 00:49:13 - INFO - Preprocessed signal shape: (208250, 19)\n",
      "2025-06-08 00:49:13 - INFO - Processed 3100 segments so far\n",
      "2025-06-08 00:49:13 - INFO - Session 36 processed in 0.24s\n",
      "2025-06-08 00:49:13 - INFO - Processing session 37/177 (Patient pqejghrj, Session s1_t1)\n",
      "2025-06-08 00:49:13 - INFO - Preprocessed signal shape: (138750, 19)\n",
      "2025-06-08 00:49:13 - INFO - Session 37 processed in 0.16s\n",
      "2025-06-08 00:49:13 - INFO - Processing session 38/177 (Patient pqejgijy, Session s3_t0)\n",
      "2025-06-08 00:49:14 - INFO - Preprocessed signal shape: (325750, 19)\n",
      "2025-06-08 00:49:14 - INFO - Processed 3200 segments so far\n",
      "2025-06-08 00:49:14 - INFO - Session 38 processed in 0.36s\n",
      "2025-06-08 00:49:14 - INFO - Processing session 39/177 (Patient pqejgimj, Session s1_t0)\n",
      "2025-06-08 00:49:14 - INFO - Preprocessed signal shape: (367500, 19)\n",
      "2025-06-08 00:49:14 - INFO - Processed 3300 segments so far\n",
      "2025-06-08 00:49:14 - INFO - Processed 3400 segments so far\n",
      "2025-06-08 00:49:14 - INFO - Session 39 processed in 0.43s\n",
      "2025-06-08 00:49:14 - INFO - Processing session 40/177 (Patient pqejgipe, Session s1_t0)\n",
      "2025-06-08 00:49:14 - INFO - Preprocessed signal shape: (139500, 19)\n",
      "2025-06-08 00:49:14 - INFO - Session 40 processed in 0.19s\n",
      "2025-06-08 00:49:14 - INFO - Processing session 41/177 (Patient pqejgipe, Session s1_t1)\n",
      "2025-06-08 00:49:14 - INFO - Preprocessed signal shape: (176000, 19)\n",
      "2025-06-08 00:49:14 - INFO - Processed 3500 segments so far\n",
      "2025-06-08 00:49:14 - INFO - Session 41 processed in 0.21s\n",
      "2025-06-08 00:49:14 - INFO - Processing session 42/177 (Patient pqejgixc, Session s2_t0)\n",
      "2025-06-08 00:49:15 - INFO - Preprocessed signal shape: (326000, 19)\n",
      "2025-06-08 00:49:15 - INFO - Processed 3600 segments so far\n",
      "2025-06-08 00:49:15 - INFO - Session 42 processed in 0.37s\n",
      "2025-06-08 00:49:15 - INFO - Processing session 43/177 (Patient pqejgjga, Session s1_t1)\n",
      "2025-06-08 00:49:15 - INFO - Preprocessed signal shape: (530750, 19)\n",
      "2025-06-08 00:49:15 - INFO - Processed 3700 segments so far\n",
      "2025-06-08 00:49:15 - INFO - Session 43 processed in 0.61s\n",
      "2025-06-08 00:49:15 - INFO - Processing session 44/177 (Patient pqejgjhk, Session s1_t0)\n",
      "2025-06-08 00:49:16 - INFO - Preprocessed signal shape: (58750, 19)\n",
      "2025-06-08 00:49:16 - INFO - Processed 3800 segments so far\n",
      "2025-06-08 00:49:16 - INFO - Session 44 processed in 0.08s\n",
      "2025-06-08 00:49:16 - INFO - Processing session 45/177 (Patient pqejgjjp, Session s1_t0)\n",
      "2025-06-08 00:49:16 - INFO - Preprocessed signal shape: (13750, 19)\n",
      "2025-06-08 00:49:16 - INFO - Session 45 processed in 0.02s\n",
      "2025-06-08 00:49:16 - INFO - Processing session 46/177 (Patient pqejgjjp, Session s2_t0)\n",
      "2025-06-08 00:49:16 - INFO - Preprocessed signal shape: (53500, 19)\n",
      "2025-06-08 00:49:16 - INFO - Session 46 processed in 0.06s\n",
      "2025-06-08 00:49:16 - INFO - Processing session 47/177 (Patient pqejgjpx, Session s15_t0)\n",
      "2025-06-08 00:49:16 - INFO - Preprocessed signal shape: (143750, 19)\n",
      "2025-06-08 00:49:16 - INFO - Session 47 processed in 0.20s\n",
      "2025-06-08 00:49:16 - INFO - Processing session 48/177 (Patient pqejgkfo, Session s1_t1)\n",
      "2025-06-08 00:49:16 - INFO - Preprocessed signal shape: (316250, 19)\n",
      "2025-06-08 00:49:16 - INFO - Processed 3900 segments so far\n",
      "2025-06-08 00:49:16 - INFO - Session 48 processed in 0.36s\n",
      "2025-06-08 00:49:16 - INFO - Processing session 49/177 (Patient pqejgkfo, Session s2_t0)\n",
      "2025-06-08 00:49:16 - INFO - Preprocessed signal shape: (43250, 19)\n",
      "2025-06-08 00:49:16 - INFO - Processed 4000 segments so far\n",
      "2025-06-08 00:49:16 - INFO - Session 49 processed in 0.06s\n",
      "2025-06-08 00:49:16 - INFO - Processing session 50/177 (Patient pqejgkfo, Session s3_t2)\n",
      "2025-06-08 00:49:16 - INFO - Preprocessed signal shape: (22750, 19)\n",
      "2025-06-08 00:49:16 - INFO - Session 50 processed in 0.03s\n",
      "2025-06-08 00:49:16 - INFO - Processing session 51/177 (Patient pqejgkfo, Session s3_t3)\n",
      "2025-06-08 00:49:16 - INFO - Preprocessed signal shape: (97750, 19)\n",
      "2025-06-08 00:49:16 - INFO - Session 51 processed in 0.11s\n",
      "2025-06-08 00:49:16 - INFO - Processing session 52/177 (Patient pqejgkfo, Session s3_t4)\n",
      "2025-06-08 00:49:16 - INFO - Preprocessed signal shape: (15000, 19)\n",
      "2025-06-08 00:49:16 - INFO - Session 52 processed in 0.02s\n",
      "2025-06-08 00:49:16 - INFO - Processing session 53/177 (Patient pqejgkps, Session s1_t0)\n",
      "2025-06-08 00:49:16 - INFO - Preprocessed signal shape: (5750, 19)\n",
      "2025-06-08 00:49:16 - INFO - Session 53 processed in 0.01s\n",
      "2025-06-08 00:49:16 - INFO - Processing session 54/177 (Patient pqejgkre, Session s1_t0)\n",
      "2025-06-08 00:49:16 - INFO - Preprocessed signal shape: (58500, 19)\n",
      "2025-06-08 00:49:16 - INFO - Session 54 processed in 0.07s\n",
      "2025-06-08 00:49:16 - INFO - Processing session 55/177 (Patient pqejgkvc, Session s10_t0)\n",
      "2025-06-08 00:49:17 - INFO - Preprocessed signal shape: (53750, 19)\n",
      "2025-06-08 00:49:17 - INFO - Session 55 processed in 0.08s\n",
      "2025-06-08 00:49:17 - INFO - Processing session 56/177 (Patient pqejgkvc, Session s10_t1)\n",
      "2025-06-08 00:49:17 - INFO - Preprocessed signal shape: (41250, 19)\n",
      "2025-06-08 00:49:17 - INFO - Session 56 processed in 0.05s\n",
      "2025-06-08 00:49:17 - INFO - Processing session 57/177 (Patient pqejgkvc, Session s10_t2)\n",
      "2025-06-08 00:49:17 - INFO - Preprocessed signal shape: (76250, 19)\n",
      "2025-06-08 00:49:17 - INFO - Processed 4100 segments so far\n",
      "2025-06-08 00:49:17 - INFO - Session 57 processed in 0.09s\n",
      "2025-06-08 00:49:17 - INFO - Processing session 58/177 (Patient pqejgkvc, Session s9_t1)\n",
      "2025-06-08 00:49:17 - INFO - Preprocessed signal shape: (262000, 19)\n",
      "2025-06-08 00:49:17 - INFO - Processed 4200 segments so far\n",
      "2025-06-08 00:49:17 - INFO - Session 58 processed in 0.33s\n",
      "2025-06-08 00:49:17 - INFO - Processing session 59/177 (Patient pqejgkvc, Session s9_t2)\n",
      "2025-06-08 00:49:17 - INFO - Preprocessed signal shape: (202250, 19)\n",
      "2025-06-08 00:49:17 - INFO - Session 59 processed in 0.23s\n",
      "2025-06-08 00:49:17 - INFO - Processing session 60/177 (Patient pqejgkvd, Session s8_t0)\n",
      "2025-06-08 00:49:17 - INFO - Preprocessed signal shape: (150250, 19)\n",
      "2025-06-08 00:49:17 - INFO - Processed 4300 segments so far\n",
      "2025-06-08 00:49:17 - INFO - Session 60 processed in 0.19s\n",
      "2025-06-08 00:49:17 - INFO - Processing session 61/177 (Patient pqejgkwc, Session s1_t0)\n",
      "2025-06-08 00:49:18 - INFO - Preprocessed signal shape: (362250, 19)\n",
      "2025-06-08 00:49:18 - INFO - Processed 4400 segments so far\n",
      "2025-06-08 00:49:18 - INFO - Session 61 processed in 0.42s\n",
      "2025-06-08 00:49:18 - INFO - Processing session 62/177 (Patient pqejgkwc, Session s2_t0)\n",
      "2025-06-08 00:49:18 - INFO - Preprocessed signal shape: (136250, 19)\n",
      "2025-06-08 00:49:18 - INFO - Session 62 processed in 0.15s\n",
      "2025-06-08 00:49:18 - INFO - Processing session 63/177 (Patient pqejgkwc, Session s2_t1)\n",
      "2025-06-08 00:49:18 - INFO - Preprocessed signal shape: (318750, 19)\n",
      "2025-06-08 00:49:18 - INFO - Processed 4500 segments so far\n",
      "2025-06-08 00:49:18 - INFO - Session 63 processed in 0.42s\n",
      "2025-06-08 00:49:18 - INFO - Processing session 64/177 (Patient pqejgkwc, Session s2_t3)\n",
      "2025-06-08 00:49:19 - INFO - Preprocessed signal shape: (126250, 19)\n",
      "2025-06-08 00:49:19 - INFO - Processed 4600 segments so far\n",
      "2025-06-08 00:49:19 - INFO - Session 64 processed in 0.15s\n",
      "2025-06-08 00:49:19 - INFO - Processing session 65/177 (Patient pqejgkwc, Session s2_t4)\n",
      "2025-06-08 00:49:19 - INFO - Preprocessed signal shape: (83500, 19)\n",
      "2025-06-08 00:49:19 - INFO - Session 65 processed in 0.11s\n",
      "2025-06-08 00:49:19 - INFO - Processing session 66/177 (Patient pqejgkwc, Session s2_t7)\n",
      "2025-06-08 00:49:19 - INFO - Preprocessed signal shape: (146000, 19)\n",
      "2025-06-08 00:49:19 - INFO - Processed 4700 segments so far\n",
      "2025-06-08 00:49:19 - INFO - Session 66 processed in 0.17s\n",
      "2025-06-08 00:49:19 - INFO - Processing session 67/177 (Patient pqejglbv, Session s2_t2)\n",
      "2025-06-08 00:49:19 - INFO - Preprocessed signal shape: (51250, 19)\n",
      "2025-06-08 00:49:19 - INFO - Session 67 processed in 0.07s\n",
      "2025-06-08 00:49:19 - INFO - Processing session 68/177 (Patient pqejglbv, Session s2_t4)\n",
      "2025-06-08 00:49:19 - INFO - Preprocessed signal shape: (26250, 19)\n",
      "2025-06-08 00:49:19 - INFO - Session 68 processed in 0.04s\n",
      "2025-06-08 00:49:19 - INFO - Processing session 69/177 (Patient pqejglbv, Session s2_t5)\n",
      "2025-06-08 00:49:19 - INFO - Preprocessed signal shape: (36250, 19)\n",
      "2025-06-08 00:49:19 - INFO - Session 69 processed in 0.05s\n",
      "2025-06-08 00:49:19 - INFO - Processing session 70/177 (Patient pqejglbv, Session s2_t6)\n",
      "2025-06-08 00:49:19 - INFO - Preprocessed signal shape: (78500, 19)\n",
      "2025-06-08 00:49:19 - INFO - Session 70 processed in 0.09s\n",
      "2025-06-08 00:49:19 - INFO - Processing session 71/177 (Patient pqejglfr, Session s1_t0)\n",
      "2025-06-08 00:49:20 - INFO - Preprocessed signal shape: (423500, 19)\n",
      "2025-06-08 00:49:20 - INFO - Processed 4800 segments so far\n",
      "2025-06-08 00:49:20 - INFO - Processed 4900 segments so far\n",
      "2025-06-08 00:49:20 - INFO - Session 71 processed in 0.56s\n",
      "2025-06-08 00:49:20 - INFO - Processing session 72/177 (Patient pqejglhb, Session s4_t0)\n",
      "2025-06-08 00:49:20 - INFO - Preprocessed signal shape: (315750, 19)\n",
      "2025-06-08 00:49:20 - INFO - Processed 5000 segments so far\n",
      "2025-06-08 00:49:20 - INFO - Session 72 processed in 0.37s\n",
      "2025-06-08 00:49:20 - INFO - Processing session 73/177 (Patient pqejglhb, Session s6_t0)\n",
      "2025-06-08 00:49:20 - INFO - Preprocessed signal shape: (153000, 19)\n",
      "2025-06-08 00:49:20 - INFO - Session 73 processed in 0.21s\n",
      "2025-06-08 00:49:20 - INFO - Processing session 74/177 (Patient pqejglhb, Session s6_t1)\n",
      "2025-06-08 00:49:20 - INFO - Preprocessed signal shape: (150250, 19)\n",
      "2025-06-08 00:49:20 - INFO - Processed 5100 segments so far\n",
      "2025-06-08 00:49:21 - INFO - Session 74 processed in 0.23s\n",
      "2025-06-08 00:49:21 - INFO - Processing session 75/177 (Patient pqejgljo, Session s1_t1)\n",
      "2025-06-08 00:49:21 - INFO - Preprocessed signal shape: (291250, 19)\n",
      "2025-06-08 00:49:21 - INFO - Processed 5200 segments so far\n",
      "2025-06-08 00:49:21 - INFO - Session 75 processed in 0.35s\n",
      "2025-06-08 00:49:21 - INFO - Processing session 76/177 (Patient pqejgljr, Session s8_t2)\n",
      "2025-06-08 00:49:21 - INFO - Preprocessed signal shape: (54500, 19)\n",
      "2025-06-08 00:49:21 - INFO - Session 76 processed in 0.07s\n",
      "2025-06-08 00:49:21 - INFO - Processing session 77/177 (Patient pqejgljr, Session s8_t3)\n",
      "2025-06-08 00:49:21 - INFO - Preprocessed signal shape: (55000, 19)\n",
      "2025-06-08 00:49:21 - INFO - Session 77 processed in 0.07s\n",
      "2025-06-08 00:49:21 - INFO - Processing session 78/177 (Patient pqejgljr, Session s8_t4)\n",
      "2025-06-08 00:49:21 - INFO - Preprocessed signal shape: (54250, 19)\n",
      "2025-06-08 00:49:21 - INFO - Session 78 processed in 0.07s\n",
      "2025-06-08 00:49:21 - INFO - Processing session 79/177 (Patient pqejgljr, Session s8_t5)\n",
      "2025-06-08 00:49:21 - INFO - Preprocessed signal shape: (60750, 19)\n",
      "2025-06-08 00:49:21 - INFO - Session 79 processed in 0.08s\n",
      "2025-06-08 00:49:21 - INFO - Processing session 80/177 (Patient pqejgljr, Session s8_t6)\n",
      "2025-06-08 00:49:21 - INFO - Preprocessed signal shape: (56250, 19)\n",
      "2025-06-08 00:49:21 - INFO - Processed 5300 segments so far\n",
      "2025-06-08 00:49:21 - INFO - Session 80 processed in 0.08s\n",
      "2025-06-08 00:49:21 - INFO - Processing session 81/177 (Patient pqejglle, Session s3_t2)\n",
      "2025-06-08 00:49:21 - INFO - Preprocessed signal shape: (246250, 19)\n",
      "2025-06-08 00:49:22 - INFO - Session 81 processed in 0.30s\n",
      "2025-06-08 00:49:22 - INFO - Processing session 82/177 (Patient pqejglle, Session s3_t3)\n",
      "2025-06-08 00:49:22 - INFO - Preprocessed signal shape: (256250, 19)\n",
      "2025-06-08 00:49:22 - INFO - Processed 5400 segments so far\n",
      "2025-06-08 00:49:22 - INFO - Session 82 processed in 0.34s\n",
      "2025-06-08 00:49:22 - INFO - Processing session 83/177 (Patient pqejglle, Session s3_t5)\n",
      "2025-06-08 00:49:22 - INFO - Preprocessed signal shape: (108250, 19)\n",
      "2025-06-08 00:49:22 - INFO - Processed 5500 segments so far\n",
      "2025-06-08 00:49:22 - INFO - Session 83 processed in 0.14s\n",
      "2025-06-08 00:49:22 - INFO - Processing session 84/177 (Patient pqejgllr, Session s1_t0)\n",
      "2025-06-08 00:49:22 - INFO - Preprocessed signal shape: (302750, 19)\n",
      "2025-06-08 00:49:22 - INFO - Processed 5600 segments so far\n",
      "2025-06-08 00:49:22 - INFO - Session 84 processed in 0.35s\n",
      "2025-06-08 00:49:22 - INFO - Processing session 85/177 (Patient pqejglmc, Session s1_t0)\n",
      "2025-06-08 00:49:23 - INFO - Preprocessed signal shape: (174750, 19)\n",
      "2025-06-08 00:49:23 - INFO - Session 85 processed in 0.21s\n",
      "2025-06-08 00:49:23 - INFO - Processing session 86/177 (Patient pqejglmc, Session s1_t1)\n",
      "2025-06-08 00:49:23 - INFO - Preprocessed signal shape: (152000, 19)\n",
      "2025-06-08 00:49:23 - INFO - Processed 5700 segments so far\n",
      "2025-06-08 00:49:23 - INFO - Session 86 processed in 0.18s\n",
      "2025-06-08 00:49:23 - INFO - Processing session 87/177 (Patient pqejglmt, Session s5_t7)\n",
      "2025-06-08 00:49:23 - INFO - Preprocessed signal shape: (300750, 19)\n",
      "2025-06-08 00:49:23 - INFO - Processed 5800 segments so far\n",
      "2025-06-08 00:49:23 - INFO - Session 87 processed in 0.37s\n",
      "2025-06-08 00:49:23 - INFO - Processing session 88/177 (Patient pqejglmt, Session s6_t2)\n",
      "2025-06-08 00:49:23 - INFO - Preprocessed signal shape: (315250, 19)\n",
      "2025-06-08 00:49:23 - INFO - Processed 5900 segments so far\n",
      "2025-06-08 00:49:24 - INFO - Session 88 processed in 0.37s\n",
      "2025-06-08 00:49:24 - INFO - Processing session 89/177 (Patient pqejglmt, Session s6_t6)\n",
      "2025-06-08 00:49:24 - INFO - Preprocessed signal shape: (597250, 19)\n",
      "2025-06-08 00:49:24 - INFO - Processed 6000 segments so far\n",
      "2025-06-08 00:49:24 - INFO - Processed 6100 segments so far\n",
      "2025-06-08 00:49:24 - INFO - Session 89 processed in 0.72s\n",
      "2025-06-08 00:49:24 - INFO - Processing session 90/177 (Patient pqejglvd, Session s5_t1)\n",
      "2025-06-08 00:49:25 - INFO - Preprocessed signal shape: (310000, 19)\n",
      "2025-06-08 00:49:25 - INFO - Processed 6200 segments so far\n",
      "2025-06-08 00:49:25 - INFO - Session 90 processed in 0.36s\n",
      "2025-06-08 00:49:25 - INFO - Processing session 91/177 (Patient pqejgmhh, Session s3_t0)\n",
      "2025-06-08 00:49:25 - INFO - Preprocessed signal shape: (317000, 19)\n",
      "2025-06-08 00:49:25 - INFO - Processed 6300 segments so far\n",
      "2025-06-08 00:49:25 - INFO - Session 91 processed in 0.39s\n",
      "2025-06-08 00:49:25 - INFO - Processing session 92/177 (Patient pqejgmke, Session s1_t0)\n",
      "2025-06-08 00:49:25 - INFO - Preprocessed signal shape: (562250, 19)\n",
      "2025-06-08 00:49:26 - INFO - Processed 6400 segments so far\n",
      "2025-06-08 00:49:26 - INFO - Processed 6500 segments so far\n",
      "2025-06-08 00:49:26 - INFO - Session 92 processed in 0.62s\n",
      "2025-06-08 00:49:26 - INFO - Processing session 93/177 (Patient pqejgmke, Session s2_t1)\n",
      "2025-06-08 00:49:26 - INFO - Preprocessed signal shape: (73250, 19)\n",
      "2025-06-08 00:49:26 - INFO - Session 93 processed in 0.10s\n",
      "2025-06-08 00:49:26 - INFO - Processing session 94/177 (Patient pqejgmke, Session s2_t2)\n",
      "2025-06-08 00:49:26 - INFO - Preprocessed signal shape: (88750, 19)\n",
      "2025-06-08 00:49:26 - INFO - Session 94 processed in 0.11s\n",
      "2025-06-08 00:49:26 - INFO - Processing session 95/177 (Patient pqejgmle, Session s2_t1)\n",
      "2025-06-08 00:49:26 - INFO - Preprocessed signal shape: (256250, 19)\n",
      "2025-06-08 00:49:26 - INFO - Processed 6600 segments so far\n",
      "2025-06-08 00:49:26 - INFO - Session 95 processed in 0.33s\n",
      "2025-06-08 00:49:26 - INFO - Processing session 96/177 (Patient pqejgncp, Session s1_t0)\n",
      "2025-06-08 00:49:26 - INFO - Preprocessed signal shape: (344000, 19)\n",
      "2025-06-08 00:49:26 - INFO - Processed 6700 segments so far\n",
      "2025-06-08 00:49:27 - INFO - Session 96 processed in 0.39s\n",
      "2025-06-08 00:49:27 - INFO - Processing session 97/177 (Patient pqejgnkm, Session s2_t0)\n",
      "2025-06-08 00:49:27 - INFO - Preprocessed signal shape: (473250, 19)\n",
      "2025-06-08 00:49:27 - INFO - Processed 6800 segments so far\n",
      "2025-06-08 00:49:27 - INFO - Processed 6900 segments so far\n",
      "2025-06-08 00:49:27 - INFO - Session 97 processed in 0.54s\n",
      "2025-06-08 00:49:27 - INFO - Processing session 98/177 (Patient pqejgnkx, Session s2_t1)\n",
      "2025-06-08 00:49:27 - INFO - Preprocessed signal shape: (75000, 19)\n",
      "2025-06-08 00:49:27 - INFO - Session 98 processed in 0.09s\n",
      "2025-06-08 00:49:27 - INFO - Processing session 99/177 (Patient pqejgnkx, Session s2_t2)\n",
      "2025-06-08 00:49:27 - INFO - Preprocessed signal shape: (68500, 19)\n",
      "2025-06-08 00:49:27 - INFO - Session 99 processed in 0.08s\n",
      "2025-06-08 00:49:27 - INFO - Processing session 100/177 (Patient pqejgnkx, Session s2_t3)\n",
      "2025-06-08 00:49:28 - INFO - Preprocessed signal shape: (317250, 19)\n",
      "2025-06-08 00:49:28 - INFO - Processed 7000 segments so far\n",
      "2025-06-08 00:49:28 - INFO - Session 100 processed in 0.38s\n",
      "2025-06-08 00:49:28 - INFO - Processing session 101/177 (Patient pqejgnkx, Session s2_t4)\n",
      "2025-06-08 00:49:28 - INFO - Preprocessed signal shape: (158000, 19)\n",
      "2025-06-08 00:49:28 - INFO - Processed 7100 segments so far\n",
      "2025-06-08 00:49:28 - INFO - Session 101 processed in 0.20s\n",
      "2025-06-08 00:49:28 - INFO - Processing session 102/177 (Patient pqejgnkx, Session s2_t5)\n",
      "2025-06-08 00:49:28 - INFO - Preprocessed signal shape: (75000, 19)\n",
      "2025-06-08 00:49:28 - INFO - Session 102 processed in 0.09s\n",
      "2025-06-08 00:49:28 - INFO - Processing session 103/177 (Patient pqejgnkx, Session s2_t6)\n",
      "2025-06-08 00:49:28 - INFO - Preprocessed signal shape: (160500, 19)\n",
      "2025-06-08 00:49:28 - INFO - Processed 7200 segments so far\n",
      "2025-06-08 00:49:28 - INFO - Session 103 processed in 0.20s\n",
      "2025-06-08 00:49:28 - INFO - Processing session 104/177 (Patient pqejgnkx, Session s2_t7)\n",
      "2025-06-08 00:49:28 - INFO - Preprocessed signal shape: (154000, 19)\n",
      "2025-06-08 00:49:28 - INFO - Session 104 processed in 0.18s\n",
      "2025-06-08 00:49:28 - INFO - Processing session 105/177 (Patient pqejgnor, Session s3_t0)\n",
      "2025-06-08 00:49:29 - INFO - Preprocessed signal shape: (602750, 19)\n",
      "2025-06-08 00:49:29 - INFO - Processed 7300 segments so far\n",
      "2025-06-08 00:49:29 - INFO - Processed 7400 segments so far\n",
      "2025-06-08 00:49:29 - INFO - Session 105 processed in 0.73s\n",
      "2025-06-08 00:49:29 - INFO - Processing session 106/177 (Patient pqejgnrf, Session s2_t0)\n",
      "2025-06-08 00:49:29 - INFO - Preprocessed signal shape: (25250, 19)\n",
      "2025-06-08 00:49:29 - INFO - Session 106 processed in 0.03s\n",
      "2025-06-08 00:49:29 - INFO - Processing session 107/177 (Patient pqejgnrf, Session s3_t1)\n",
      "2025-06-08 00:49:29 - INFO - Preprocessed signal shape: (56750, 19)\n",
      "2025-06-08 00:49:29 - INFO - Session 107 processed in 0.10s\n",
      "2025-06-08 00:49:29 - INFO - Processing session 108/177 (Patient pqejgnuq, Session s5_t0)\n",
      "2025-06-08 00:49:29 - INFO - Preprocessed signal shape: (310250, 19)\n",
      "2025-06-08 00:49:29 - INFO - Processed 7500 segments so far\n",
      "2025-06-08 00:49:30 - INFO - Session 108 processed in 0.37s\n",
      "2025-06-08 00:49:30 - INFO - Processing session 109/177 (Patient pqejgnvg, Session s3_t0)\n",
      "2025-06-08 00:49:30 - INFO - Preprocessed signal shape: (389500, 19)\n",
      "2025-06-08 00:49:30 - INFO - Processed 7600 segments so far\n",
      "2025-06-08 00:49:30 - INFO - Processed 7700 segments so far\n",
      "2025-06-08 00:49:30 - INFO - Session 109 processed in 0.44s\n",
      "2025-06-08 00:49:30 - INFO - Processing session 110/177 (Patient pqejgnvu, Session s2_t0)\n",
      "2025-06-08 00:49:30 - INFO - Preprocessed signal shape: (371250, 19)\n",
      "2025-06-08 00:49:30 - INFO - Processed 7800 segments so far\n",
      "2025-06-08 00:49:30 - INFO - Session 110 processed in 0.45s\n",
      "2025-06-08 00:49:30 - INFO - Processing session 111/177 (Patient pqejgodj, Session s1_t0)\n",
      "2025-06-08 00:49:31 - INFO - Preprocessed signal shape: (361000, 19)\n",
      "2025-06-08 00:49:31 - INFO - Processed 7900 segments so far\n",
      "2025-06-08 00:49:31 - INFO - Session 111 processed in 0.41s\n",
      "2025-06-08 00:49:31 - INFO - Processing session 112/177 (Patient pqejgojo, Session s2_t2)\n",
      "2025-06-08 00:49:31 - INFO - Preprocessed signal shape: (183000, 19)\n",
      "2025-06-08 00:49:31 - INFO - Processed 8000 segments so far\n",
      "2025-06-08 00:49:31 - INFO - Session 112 processed in 0.22s\n",
      "2025-06-08 00:49:31 - INFO - Processing session 113/177 (Patient pqejgojo, Session s4_t0)\n",
      "2025-06-08 00:49:32 - INFO - Preprocessed signal shape: (794000, 19)\n",
      "2025-06-08 00:49:32 - INFO - Processed 8100 segments so far\n",
      "2025-06-08 00:49:32 - INFO - Processed 8200 segments so far\n",
      "2025-06-08 00:49:32 - INFO - Session 113 processed in 1.09s\n",
      "2025-06-08 00:49:32 - INFO - Processing session 114/177 (Patient pqejgokj, Session s3_t3)\n",
      "2025-06-08 00:49:32 - INFO - Preprocessed signal shape: (181500, 19)\n",
      "2025-06-08 00:49:32 - INFO - Processed 8300 segments so far\n",
      "2025-06-08 00:49:32 - INFO - Session 114 processed in 0.25s\n",
      "2025-06-08 00:49:32 - INFO - Processing session 115/177 (Patient pqejgokj, Session s4_t0)\n",
      "2025-06-08 00:49:33 - INFO - Preprocessed signal shape: (239750, 19)\n",
      "2025-06-08 00:49:33 - INFO - Processed 8400 segments so far\n",
      "2025-06-08 00:49:33 - INFO - Session 115 processed in 0.30s\n",
      "2025-06-08 00:49:33 - INFO - Processing session 116/177 (Patient pqejgokj, Session s4_t2)\n",
      "2025-06-08 00:49:33 - INFO - Preprocessed signal shape: (225250, 19)\n",
      "2025-06-08 00:49:33 - INFO - Processed 8500 segments so far\n",
      "2025-06-08 00:49:33 - INFO - Session 116 processed in 0.26s\n",
      "2025-06-08 00:49:33 - INFO - Processing session 117/177 (Patient pqejgokj, Session s4_t3)\n",
      "2025-06-08 00:49:33 - INFO - Preprocessed signal shape: (198500, 19)\n",
      "2025-06-08 00:49:33 - INFO - Session 117 processed in 0.23s\n",
      "2025-06-08 00:49:33 - INFO - Processing session 118/177 (Patient pqejgoli, Session s2_t0)\n",
      "2025-06-08 00:49:34 - INFO - Preprocessed signal shape: (346500, 19)\n",
      "2025-06-08 00:49:34 - INFO - Processed 8600 segments so far\n",
      "2025-06-08 00:49:34 - INFO - Session 118 processed in 0.40s\n",
      "2025-06-08 00:49:34 - INFO - Processing session 119/177 (Patient pqejgoot, Session s1_t0)\n",
      "2025-06-08 00:49:34 - INFO - Preprocessed signal shape: (312000, 19)\n",
      "2025-06-08 00:49:34 - INFO - Processed 8700 segments so far\n",
      "2025-06-08 00:49:34 - INFO - Session 119 processed in 0.38s\n",
      "2025-06-08 00:49:34 - INFO - Processing session 120/177 (Patient pqejgorg, Session s5_t0)\n",
      "2025-06-08 00:49:34 - INFO - Preprocessed signal shape: (150250, 19)\n",
      "2025-06-08 00:49:34 - INFO - Processed 8800 segments so far\n",
      "2025-06-08 00:49:34 - INFO - Session 120 processed in 0.18s\n",
      "2025-06-08 00:49:34 - INFO - Processing session 121/177 (Patient pqejgorg, Session s5_t1)\n",
      "2025-06-08 00:49:34 - INFO - Preprocessed signal shape: (150250, 19)\n",
      "2025-06-08 00:49:34 - INFO - Session 121 processed in 0.18s\n",
      "2025-06-08 00:49:34 - INFO - Processing session 122/177 (Patient pqejgoti, Session s1_t1)\n",
      "2025-06-08 00:49:35 - INFO - Preprocessed signal shape: (314500, 19)\n",
      "2025-06-08 00:49:35 - INFO - Processed 8900 segments so far\n",
      "2025-06-08 00:49:35 - INFO - Session 122 processed in 0.35s\n",
      "2025-06-08 00:49:35 - INFO - Processing session 123/177 (Patient pqejgpeg, Session s1_t0)\n",
      "2025-06-08 00:49:35 - INFO - Preprocessed signal shape: (278750, 19)\n",
      "2025-06-08 00:49:35 - INFO - Processed 9000 segments so far\n",
      "2025-06-08 00:49:35 - INFO - Session 123 processed in 0.32s\n",
      "2025-06-08 00:49:35 - INFO - Processing session 124/177 (Patient pqejgpfm, Session s4_t2)\n",
      "2025-06-08 00:49:35 - INFO - Preprocessed signal shape: (318000, 19)\n",
      "2025-06-08 00:49:35 - INFO - Processed 9100 segments so far\n",
      "2025-06-08 00:49:35 - INFO - Session 124 processed in 0.40s\n",
      "2025-06-08 00:49:35 - INFO - Processing session 125/177 (Patient pqejgpfm, Session s4_t4)\n",
      "2025-06-08 00:49:36 - INFO - Preprocessed signal shape: (397750, 19)\n",
      "2025-06-08 00:49:36 - INFO - Processed 9200 segments so far\n",
      "2025-06-08 00:49:36 - INFO - Processed 9300 segments so far\n",
      "2025-06-08 00:49:36 - INFO - Session 125 processed in 0.48s\n",
      "2025-06-08 00:49:36 - INFO - Processing session 126/177 (Patient pqejgpfm, Session s4_t5)\n",
      "2025-06-08 00:49:36 - INFO - Preprocessed signal shape: (370750, 19)\n",
      "2025-06-08 00:49:36 - INFO - Processed 9400 segments so far\n",
      "2025-06-08 00:49:36 - INFO - Session 126 processed in 0.44s\n",
      "2025-06-08 00:49:36 - INFO - Processing session 127/177 (Patient pqejgphr, Session s1_t1)\n",
      "2025-06-08 00:49:36 - INFO - Preprocessed signal shape: (103000, 19)\n",
      "2025-06-08 00:49:36 - INFO - Session 127 processed in 0.12s\n",
      "2025-06-08 00:49:36 - INFO - Processing session 128/177 (Patient pqejgphr, Session s1_t2)\n",
      "2025-06-08 00:49:37 - INFO - Preprocessed signal shape: (178750, 19)\n",
      "2025-06-08 00:49:37 - INFO - Processed 9500 segments so far\n",
      "2025-06-08 00:49:37 - INFO - Session 128 processed in 0.25s\n",
      "2025-06-08 00:49:37 - INFO - Processing session 129/177 (Patient pqejgpjq, Session s2_t0)\n",
      "2025-06-08 00:49:37 - INFO - Preprocessed signal shape: (300750, 19)\n",
      "2025-06-08 00:49:37 - INFO - Processed 9600 segments so far\n",
      "2025-06-08 00:49:37 - INFO - Session 129 processed in 0.34s\n",
      "2025-06-08 00:49:37 - INFO - Processing session 130/177 (Patient pqejgpjq, Session s4_t2)\n",
      "2025-06-08 00:49:37 - INFO - Preprocessed signal shape: (164750, 19)\n",
      "2025-06-08 00:49:37 - INFO - Session 130 processed in 0.20s\n",
      "2025-06-08 00:49:37 - INFO - Processing session 131/177 (Patient pqejgpju, Session s2_t0)\n",
      "2025-06-08 00:49:37 - INFO - Preprocessed signal shape: (268750, 19)\n",
      "2025-06-08 00:49:37 - INFO - Processed 9700 segments so far\n",
      "2025-06-08 00:49:38 - INFO - Session 131 processed in 0.32s\n",
      "2025-06-08 00:49:38 - INFO - Processing session 132/177 (Patient pqejgpml, Session s2_t0)\n",
      "2025-06-08 00:49:38 - INFO - Preprocessed signal shape: (330500, 19)\n",
      "2025-06-08 00:49:38 - INFO - Processed 9800 segments so far\n",
      "2025-06-08 00:49:38 - INFO - Session 132 processed in 0.37s\n",
      "2025-06-08 00:49:38 - INFO - Processing session 133/177 (Patient pqejgpml, Session s3_t2)\n",
      "2025-06-08 00:49:38 - INFO - Preprocessed signal shape: (150250, 19)\n",
      "2025-06-08 00:49:38 - INFO - Processed 9900 segments so far\n",
      "2025-06-08 00:49:38 - INFO - Session 133 processed in 0.17s\n",
      "2025-06-08 00:49:38 - INFO - Processing session 134/177 (Patient pqejgpml, Session s3_t6)\n",
      "2025-06-08 00:49:38 - INFO - Preprocessed signal shape: (150250, 19)\n",
      "2025-06-08 00:49:38 - INFO - Session 134 processed in 0.20s\n",
      "2025-06-08 00:49:38 - INFO - Processing session 135/177 (Patient pqejgpmm, Session s4_t10)\n",
      "2025-06-08 00:49:38 - INFO - Preprocessed signal shape: (144500, 19)\n",
      "2025-06-08 00:49:38 - INFO - Processed 10000 segments so far\n",
      "2025-06-08 00:49:38 - INFO - Session 135 processed in 0.17s\n",
      "2025-06-08 00:49:38 - INFO - Processing session 136/177 (Patient pqejgpru, Session s4_t1)\n",
      "2025-06-08 00:49:39 - INFO - Preprocessed signal shape: (150250, 19)\n",
      "2025-06-08 00:49:39 - INFO - Session 136 processed in 0.18s\n",
      "2025-06-08 00:49:39 - INFO - Processing session 137/177 (Patient pqejgpru, Session s4_t2)\n",
      "2025-06-08 00:49:39 - INFO - Preprocessed signal shape: (150250, 19)\n",
      "2025-06-08 00:49:39 - INFO - Processed 10100 segments so far\n",
      "2025-06-08 00:49:39 - INFO - Session 137 processed in 0.18s\n",
      "2025-06-08 00:49:39 - INFO - Processing session 138/177 (Patient pqejgqbn, Session s11_t1)\n",
      "2025-06-08 00:49:39 - INFO - Preprocessed signal shape: (230000, 19)\n",
      "2025-06-08 00:49:39 - INFO - Processed 10200 segments so far\n",
      "2025-06-08 00:49:39 - INFO - Session 138 processed in 0.26s\n",
      "2025-06-08 00:49:39 - INFO - Processing session 139/177 (Patient pqejgqbn, Session s5_t3)\n",
      "2025-06-08 00:49:39 - INFO - Preprocessed signal shape: (247750, 19)\n",
      "2025-06-08 00:49:39 - INFO - Session 139 processed in 0.29s\n",
      "2025-06-08 00:49:39 - INFO - Processing session 140/177 (Patient pqejgqbn, Session s5_t5)\n",
      "2025-06-08 00:49:40 - INFO - Preprocessed signal shape: (211500, 19)\n",
      "2025-06-08 00:49:40 - INFO - Processed 10300 segments so far\n",
      "2025-06-08 00:49:40 - INFO - Session 140 processed in 0.27s\n",
      "2025-06-08 00:49:40 - INFO - Processing session 141/177 (Patient pqejgqbn, Session s5_t8)\n",
      "2025-06-08 00:49:40 - INFO - Preprocessed signal shape: (197750, 19)\n",
      "2025-06-08 00:49:40 - INFO - Processed 10400 segments so far\n",
      "2025-06-08 00:49:40 - INFO - Session 141 processed in 0.24s\n",
      "2025-06-08 00:49:40 - INFO - Processing session 142/177 (Patient pqejgqbn, Session s8_t3)\n",
      "2025-06-08 00:49:40 - INFO - Preprocessed signal shape: (150250, 19)\n",
      "2025-06-08 00:49:40 - INFO - Session 142 processed in 0.18s\n",
      "2025-06-08 00:49:40 - INFO - Processing session 143/177 (Patient pqejgqbu, Session s1_t1)\n",
      "2025-06-08 00:49:40 - INFO - Preprocessed signal shape: (171750, 19)\n",
      "2025-06-08 00:49:40 - INFO - Processed 10500 segments so far\n",
      "2025-06-08 00:49:40 - INFO - Session 143 processed in 0.20s\n",
      "2025-06-08 00:49:40 - INFO - Processing session 144/177 (Patient pqejgqbu, Session s1_t2)\n",
      "2025-06-08 00:49:41 - INFO - Preprocessed signal shape: (499500, 19)\n",
      "2025-06-08 00:49:41 - INFO - Processed 10600 segments so far\n",
      "2025-06-08 00:49:41 - INFO - Processed 10700 segments so far\n",
      "2025-06-08 00:49:41 - INFO - Session 144 processed in 0.58s\n",
      "2025-06-08 00:49:41 - INFO - Processing session 145/177 (Patient pqejgqji, Session s2_t0)\n",
      "2025-06-08 00:49:41 - INFO - Preprocessed signal shape: (55500, 19)\n",
      "2025-06-08 00:49:41 - INFO - Session 145 processed in 0.07s\n",
      "2025-06-08 00:49:41 - INFO - Processing session 146/177 (Patient pqejgqji, Session s2_t1)\n",
      "2025-06-08 00:49:41 - INFO - Preprocessed signal shape: (211500, 19)\n",
      "2025-06-08 00:49:41 - INFO - Session 146 processed in 0.27s\n",
      "2025-06-08 00:49:41 - INFO - Processing session 147/177 (Patient pqejgqji, Session s3_t6)\n",
      "2025-06-08 00:49:41 - INFO - Preprocessed signal shape: (75000, 19)\n",
      "2025-06-08 00:49:41 - INFO - Processed 10800 segments so far\n",
      "2025-06-08 00:49:41 - INFO - Session 147 processed in 0.09s\n",
      "2025-06-08 00:49:41 - INFO - Processing session 148/177 (Patient pqejgqnk, Session s6_t3)\n",
      "2025-06-08 00:49:41 - INFO - Preprocessed signal shape: (75000, 19)\n",
      "2025-06-08 00:49:41 - INFO - Session 148 processed in 0.09s\n",
      "2025-06-08 00:49:41 - INFO - Processing session 149/177 (Patient pqejgqpu, Session s1_t0)\n",
      "2025-06-08 00:49:42 - INFO - Preprocessed signal shape: (348250, 19)\n",
      "2025-06-08 00:49:42 - INFO - Processed 10900 segments so far\n",
      "2025-06-08 00:49:42 - INFO - Session 149 processed in 0.39s\n",
      "2025-06-08 00:49:42 - INFO - Processing session 150/177 (Patient pqejgqpu, Session s3_t1)\n",
      "2025-06-08 00:49:42 - INFO - Preprocessed signal shape: (324000, 19)\n",
      "2025-06-08 00:49:42 - INFO - Processed 11000 segments so far\n",
      "2025-06-08 00:49:42 - INFO - Session 150 processed in 0.38s\n",
      "2025-06-08 00:49:42 - INFO - Processing session 151/177 (Patient pqejgqpu, Session s7_t1)\n",
      "2025-06-08 00:49:42 - INFO - Preprocessed signal shape: (346000, 19)\n",
      "2025-06-08 00:49:42 - INFO - Processed 11100 segments so far\n",
      "2025-06-08 00:49:43 - INFO - Session 151 processed in 0.43s\n",
      "2025-06-08 00:49:43 - INFO - Processing session 152/177 (Patient pqejgqtk, Session s10_t1)\n",
      "2025-06-08 00:49:43 - INFO - Preprocessed signal shape: (347500, 19)\n",
      "2025-06-08 00:49:43 - INFO - Processed 11200 segments so far\n",
      "2025-06-08 00:49:43 - INFO - Session 152 processed in 0.41s\n",
      "2025-06-08 00:49:43 - INFO - Processing session 153/177 (Patient pqejgrgl, Session s1_t0)\n",
      "2025-06-08 00:49:44 - INFO - Preprocessed signal shape: (654500, 19)\n",
      "2025-06-08 00:49:44 - INFO - Processed 11300 segments so far\n",
      "2025-06-08 00:49:44 - INFO - Processed 11400 segments so far\n",
      "2025-06-08 00:49:44 - INFO - Processed 11500 segments so far\n",
      "2025-06-08 00:49:44 - INFO - Session 153 processed in 0.80s\n",
      "2025-06-08 00:49:44 - INFO - Processing session 154/177 (Patient pqejgrmp, Session s1_t0)\n",
      "2025-06-08 00:49:44 - INFO - Preprocessed signal shape: (318000, 19)\n",
      "2025-06-08 00:49:44 - INFO - Processed 11600 segments so far\n",
      "2025-06-08 00:49:44 - INFO - Session 154 processed in 0.42s\n",
      "2025-06-08 00:49:44 - INFO - Processing session 155/177 (Patient pqejgrsg, Session s2_t2)\n",
      "2025-06-08 00:49:44 - INFO - Preprocessed signal shape: (259250, 19)\n",
      "2025-06-08 00:49:45 - INFO - Processed 11700 segments so far\n",
      "2025-06-08 00:49:45 - INFO - Session 155 processed in 0.32s\n",
      "2025-06-08 00:49:45 - INFO - Processing session 156/177 (Patient pqejgtjb, Session s3_t1)\n",
      "2025-06-08 00:49:45 - INFO - Preprocessed signal shape: (326750, 19)\n",
      "2025-06-08 00:49:45 - INFO - Processed 11800 segments so far\n",
      "2025-06-08 00:49:45 - INFO - Session 156 processed in 0.39s\n",
      "2025-06-08 00:49:45 - INFO - Processing session 157/177 (Patient pqejgtlr, Session s1_t0)\n",
      "2025-06-08 00:49:45 - INFO - Preprocessed signal shape: (90250, 19)\n",
      "2025-06-08 00:49:45 - INFO - Session 157 processed in 0.12s\n",
      "2025-06-08 00:49:45 - INFO - Processing session 158/177 (Patient pqejgtlr, Session s1_t1)\n",
      "2025-06-08 00:49:45 - INFO - Preprocessed signal shape: (86750, 19)\n",
      "2025-06-08 00:49:45 - INFO - Session 158 processed in 0.11s\n",
      "2025-06-08 00:49:45 - INFO - Processing session 159/177 (Patient pqejgtlr, Session s1_t2)\n",
      "2025-06-08 00:49:45 - INFO - Preprocessed signal shape: (108500, 19)\n",
      "2025-06-08 00:49:45 - INFO - Processed 11900 segments so far\n",
      "2025-06-08 00:49:45 - INFO - Session 159 processed in 0.13s\n",
      "2025-06-08 00:49:45 - INFO - Processing session 160/177 (Patient pqejgtxc, Session s3_t1)\n",
      "2025-06-08 00:49:46 - INFO - Preprocessed signal shape: (270750, 19)\n",
      "2025-06-08 00:49:46 - INFO - Session 160 processed in 0.34s\n",
      "2025-06-08 00:49:46 - INFO - Processing session 161/177 (Patient pqejgtxc, Session s3_t2)\n",
      "2025-06-08 00:49:46 - INFO - Preprocessed signal shape: (150250, 19)\n",
      "2025-06-08 00:49:46 - INFO - Processed 12000 segments so far\n",
      "2025-06-08 00:49:46 - INFO - Session 161 processed in 0.20s\n",
      "2025-06-08 00:49:46 - INFO - Processing session 162/177 (Patient pqejgtxc, Session s3_t3)\n",
      "2025-06-08 00:49:46 - INFO - Preprocessed signal shape: (176250, 19)\n",
      "2025-06-08 00:49:46 - INFO - Processed 12100 segments so far\n",
      "2025-06-08 00:49:46 - INFO - Session 162 processed in 0.22s\n",
      "2025-06-08 00:49:46 - INFO - Processing session 163/177 (Patient pqejgtxc, Session s3_t4)\n",
      "2025-06-08 00:49:46 - INFO - Preprocessed signal shape: (181750, 19)\n",
      "2025-06-08 00:49:46 - INFO - Session 163 processed in 0.21s\n",
      "2025-06-08 00:49:46 - INFO - Processing session 164/177 (Patient pqejgtxc, Session s3_t5)\n",
      "2025-06-08 00:49:46 - INFO - Preprocessed signal shape: (172250, 19)\n",
      "2025-06-08 00:49:46 - INFO - Processed 12200 segments so far\n",
      "2025-06-08 00:49:46 - INFO - Session 164 processed in 0.20s\n",
      "2025-06-08 00:49:46 - INFO - Processing session 165/177 (Patient pqejgtxc, Session s3_t6)\n",
      "2025-06-08 00:49:47 - INFO - Preprocessed signal shape: (195250, 19)\n",
      "2025-06-08 00:49:47 - INFO - Session 165 processed in 0.23s\n",
      "2025-06-08 00:49:47 - INFO - Processing session 166/177 (Patient pqejguob, Session s1_t0)\n",
      "2025-06-08 00:49:47 - INFO - Preprocessed signal shape: (424250, 19)\n",
      "2025-06-08 00:49:47 - INFO - Processed 12300 segments so far\n",
      "2025-06-08 00:49:47 - INFO - Processed 12400 segments so far\n",
      "2025-06-08 00:49:47 - INFO - Session 166 processed in 0.52s\n",
      "2025-06-08 00:49:47 - INFO - Processing session 167/177 (Patient pqejgupd, Session s1_t1)\n",
      "2025-06-08 00:49:47 - INFO - Preprocessed signal shape: (210750, 19)\n",
      "2025-06-08 00:49:47 - INFO - Processed 12500 segments so far\n",
      "2025-06-08 00:49:47 - INFO - Session 167 processed in 0.26s\n",
      "2025-06-08 00:49:47 - INFO - Processing session 168/177 (Patient pqejgupd, Session s3_t2)\n",
      "2025-06-08 00:49:48 - INFO - Preprocessed signal shape: (157500, 19)\n",
      "2025-06-08 00:49:48 - INFO - Session 168 processed in 0.18s\n",
      "2025-06-08 00:49:48 - INFO - Processing session 169/177 (Patient pqejgupd, Session s3_t6)\n",
      "2025-06-08 00:49:48 - INFO - Preprocessed signal shape: (85250, 19)\n",
      "2025-06-08 00:49:48 - INFO - Session 169 processed in 0.10s\n",
      "2025-06-08 00:49:48 - INFO - Processing session 170/177 (Patient pqejgupd, Session s3_t7)\n",
      "2025-06-08 00:49:48 - INFO - Preprocessed signal shape: (119250, 19)\n",
      "2025-06-08 00:49:48 - INFO - Processed 12600 segments so far\n",
      "2025-06-08 00:49:48 - INFO - Session 170 processed in 0.14s\n",
      "2025-06-08 00:49:48 - INFO - Processing session 171/177 (Patient pqejgupd, Session s3_t9)\n",
      "2025-06-08 00:49:48 - INFO - Preprocessed signal shape: (150250, 19)\n",
      "2025-06-08 00:49:48 - INFO - Session 171 processed in 0.20s\n",
      "2025-06-08 00:49:48 - INFO - Processing session 172/177 (Patient pqejgurd, Session s1_t0)\n",
      "2025-06-08 00:49:48 - INFO - Preprocessed signal shape: (229250, 19)\n",
      "2025-06-08 00:49:48 - INFO - Processed 12700 segments so far\n",
      "2025-06-08 00:49:48 - INFO - Session 172 processed in 0.27s\n",
      "2025-06-08 00:49:48 - INFO - Processing session 173/177 (Patient pqejgurd, Session s1_t1)\n",
      "2025-06-08 00:49:49 - INFO - Preprocessed signal shape: (221000, 19)\n",
      "2025-06-08 00:49:49 - INFO - Processed 12800 segments so far\n",
      "2025-06-08 00:49:49 - INFO - Session 173 processed in 0.28s\n",
      "2025-06-08 00:49:49 - INFO - Processing session 174/177 (Patient pqejgveb, Session s1_t1)\n",
      "2025-06-08 00:49:49 - INFO - Preprocessed signal shape: (333000, 19)\n",
      "2025-06-08 00:49:49 - INFO - Processed 12900 segments so far\n",
      "2025-06-08 00:49:49 - INFO - Session 174 processed in 0.39s\n",
      "2025-06-08 00:49:49 - INFO - Processing session 175/177 (Patient pqejgvqb, Session s1_t0)\n",
      "2025-06-08 00:49:49 - INFO - Preprocessed signal shape: (129750, 19)\n",
      "2025-06-08 00:49:49 - INFO - Session 175 processed in 0.17s\n",
      "2025-06-08 00:49:49 - INFO - Processing session 176/177 (Patient pqejgvqb, Session s1_t13)\n",
      "2025-06-08 00:49:49 - INFO - Preprocessed signal shape: (41250, 19)\n",
      "2025-06-08 00:49:49 - INFO - Session 176 processed in 0.05s\n",
      "2025-06-08 00:49:49 - INFO - Processing session 177/177 (Patient pqejgvqb, Session s1_t4)\n",
      "2025-06-08 00:49:49 - INFO - Preprocessed signal shape: (22250, 19)\n",
      "2025-06-08 00:49:49 - INFO - Session 177 processed in 0.06s\n",
      "2025-06-08 00:49:49 - INFO - Session processing completed in 47.40s\n",
      "2025-06-08 00:49:49 - INFO - Processed 12993 segments, skipped 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train_dataset: 12993\n",
      " Eliminated IDs: []\n"
     ]
    }
   ],
   "source": [
    "%aimport\n",
    "from src.data.dataset_graph import GraphEEGDataset\n",
    "\n",
    "# dataset settings\n",
    "selected_features = []\n",
    "embeddings = []\n",
    "edge_strategy = \"spatial\"\n",
    "correlation_threshold = 0.5\n",
    "top_k = None\n",
    "low_bandpass_frequency = 0.5\n",
    "high_bandpass_frequency = 50\n",
    "\n",
    "# additional settings\n",
    "oversampling_power = 1.0\n",
    "\n",
    "# load training dataset\n",
    "dataset_tr = GraphEEGDataset(\n",
    "    root=train_dataset_dir,\n",
    "    clips=clips_tr,\n",
    "    signal_folder=train_dir,\n",
    "    extracted_features_dir=extracted_features_dir,\n",
    "    use_selected_features=False,\n",
    "    embeddings_dir=embeddings_dir,\n",
    "    use_embeddings=False,\n",
    "    edge_strategy=edge_strategy,\n",
    "    spatial_distance_file=(\n",
    "        spatial_distance_file if edge_strategy == \"spatial\" else None\n",
    "    ),\n",
    "    top_k=top_k,\n",
    "    correlation_threshold=correlation_threshold,\n",
    "    force_reprocess=True,\n",
    "    bandpass_frequencies=(\n",
    "        low_bandpass_frequency,\n",
    "        high_bandpass_frequency,\n",
    "    ),\n",
    "    segment_length=3000,\n",
    "    apply_filtering=True,\n",
    "    apply_rereferencing=True,\n",
    "    apply_normalization=True,\n",
    "    sampling_rate=250,\n",
    ")\n",
    "\n",
    "# Check the length of the dataset\n",
    "print(f\"Length of train_dataset: {len(dataset_tr)}\")\n",
    "print(f' Eliminated IDs: {dataset_tr.ids_to_eliminate}')\n",
    "\n",
    "# Eliminate ids that did not have electrodes above correlation threshols\n",
    "clips_tr = clips_tr[~clips_tr.index.isin(dataset_tr.ids_to_eliminate)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6fcb2272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['patient', 'session', 'segment']\n"
     ]
    }
   ],
   "source": [
    "print(clips_te.index.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6a32d044",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-08 00:49:54 - INFO - Initializing GraphEEGDataset...\n",
      "2025-06-08 00:49:54 - INFO - Dataset parameters:\n",
      "2025-06-08 00:49:54 - INFO -   - Root directory: data/graph_dataset_test\n",
      "2025-06-08 00:49:54 - INFO -   - Edge strategy: spatial\n",
      "2025-06-08 00:49:54 - INFO -   - Top-k neighbors: None\n",
      "2025-06-08 00:49:54 - INFO -   - Correlation threshold: 0.5\n",
      "2025-06-08 00:49:54 - INFO -   - Force reprocess: True\n",
      "2025-06-08 00:49:54 - INFO -   - Bandpass frequencies: (0.5, 50)\n",
      "2025-06-08 00:49:54 - INFO -   - Segment length: 3000\n",
      "2025-06-08 00:49:54 - INFO -   - Apply filtering: True\n",
      "2025-06-08 00:49:54 - INFO -   - Apply rereferencing: False\n",
      "2025-06-08 00:49:54 - INFO -   - Apply normalization: False\n",
      "2025-06-08 00:49:54 - INFO -   - Sampling rate: 250\n",
      "2025-06-08 00:49:54 - INFO -   - Test mode: True\n",
      "2025-06-08 00:49:54 - INFO - Number of EEG channels: 19\n",
      "2025-06-08 00:49:54 - INFO - Setting up signal filters...\n",
      "2025-06-08 00:49:54 - INFO - Loading spatial distances from data/distances_3d.csv\n",
      "2025-06-08 00:49:54 - INFO - Loading spatial distances from data/distances_3d.csv\n",
      "2025-06-08 00:49:54 - INFO - Loaded 361 spatial distances in 0.01s\n",
      "2025-06-08 00:49:54 - INFO - Loaded 361 spatial distance pairs\n",
      "2025-06-08 00:49:54 - INFO - Force reprocessing enabled - cleaning up existing processed files\n",
      "2025-06-08 00:49:54 - INFO - Deleted 0 existing processed files\n",
      "2025-06-08 00:49:54 - INFO - Starting session processing...\n",
      "2025-06-08 00:49:54 - INFO - Starting session processing...\n",
      "2025-06-08 00:49:54 - INFO - Processing session 1/50 (Patient pqejgcvm, Session s1_t0)\n",
      "2025-06-08 00:49:54 - INFO - Preprocessed signal shape: (75250, 19)\n",
      "2025-06-08 00:49:54 - INFO - Processed 0 segments so far\n",
      "2025-06-08 00:49:54 - INFO - Session 1 processed in 0.08s\n",
      "2025-06-08 00:49:54 - INFO - Processing session 2/50 (Patient pqejgcvm, Session s1_t1)\n",
      "2025-06-08 00:49:54 - INFO - Preprocessed signal shape: (59000, 19)\n",
      "2025-06-08 00:49:54 - INFO - Session 2 processed in 0.06s\n",
      "2025-06-08 00:49:54 - INFO - Processing session 3/50 (Patient pqejgcvm, Session s2_t0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modules to reload:\n",
      "\n",
      "\n",
      "Modules to skip:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-08 00:49:54 - INFO - Preprocessed signal shape: (65500, 19)\n",
      "2025-06-08 00:49:54 - INFO - Session 3 processed in 0.09s\n",
      "2025-06-08 00:49:54 - INFO - Processing session 4/50 (Patient pqejgdix, Session s2_t1)\n",
      "2025-06-08 00:49:54 - INFO - Preprocessed signal shape: (88500, 19)\n",
      "2025-06-08 00:49:55 - INFO - Session 4 processed in 0.09s\n",
      "2025-06-08 00:49:55 - INFO - Processing session 5/50 (Patient pqejgdix, Session s2_t2)\n",
      "2025-06-08 00:49:55 - INFO - Preprocessed signal shape: (69250, 19)\n",
      "2025-06-08 00:49:55 - INFO - Processed 100 segments so far\n",
      "2025-06-08 00:49:55 - INFO - Session 5 processed in 0.08s\n",
      "2025-06-08 00:49:55 - INFO - Processing session 6/50 (Patient pqejgdix, Session s2_t4)\n",
      "2025-06-08 00:49:55 - INFO - Preprocessed signal shape: (76000, 19)\n",
      "2025-06-08 00:49:55 - INFO - Session 6 processed in 0.08s\n",
      "2025-06-08 00:49:55 - INFO - Processing session 7/50 (Patient pqejgdix, Session s2_t5)\n",
      "2025-06-08 00:49:55 - INFO - Preprocessed signal shape: (73500, 19)\n",
      "2025-06-08 00:49:55 - INFO - Session 7 processed in 0.08s\n",
      "2025-06-08 00:49:55 - INFO - Processing session 8/50 (Patient pqejgdyf, Session s1_t1)\n",
      "2025-06-08 00:49:55 - INFO - Preprocessed signal shape: (310000, 19)\n",
      "2025-06-08 00:49:55 - INFO - Processed 200 segments so far\n",
      "2025-06-08 00:49:55 - INFO - Session 8 processed in 0.34s\n",
      "2025-06-08 00:49:55 - INFO - Processing session 9/50 (Patient pqejgfkt, Session s5_t0)\n",
      "2025-06-08 00:49:55 - INFO - Preprocessed signal shape: (130250, 19)\n",
      "2025-06-08 00:49:55 - INFO - Processed 300 segments so far\n",
      "2025-06-08 00:49:55 - INFO - Session 9 processed in 0.15s\n",
      "2025-06-08 00:49:55 - INFO - Processing session 10/50 (Patient pqejgfkt, Session s5_t1)\n",
      "2025-06-08 00:49:55 - INFO - Preprocessed signal shape: (23750, 19)\n",
      "2025-06-08 00:49:55 - INFO - Session 10 processed in 0.03s\n",
      "2025-06-08 00:49:55 - INFO - Processing session 11/50 (Patient pqejgfkt, Session s5_t2)\n",
      "2025-06-08 00:49:55 - INFO - Preprocessed signal shape: (11250, 19)\n",
      "2025-06-08 00:49:55 - INFO - Session 11 processed in 0.04s\n",
      "2025-06-08 00:49:55 - INFO - Processing session 12/50 (Patient pqejgfkt, Session s5_t3)\n",
      "2025-06-08 00:49:55 - INFO - Preprocessed signal shape: (12750, 19)\n",
      "2025-06-08 00:49:55 - INFO - Session 12 processed in 0.02s\n",
      "2025-06-08 00:49:55 - INFO - Processing session 13/50 (Patient pqejgfkt, Session s5_t4)\n",
      "2025-06-08 00:49:55 - INFO - Preprocessed signal shape: (150250, 19)\n",
      "2025-06-08 00:49:56 - INFO - Session 13 processed in 0.18s\n",
      "2025-06-08 00:49:56 - INFO - Processing session 14/50 (Patient pqejgfkt, Session s5_t5)\n",
      "2025-06-08 00:49:56 - INFO - Preprocessed signal shape: (50000, 19)\n",
      "2025-06-08 00:49:56 - INFO - Session 14 processed in 0.06s\n",
      "2025-06-08 00:49:56 - INFO - Processing session 15/50 (Patient pqejgfll, Session s2_t0)\n",
      "2025-06-08 00:49:56 - INFO - Preprocessed signal shape: (167500, 19)\n",
      "2025-06-08 00:49:56 - INFO - Processed 400 segments so far\n",
      "2025-06-08 00:49:56 - INFO - Session 15 processed in 0.18s\n",
      "2025-06-08 00:49:56 - INFO - Processing session 16/50 (Patient pqejggiv, Session s1_t1)\n",
      "2025-06-08 00:49:56 - INFO - Preprocessed signal shape: (367750, 19)\n",
      "2025-06-08 00:49:56 - INFO - Processed 500 segments so far\n",
      "2025-06-08 00:49:56 - INFO - Session 16 processed in 0.41s\n",
      "2025-06-08 00:49:56 - INFO - Processing session 17/50 (Patient pqejghgm, Session s1_t1)\n",
      "2025-06-08 00:49:56 - INFO - Preprocessed signal shape: (315000, 19)\n",
      "2025-06-08 00:49:56 - INFO - Processed 600 segments so far\n",
      "2025-06-08 00:49:57 - INFO - Session 17 processed in 0.34s\n",
      "2025-06-08 00:49:57 - INFO - Processing session 18/50 (Patient pqejgjsa, Session s4_t0)\n",
      "2025-06-08 00:49:57 - INFO - Preprocessed signal shape: (86250, 19)\n",
      "2025-06-08 00:49:57 - INFO - Processed 700 segments so far\n",
      "2025-06-08 00:49:57 - INFO - Session 18 processed in 0.09s\n",
      "2025-06-08 00:49:57 - INFO - Processing session 19/50 (Patient pqejgkzk, Session s4_t4)\n",
      "2025-06-08 00:49:57 - INFO - Preprocessed signal shape: (70250, 19)\n",
      "2025-06-08 00:49:57 - INFO - Session 19 processed in 0.11s\n",
      "2025-06-08 00:49:57 - INFO - Processing session 20/50 (Patient pqejglig, Session s2_t0)\n",
      "2025-06-08 00:49:57 - INFO - Preprocessed signal shape: (60250, 19)\n",
      "2025-06-08 00:49:57 - INFO - Session 20 processed in 0.06s\n",
      "2025-06-08 00:49:57 - INFO - Processing session 21/50 (Patient pqejgmhe, Session s1_t0)\n",
      "2025-06-08 00:49:57 - INFO - Preprocessed signal shape: (334250, 19)\n",
      "2025-06-08 00:49:57 - INFO - Processed 800 segments so far\n",
      "2025-06-08 00:49:57 - INFO - Session 21 processed in 0.37s\n",
      "2025-06-08 00:49:57 - INFO - Processing session 22/50 (Patient pqejgmjq, Session s2_t0)\n",
      "2025-06-08 00:49:57 - INFO - Preprocessed signal shape: (303750, 19)\n",
      "2025-06-08 00:49:57 - INFO - Processed 900 segments so far\n",
      "2025-06-08 00:49:57 - INFO - Session 22 processed in 0.33s\n",
      "2025-06-08 00:49:57 - INFO - Processing session 23/50 (Patient pqejgmni, Session s1_t1)\n",
      "2025-06-08 00:49:58 - INFO - Preprocessed signal shape: (497000, 19)\n",
      "2025-06-08 00:49:58 - INFO - Processed 1000 segments so far\n",
      "2025-06-08 00:49:58 - INFO - Processed 1100 segments so far\n",
      "2025-06-08 00:49:58 - INFO - Session 23 processed in 0.52s\n",
      "2025-06-08 00:49:58 - INFO - Processing session 24/50 (Patient pqejgnhh, Session s2_t0)\n",
      "2025-06-08 00:49:59 - INFO - Preprocessed signal shape: (1410000, 19)\n",
      "2025-06-08 00:49:59 - INFO - Processed 1200 segments so far\n",
      "2025-06-08 00:49:59 - INFO - Processed 1300 segments so far\n",
      "2025-06-08 00:49:59 - INFO - Processed 1400 segments so far\n",
      "2025-06-08 00:50:00 - INFO - Processed 1500 segments so far\n",
      "2025-06-08 00:50:00 - INFO - Session 24 processed in 1.61s\n",
      "2025-06-08 00:50:00 - INFO - Processing session 25/50 (Patient pqejgnih, Session s3_t0)\n",
      "2025-06-08 00:50:00 - INFO - Preprocessed signal shape: (75000, 19)\n",
      "2025-06-08 00:50:00 - INFO - Processed 1600 segments so far\n",
      "2025-06-08 00:50:00 - INFO - Session 25 processed in 0.08s\n",
      "2025-06-08 00:50:00 - INFO - Processing session 26/50 (Patient pqejgnih, Session s3_t6)\n",
      "2025-06-08 00:50:00 - INFO - Preprocessed signal shape: (75000, 19)\n",
      "2025-06-08 00:50:00 - INFO - Session 26 processed in 0.08s\n",
      "2025-06-08 00:50:00 - INFO - Processing session 27/50 (Patient pqejgnkt, Session s2_t1)\n",
      "2025-06-08 00:50:00 - INFO - Preprocessed signal shape: (375750, 19)\n",
      "2025-06-08 00:50:00 - INFO - Processed 1700 segments so far\n",
      "2025-06-08 00:50:00 - INFO - Session 27 processed in 0.41s\n",
      "2025-06-08 00:50:00 - INFO - Processing session 28/50 (Patient pqejgnog, Session s1_t1)\n",
      "2025-06-08 00:50:00 - INFO - Preprocessed signal shape: (318500, 19)\n",
      "2025-06-08 00:50:00 - INFO - Processed 1800 segments so far\n",
      "2025-06-08 00:50:00 - INFO - Session 28 processed in 0.32s\n",
      "2025-06-08 00:50:00 - INFO - Processing session 29/50 (Patient pqejgqxi, Session s1_t2)\n",
      "2025-06-08 00:50:01 - INFO - Preprocessed signal shape: (291750, 19)\n",
      "2025-06-08 00:50:01 - INFO - Processed 1900 segments so far\n",
      "2025-06-08 00:50:01 - INFO - Session 29 processed in 0.31s\n",
      "2025-06-08 00:50:01 - INFO - Processing session 30/50 (Patient pqejgrff, Session s1_t0)\n",
      "2025-06-08 00:50:01 - INFO - Preprocessed signal shape: (469750, 19)\n",
      "2025-06-08 00:50:01 - INFO - Processed 2000 segments so far\n",
      "2025-06-08 00:50:01 - INFO - Processed 2100 segments so far\n",
      "2025-06-08 00:50:01 - INFO - Session 30 processed in 0.48s\n",
      "2025-06-08 00:50:01 - INFO - Processing session 31/50 (Patient pqejgrhn, Session s1_t0)\n",
      "2025-06-08 00:50:02 - INFO - Preprocessed signal shape: (878250, 19)\n",
      "2025-06-08 00:50:02 - INFO - Processed 2200 segments so far\n",
      "2025-06-08 00:50:02 - INFO - Processed 2300 segments so far\n",
      "2025-06-08 00:50:02 - INFO - Processed 2400 segments so far\n",
      "2025-06-08 00:50:02 - INFO - Session 31 processed in 0.97s\n",
      "2025-06-08 00:50:02 - INFO - Processing session 32/50 (Patient pqejgrhn, Session s3_t0)\n",
      "2025-06-08 00:50:02 - INFO - Preprocessed signal shape: (18250, 19)\n",
      "2025-06-08 00:50:02 - INFO - Session 32 processed in 0.02s\n",
      "2025-06-08 00:50:02 - INFO - Processing session 33/50 (Patient pqejgrhn, Session s3_t1)\n",
      "2025-06-08 00:50:03 - INFO - Preprocessed signal shape: (374000, 19)\n",
      "2025-06-08 00:50:03 - INFO - Processed 2500 segments so far\n",
      "2025-06-08 00:50:03 - INFO - Session 33 processed in 0.40s\n",
      "2025-06-08 00:50:03 - INFO - Processing session 34/50 (Patient pqejgsfr, Session s2_t2)\n",
      "2025-06-08 00:50:03 - INFO - Preprocessed signal shape: (196750, 19)\n",
      "2025-06-08 00:50:03 - INFO - Processed 2600 segments so far\n",
      "2025-06-08 00:50:03 - INFO - Session 34 processed in 0.25s\n",
      "2025-06-08 00:50:03 - INFO - Processing session 35/50 (Patient pqejgsfr, Session s2_t3)\n",
      "2025-06-08 00:50:03 - INFO - Preprocessed signal shape: (192000, 19)\n",
      "2025-06-08 00:50:03 - INFO - Session 35 processed in 0.21s\n",
      "2025-06-08 00:50:03 - INFO - Processing session 36/50 (Patient pqejgsfr, Session s3_t0)\n",
      "2025-06-08 00:50:03 - INFO - Preprocessed signal shape: (179750, 19)\n",
      "2025-06-08 00:50:03 - INFO - Processed 2700 segments so far\n",
      "2025-06-08 00:50:03 - INFO - Session 36 processed in 0.20s\n",
      "2025-06-08 00:50:03 - INFO - Processing session 37/50 (Patient pqejgsfr, Session s3_t3)\n",
      "2025-06-08 00:50:03 - INFO - Preprocessed signal shape: (197250, 19)\n",
      "2025-06-08 00:50:04 - INFO - Processed 2800 segments so far\n",
      "2025-06-08 00:50:04 - INFO - Session 37 processed in 0.22s\n",
      "2025-06-08 00:50:04 - INFO - Processing session 38/50 (Patient pqejgsfr, Session s3_t4)\n",
      "2025-06-08 00:50:04 - INFO - Preprocessed signal shape: (182750, 19)\n",
      "2025-06-08 00:50:04 - INFO - Session 38 processed in 0.20s\n",
      "2025-06-08 00:50:04 - INFO - Processing session 39/50 (Patient pqejgsfr, Session s3_t6)\n",
      "2025-06-08 00:50:04 - INFO - Preprocessed signal shape: (182250, 19)\n",
      "2025-06-08 00:50:04 - INFO - Processed 2900 segments so far\n",
      "2025-06-08 00:50:04 - INFO - Session 39 processed in 0.21s\n",
      "2025-06-08 00:50:04 - INFO - Processing session 40/50 (Patient pqejgsfr, Session s3_t7)\n",
      "2025-06-08 00:50:04 - INFO - Preprocessed signal shape: (221250, 19)\n",
      "2025-06-08 00:50:04 - INFO - Session 40 processed in 0.25s\n",
      "2025-06-08 00:50:04 - INFO - Processing session 41/50 (Patient pqejgsmy, Session s3_t6)\n",
      "2025-06-08 00:50:04 - INFO - Preprocessed signal shape: (150250, 19)\n",
      "2025-06-08 00:50:04 - INFO - Processed 3000 segments so far\n",
      "2025-06-08 00:50:04 - INFO - Session 41 processed in 0.18s\n",
      "2025-06-08 00:50:04 - INFO - Processing session 42/50 (Patient pqejgtld, Session s3_t0)\n",
      "2025-06-08 00:50:04 - INFO - Preprocessed signal shape: (75000, 19)\n",
      "2025-06-08 00:50:04 - INFO - Session 42 processed in 0.09s\n",
      "2025-06-08 00:50:04 - INFO - Processing session 43/50 (Patient pqejgtld, Session s3_t1)\n",
      "2025-06-08 00:50:05 - INFO - Preprocessed signal shape: (150250, 19)\n",
      "2025-06-08 00:50:05 - INFO - Processed 3100 segments so far\n",
      "2025-06-08 00:50:05 - INFO - Session 43 processed in 0.16s\n",
      "2025-06-08 00:50:05 - INFO - Processing session 44/50 (Patient pqejguho, Session s1_t0)\n",
      "2025-06-08 00:50:05 - INFO - Preprocessed signal shape: (229500, 19)\n",
      "2025-06-08 00:50:05 - INFO - Session 44 processed in 0.24s\n",
      "2025-06-08 00:50:05 - INFO - Processing session 45/50 (Patient pqejguho, Session s3_t1)\n",
      "2025-06-08 00:50:05 - INFO - Preprocessed signal shape: (75000, 19)\n",
      "2025-06-08 00:50:05 - INFO - Processed 3200 segments so far\n",
      "2025-06-08 00:50:05 - INFO - Session 45 processed in 0.08s\n",
      "2025-06-08 00:50:05 - INFO - Processing session 46/50 (Patient pqejguho, Session s3_t2)\n",
      "2025-06-08 00:50:05 - INFO - Preprocessed signal shape: (309000, 19)\n",
      "2025-06-08 00:50:05 - INFO - Processed 3300 segments so far\n",
      "2025-06-08 00:50:05 - INFO - Session 46 processed in 0.37s\n",
      "2025-06-08 00:50:05 - INFO - Processing session 47/50 (Patient pqejguho, Session s3_t6)\n",
      "2025-06-08 00:50:05 - INFO - Preprocessed signal shape: (161250, 19)\n",
      "2025-06-08 00:50:05 - INFO - Session 47 processed in 0.17s\n",
      "2025-06-08 00:50:05 - INFO - Processing session 48/50 (Patient pqejguho, Session s4_t3)\n",
      "2025-06-08 00:50:06 - INFO - Preprocessed signal shape: (165000, 19)\n",
      "2025-06-08 00:50:06 - INFO - Processed 3400 segments so far\n",
      "2025-06-08 00:50:06 - INFO - Session 48 processed in 0.18s\n",
      "2025-06-08 00:50:06 - INFO - Processing session 49/50 (Patient pqejguho, Session s4_t5)\n",
      "2025-06-08 00:50:06 - INFO - Preprocessed signal shape: (75000, 19)\n",
      "2025-06-08 00:50:06 - INFO - Session 49 processed in 0.08s\n",
      "2025-06-08 00:50:06 - INFO - Processing session 50/50 (Patient pqejgvej, Session s1_t0)\n",
      "2025-06-08 00:50:06 - INFO - Preprocessed signal shape: (474500, 19)\n",
      "2025-06-08 00:50:06 - INFO - Processed 3500 segments so far\n",
      "2025-06-08 00:50:06 - INFO - Processed 3600 segments so far\n",
      "2025-06-08 00:50:06 - INFO - Session 50 processed in 0.51s\n",
      "2025-06-08 00:50:06 - INFO - Session processing completed in 12.09s\n",
      "2025-06-08 00:50:06 - INFO - Processed 3614 segments, skipped 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of test_dataset: 3614\n",
      " Eliminated IDs:[]\n"
     ]
    }
   ],
   "source": [
    "%aimport\n",
    "from src.data.dataset_graph import GraphEEGDataset\n",
    "\n",
    "# load test dataset\n",
    "te_dataset = GraphEEGDataset(\n",
    "    root=test_dataset_dir,\n",
    "    clips=clips_te,\n",
    "    signal_folder=test_dir,\n",
    "    extracted_features_dir=extracted_features_dir,\n",
    "    use_selected_features=False,\n",
    "    embeddings_dir=embeddings_dir,\n",
    "    use_embeddings=False,\n",
    "    edge_strategy=\"spatial\",\n",
    "    spatial_distance_file=spatial_distance_file,\n",
    "    top_k=None,\n",
    "    correlation_threshold=0.5,\n",
    "    force_reprocess=True,\n",
    "    bandpass_frequencies=(\n",
    "        low_bandpass_frequency,\n",
    "        high_bandpass_frequency,\n",
    "    ),\n",
    "    segment_length=3000,\n",
    "    apply_filtering=True,\n",
    "    apply_rereferencing=False,\n",
    "    apply_normalization=False,\n",
    "    sampling_rate=250,\n",
    "    is_test = True,\n",
    ")\n",
    "\n",
    "# Check the length of the dataset\n",
    "print(f\"Length of test_dataset: {len(te_dataset)}\")\n",
    "print(f' Eliminated IDs:{te_dataset.ids_to_eliminate}')\n",
    "\n",
    "# Eliminate ids that did not have electrodes above correlation threshols\n",
    "clips_te = clips_te[~clips_te.index.isin(te_dataset.ids_to_eliminate)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e6943f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels before split\n",
      "[1 1 1 ... 1 1 0]\n",
      "[00:52:04] Train labels: 0 -> 8375, 1 -> 2019\n",
      "[00:52:04] Val labels:   0 -> 2101, 1 -> 498\n",
      "Train batches: 163\n",
      "Val batches: 41\n",
      "Test batches: 57\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import random_split\n",
    "from src.utils.general_funcs import labels_stats\n",
    "\n",
    "# Get total samples and split sizes\n",
    "total_samples = len(dataset_tr)\n",
    "train_size = int(0.8 * total_samples)\n",
    "val_size = total_samples - train_size\n",
    "\n",
    "# Get labels for initial split\n",
    "y = clips_tr[\"label\"].values\n",
    "\n",
    "# Create initial train/val split using random permutation\n",
    "indices = torch.randperm(total_samples)\n",
    "train_indices = indices[:train_size].numpy()\n",
    "val_indices = indices[train_size:].numpy()\n",
    "\n",
    "print('Labels before split', flush=True)\n",
    "print(y, flush=True)\n",
    "\n",
    "# Print stats for class 0 and 1\n",
    "labels_stats(y, train_indices, val_indices)\n",
    "\n",
    "# Create train and val datasets\n",
    "train_dataset = Subset(dataset_tr, train_indices)\n",
    "val_dataset = Subset(dataset_tr, val_indices)\n",
    "\n",
    "# 3. Compute sample weights for oversampling\n",
    "train_labels = [clips_tr.iloc[i][\"label\"] for i in train_indices]\n",
    "class_counts = np.bincount(train_labels)\n",
    "class_weights = (1. / class_counts) ** oversampling_power  # Higher weights for not frequent classes\n",
    "sample_weights = [class_weights[label] for label in train_labels]  # Assign weight to each sample based on its class\n",
    "\n",
    "# 4. Define sampler\n",
    "sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n",
    "\n",
    "# Define dataloaders\n",
    "BATCH_SIZE = 64\n",
    "train_loader = GeoDataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    sampler=sampler, \n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True,\n",
    "    prefetch_factor=2\n",
    ")\n",
    "val_loader = GeoDataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True,\n",
    "    prefetch_factor=2\n",
    ")\n",
    "te_loader = GeoDataLoader(\n",
    "    te_dataset, \n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True,\n",
    "    prefetch_factor=2\n",
    ")\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Val batches: {len(val_loader)}\")\n",
    "print(f\"Test batches: {len(te_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "67042055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modules to reload:\n",
      "\n",
      "\n",
      "Modules to skip:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%aimport\n",
    "from src.layers.hybrid.cnn_bilstm_gcn import EEGCNNBiLSTMGCN\n",
    "\n",
    "config = {\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"weight_decay\": 1e-2,\n",
    "    \"patience\": 10,\n",
    "    \"epochs\": 100,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720925b0",
   "metadata": {},
   "source": [
    "### Test 3 - First breakthrough model\n",
    "\n",
    "```\n",
    "Epochs:   2%| | 2/100 [03:21<5:28:40, 201.23s/it, train_loss=0.7174, val_loss=0.5724, best_val_f1=0.0848, lr=3.00e-04, b2025-06-05 13:32:42 - INFO - \n",
    "Epochs:   3%| | 3/100 [06:28<5:12:31, 193.31s/it, train_loss=0.6813, val_loss=0.5767, best_val_f1=0.1734, lr=3.00e-04, b2025-06-05 13:35:50 - INFO - \n",
    "Epochs:   4%| | 4/100 [09:26<4:57:36, 186.00s/it, train_loss=0.6638, val_loss=0.6072, best_val_f1=0.1734, lr=3.00e-04, b2025-06-05 13:38:47 - INFO - \n",
    "Epochs:   5%| | 5/100 [12:26<4:50:40, 183.58s/it, train_loss=0.6704, val_loss=0.5754, best_val_f1=0.2178, lr=3.00e-04, b2025-06-05 13:41:47 - INFO - \n",
    "...\n",
    "Epochs:   7%| | 7/100 [19:21<5:10:58, 200.62s/it, train_loss=0.6333, val_loss=0.5949, best_val_f1=0.3921, lr=3.00e-04, b2025-06-05 13:48:43 - INFO - \n",
    "Epochs:   8%| | 8/100 [23:11<5:22:14, 210.15s/it, train_loss=0.6261, val_loss=0.5993, best_val_f1=0.3921, lr=3.00e-04, b2025-06-05 13:52:33 - INFO - \n",
    "Epochs:   9%| | 9/100 [26:35<5:15:33, 208.06s/it, train_loss=0.6043, val_loss=0.5743, best_val_f1=0.3921, lr=3.00e-04, b2025-06-05 13:55:56 - INFO - \n",
    "...\n",
    "Epochs:  12%| | 12/100 [36:17<4:49:57, 197.70s/it, train_loss=0.5935, val_loss=0.5691, best_val_f1=0.5043, lr=3.00e-04, 2025-06-05 14:05:38 - INFO - \n",
    "Epochs:  13%|| 13/100 [39:27<4:43:05, 195.24s/it, train_loss=0.5701, val_loss=0.5855, best_val_f1=0.5380, lr=3.00e-04, 2025-06-05 14:08:48 - INFO - \n",
    "Epochs:  14%|| 14/100 [42:32<4:35:35, 192.27s/it, train_loss=0.5329, val_loss=0.6952, best_val_f1=0.5380, lr=3.00e-04, 2025-06-05 14:11:54 - INFO -\n",
    "Epochs:  18%|| 18/100 [55:14<4:22:12, 191.86s/it, train_loss=0.5042, val_loss=0.5616, best_val_f1=0.5623, lr=3.00e-04, 2025-06-05 14:24:36 - INFO -\n",
    "Epochs:  19%|| 19/100 [58:26<4:19:03, 191.89s/it, train_loss=0.5092, val_loss=0.4702, best_val_f1=0.6405, lr=3.00e-04, 2025-06-05 14:27:48 - INFO - \n",
    "Epochs:  20%|| 20/100 [04:25<5:53:37, 265.22s/it, train_loss=0.5077, val_loss=0.4850, best_val_f1=0.6405, lr=3.00e-04, 2025-06-05 15:35:20 - INFO - \n",
    "Epochs:  21%|| 21/100 [07:55<5:06:16, 232.62s/it, train_loss=0.4657, val_loss=0.4666, best_val_f1=0.6405, lr=3.00e-04, 2025-06-05 15:38:49 - INFO - \n",
    "...\n",
    "Epochs:  23%|| 23/100 [16:40<5:02:39, 235.83s/it, train_loss=0.4786, val_loss=0.4441, best_val_f1=0.6405, lr=3.00e-04, 2025-06-05 15:24:57 - INFO -\n",
    "Epochs:  24%|| 24/100 [18:00<4:20:53, 205.96s/it, train_loss=0.4688, val_loss=0.5586, best_val_f1=0.6405, lr=3.00e-04, 2025-06-05 15:48:55 - INFO - \n",
    "Epochs:  25%|| 25/100 [21:08<4:09:36, 199.69s/it, train_loss=0.4521, val_loss=0.4014, best_val_f1=0.6484, lr=3.00e-04, 2025-06-05 15:52:02 - INFO - \n",
    "Epochs:  26%|| 26/100 [24:09<3:58:50, 193.65s/it, train_loss=0.4378, val_loss=0.3937, best_val_f1=0.6800, lr=3.00e-04, 2025-06-05 15:55:04 - INFO - \n",
    "... FROM HERE NOTHING...\n",
    "Epochs:  31%|| 31/100 [39:30<3:35:33, 187.44s/it, train_loss=0.4061, val_loss=0.4341, best_val_f1=0.6800, lr=3.00e-04, 2025-06-05 16:10:25 - INFO - \n",
    "Epochs:  32%|| 32/100 [18:51<3:20:29, 176.90s/it, train_loss=0.3984, val_loss=0.4484, best_val_f1=0.6800, lr=3.00e-04, 2025-06-05 18:22:51 - INFO - \n",
    "Epochs:  35%|| 35/100 [52:42<3:31:23, 195.13s/it, train_loss=0.3835, val_loss=0.4302, best_val_f1=0.6800, lr=3.00e-04, 2025-06-05 16:23:36 - INFO - \n",
    "Epochs:  37%|| 37/100 [32:44<2:56:23, 168.00s/it, train_loss=0.3619, val_loss=0.4276, best_val_f1=0.6800, lr=3.00e-04, 2025-06-05 18:36:45 - INFO - \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b640647a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_PATH = CHECKPOINT_ROOT / \"lstm_gnn_first_best_model.pt\"\n",
    "first_best_model = EEGCNNBiLSTMGCN(\n",
    "    # Parameters for the CNN_BiLSTM_Encoder (temporal encoder)\n",
    "    cnn_dropout_prob = 0.25,\n",
    "    lstm_hidden_dim = 128,\n",
    "    lstm_out_dim = 128,\n",
    "    lstm_dropout_prob = 0.25,\n",
    "    lstm_use_batch_norm= True,\n",
    "    lstm_use_layer_norm= False,\n",
    "    # Parameters for the EEGGCN (graph neural network)\n",
    "    gcn_hidden_channels = 128,\n",
    "    gcn_out_channels = 128,\n",
    "    gcn_pooling_type= \"mean\",\n",
    "    gcn_use_batch_norm = True,\n",
    "    gcn_num_layers = 3,\n",
    "    gcn_dropout_prob = 0.5,\n",
    "    num_channels = 19,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424f5b8b",
   "metadata": {},
   "source": [
    "### Test 4 - Smaller CGN output channels\n",
    "\n",
    "```\n",
    "Epochs:  29%|| 29/100 [2:32:36<6:26:13, 326.39s/it, train_loss=0.3669, val_loss=0.4361, best_val_f1=0.6758, lr=3.00e-042025-06-05 21:22:07 - INFO - \n",
    "Epochs:  30%|| 30/100 [2:38:01<6:20:19, 326.00s/it, train_loss=0.3709, val_loss=0.5588, best_val_f1=0.6758, lr=3.00e-042025-06-05 21:27:32 - INFO - \n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6e3138",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_PATH = CHECKPOINT_ROOT / \"lstm_gnn_first_best_model_bigger_gcn_output_channels.pt\"\n",
    "\n",
    "new_model_smaller_gcn_output = EEGCNNBiLSTMGCN(\n",
    "    # Parameters for the CNN_BiLSTM_Encoder (temporal encoder)\n",
    "    cnn_dropout_prob = 0.25,\n",
    "    lstm_hidden_dim = 128,\n",
    "    lstm_out_dim = 128,\n",
    "    lstm_dropout_prob = 0.25,\n",
    "    lstm_use_batch_norm= True,\n",
    "    lstm_use_layer_norm= False,\n",
    "    # Parameters for the EEGGCN (graph neural network)\n",
    "    gcn_hidden_channels = 128,\n",
    "    gcn_out_channels = 64,\n",
    "    gcn_pooling_type= \"mean\",\n",
    "    gcn_use_batch_norm = True,\n",
    "    gcn_num_layers = 3,\n",
    "    gcn_dropout_prob = 0.5,\n",
    "    num_channels = 19,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9eaaf2d",
   "metadata": {},
   "source": [
    "### Test 6 - Smaller GCN output channels + increased embedding length + Deeper GCN\n",
    "\n",
    "```\n",
    "Epochs:   2%| | 2/100 [04:54<8:01:46, 294.97s/it, train_loss=0.5635, val_loss=0.6869, best_val_f1=0.5291, lr=1.00e-03, b2025-06-06 00:08:26 - INFO - \n",
    "Epochs:  26%|| 26/100 [1:16:00<3:35:35, 174.81s/it, train_loss=0.2740, val_loss=0.4044, best_val_f1=0.7278, lr=6.25e-052025-06-06 01:19:31 - INFO - \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1335c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_small_gcn_bigger_embedding = EEGCNNBiLSTMGCN(\n",
    "    # Parameters for the CNN_BiLSTM_Encoder (temporal encoder)\n",
    "    cnn_dropout_prob = 0.25,\n",
    "    lstm_hidden_dim = 128,\n",
    "    lstm_out_dim = 128,\n",
    "    lstm_dropout_prob = 0.25,\n",
    "    lstm_use_batch_norm= True,\n",
    "    lstm_use_layer_norm= False,\n",
    "    # Parameters for the EEGGCN (graph neural network)\n",
    "    gcn_hidden_channels = 128,\n",
    "    gcn_out_channels = 64,\n",
    "    gcn_pooling_type= \"mean\",\n",
    "    gcn_use_batch_norm = True,\n",
    "    gcn_num_layers = 4,\n",
    "    gcn_dropout_prob = 0.5,\n",
    "    num_channels = 19,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da60626",
   "metadata": {},
   "source": [
    "\n",
    "### Test 7: Same as T6 but slighly bigger GCN output channels\n",
    ">[HIGHEST F1 SCORE EVER RECORDED]\n",
    "```\n",
    " Checkpoint loaded. Resuming from epoch 33. Best 'val_f1' score: 0.7346\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d2a2ed81",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_PATH = CHECKPOINT_ROOT / \"lstm_gnn_bigger_gcn_bigger_embedding.pt\"\n",
    "model_bigger_gcn_bigger_embedding = EEGCNNBiLSTMGCN(\n",
    "    # Parameters for the CNN_BiLSTM_Encoder (temporal encoder)\n",
    "    cnn_dropout_prob = 0.25,\n",
    "    lstm_hidden_dim = 128,\n",
    "    lstm_out_dim = 128,\n",
    "    lstm_dropout_prob = 0.25,\n",
    "    lstm_use_batch_norm= True,\n",
    "    lstm_use_layer_norm= False,\n",
    "    # Parameters for the EEGGCN (graph neural network)\n",
    "    gcn_hidden_channels = 128,\n",
    "    gcn_out_channels = 96,\n",
    "    gcn_pooling_type= \"mean\",\n",
    "    gcn_use_batch_norm = True,\n",
    "    gcn_num_layers = 4,\n",
    "    gcn_dropout_prob = 0.5,\n",
    "    num_channels = 19,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "282b6879",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'layers'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[56]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m SAVE_PATH = CHECKPOINT_ROOT / \u001b[33m\"\u001b[39m\u001b[33mlstm_gnn_bigger_gcn_bigger_embedding_attention.pt\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlayers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mhybrid\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcnn_bilstm_attention_gcn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EEGCNNBiLSTMAttentionGNN\n\u001b[32m      3\u001b[39m model_bigger_gcn_bigger_embedding = EEGCNNBiLSTMAttentionGNN(\n\u001b[32m      4\u001b[39m     \u001b[38;5;66;03m# Parameters for the CNN_BiLSTM_Encoder (temporal encoder)\u001b[39;00m\n\u001b[32m      5\u001b[39m     cnn_dropout_prob = \u001b[32m0.25\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     18\u001b[39m     num_channels = \u001b[32m19\u001b[39m,\n\u001b[32m     19\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/NeuroGraphNet/src/layers/hybrid/cnn_bilstm_attention_gcn.py:5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnn\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mF\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlayers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mencoders\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcnn_encoder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EEGCNNEncoder\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlayers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtemporal\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlstm_attention\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EEGLSTMAttention\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlayers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgcn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EEGGCN\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'layers'"
     ]
    }
   ],
   "source": [
    "SAVE_PATH = CHECKPOINT_ROOT / \"lstm_gnn_bigger_gcn_bigger_embedding_attention.pt\"\n",
    "from src.layers.hybrid.cnn_bilstm_attention_gcn import EEGCNNBiLSTMAttentionGNN\n",
    "model_bigger_gcn_bigger_embedding = EEGCNNBiLSTMAttentionGNN(\n",
    "    # Parameters for the CNN_BiLSTM_Encoder (temporal encoder)\n",
    "    cnn_dropout_prob = 0.25,\n",
    "    lstm_hidden_dim = 128,\n",
    "    lstm_out_dim = 128,\n",
    "    lstm_dropout_prob = 0.25,\n",
    "    lstm_use_batch_norm= True,\n",
    "    lstm_use_layer_norm= False,\n",
    "    # Parameters for the EEGGCN (graph neural network)\n",
    "    gcn_hidden_channels = 128,\n",
    "    gcn_out_channels = 96,\n",
    "    gcn_pooling_type= \"mean\",\n",
    "    gcn_use_batch_norm = True,\n",
    "    gcn_num_layers = 4,\n",
    "    gcn_dropout_prob = 0.5,\n",
    "    num_channels = 19,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bad429a",
   "metadata": {},
   "source": [
    "### Test 7B: Alternative architecture to improve generalization\n",
    "\n",
    "```\n",
    "Epochs:   6%| | 6/100 [11:12<3:31:19, 134.89s/it, train_loss=0.5436, val_loss=0.4397, best_val_f1=0.5160, lr=1.00e-04, b2025-06-06 18:28:03 - INFO - \n",
    "...\n",
    "Epochs:  22%|| 22/100 [47:24<2:55:59, 135.38s/it, train_loss=0.4128, val_loss=0.3321, best_val_f1=0.6864, lr=1.25e-05, 2025-06-06 19:04:15 - INFO - \n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f882bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Checkpoint loaded. Resuming from epoch 37. Best 'val_f1' score: 0.7191\n",
    "SAVE_PATH = CHECKPOINT_ROOT / \"lstm_gnn_generalizable.pt\"\n",
    "model_generalizable = EEGCNNBiLSTMGCN(\n",
    "    # Parameters for the CNN_BiLSTM_Encoder (temporal encoder)\n",
    "    cnn_dropout_prob = 0.35, # slightly higher dropout to avoid overfitting\n",
    "    lstm_hidden_dim = 128,\n",
    "    lstm_out_dim = 128,\n",
    "    lstm_dropout_prob = 0.35, # slightly higher dropout to avoid overfitting\n",
    "    # Parameters for the EEGGCN (graph neural network)\n",
    "    gcn_hidden_channels = 128,\n",
    "    gcn_out_channels = 96,\n",
    "    gcn_num_layers = 4,\n",
    "    gcn_dropout_prob = 0.6, # slightly higher dropout to avoid overfitting\n",
    "    num_classes = 1,\n",
    "    num_channels = 19,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077b4f3c",
   "metadata": {},
   "source": [
    "### Test 7C: slightly bigger GCN layers\n",
    "\n",
    "BEST MODEL YET!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c3ccd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SAVE_PATH = CHECKPOINT_ROOT / \"lstm_gnn_generalizable_bigger.pt\"\n",
    "model_generalizable_bigger = EEGCNNBiLSTMGCN(\n",
    "    # Parameters for the CNN_BiLSTM_Encoder (temporal encoder)\n",
    "    cnn_dropout_prob = 0.25, # slightly higher dropout to avoid overfitting\n",
    "    lstm_hidden_dim = 128,\n",
    "    lstm_out_dim = 128,\n",
    "    lstm_dropout_prob = 0.25, # slightly higher dropout to avoid overfitting\n",
    "    # Parameters for the EEGGCN (graph neural network)\n",
    "    gcn_hidden_channels = 192,\n",
    "    gcn_out_channels = 128,\n",
    "    gcn_num_layers = 4,\n",
    "    gcn_dropout_prob = 0.6, # slightly higher dropout to avoid overfitting\n",
    "    num_classes = 1,\n",
    "    num_channels = 19,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6355457",
   "metadata": {},
   "source": [
    "### Test 7D: even bigger GCN layers\n",
    "\n",
    "Comparable performance to best model. We might need to increase the number of GCN layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed9d736",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SAVE_PATH = CHECKPOINT_ROOT / \"lstm_gnn_generalizable_even_bigger.pt\"\n",
    "model_generalizable_even_bigger = EEGCNNBiLSTMGCN(\n",
    "    # Parameters for the CNN_BiLSTM_Encoder (temporal encoder)\n",
    "    cnn_dropout_prob = 0.25, # slightly higher dropout to avoid overfitting\n",
    "    lstm_hidden_dim = 128,\n",
    "    lstm_out_dim = 128,\n",
    "    lstm_dropout_prob = 0.25, # slightly higher dropout to avoid overfitting\n",
    "    # Parameters for the EEGGCN (graph neural network)\n",
    "    gcn_hidden_channels = 224,\n",
    "    gcn_out_channels = 192,\n",
    "    gcn_num_layers = 4,\n",
    "    gcn_dropout_prob = 0.6, # slightly higher dropout to avoid overfitting\n",
    "    num_classes = 1,\n",
    "    num_channels = 19,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50956294",
   "metadata": {},
   "source": [
    "### Test 7E: increased number of GCN layers\n",
    "\n",
    "Assumption: the previous model was unable to learn enough, maybe the GCN was unable to capture\n",
    "\n",
    "```\n",
    "Epochs:   9%| | 9/100 [17:54<3:23:31, 134.20s/it, train_loss=0.4532, val_loss=0.3489, best_val_f1=0.6695, lr=5.00e-05, b2025-06-07 17:01:05 - INFO - \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9b1c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_PATH = CHECKPOINT_ROOT / \"lstm_gnn_generalizable_even_more_bigger.pt\"\n",
    "model_generalizable_even_more_bigger = EEGCNNBiLSTMGCN(\n",
    "    # Parameters for the CNN_BiLSTM_Encoder (temporal encoder)\n",
    "    cnn_dropout_prob = 0.25,\n",
    "    lstm_hidden_dim = 128,\n",
    "    lstm_out_dim = 128,\n",
    "    lstm_dropout_prob = 0.25,\n",
    "    # Parameters for the EEGGCN (graph neural network)\n",
    "    gcn_hidden_channels = 224,\n",
    "    gcn_out_channels = 192,\n",
    "    gcn_num_layers = 5,\n",
    "    gcn_dropout_prob = 0.6, # slightly higher dropout to avoid overfitting\n",
    "    num_classes = 1,\n",
    "    num_channels = 19,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08442186",
   "metadata": {},
   "source": [
    "### Test 7F: Increased number of BiLSTM layers + Test 7E architecture\n",
    "\n",
    "Assumpion: we saw a drammatical increase in accuracy by increasing the number of GCN layers. This hints that the model was now able to learn the most from the embeddings. To improve the performance even further without having to increase the number of GCN layers even more (overall reduce complexity, improve generalization), we will try to increase the number of BiLSTM layers. \n",
    "\n",
    "Using multiple BiLSTM layers will allow embeddings to be processed in a more complex way, potentially capturing more intricate relationships in the data. The GCN layers will take care of the graph structure, while the BiLSTM layers will enhance the temporal dependencies and relationships in the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b963a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_PATH = CHECKPOINT_ROOT / \"lstm_gnn_generalizable_even_more_bigger.pt\"\n",
    "model_generalizable_even_more_bigger = EEGCNNBiLSTMGCN(\n",
    "    # Parameters for the CNN_BiLSTM_Encoder (temporal encoder)\n",
    "    cnn_dropout_prob = 0.25,\n",
    "    lstm_hidden_dim = 128,\n",
    "    lstm_out_dim = 128,\n",
    "    lstm_dropout_prob = 0.25,\n",
    "    lstm_num_layers = 2,\n",
    "    # Parameters for the EEGGCN (graph neural network)\n",
    "    gcn_hidden_channels = 224,\n",
    "    gcn_out_channels = 192,\n",
    "    gcn_num_layers = 5,\n",
    "    gcn_dropout_prob = 0.6, # slightly higher dropout to avoid overfitting\n",
    "    num_classes = 1,\n",
    "    num_channels = 19,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3663332c",
   "metadata": {},
   "source": [
    "```\n",
    "Epochs:   1%|                                                                                  | 1/100 [00:00<?, ?it/s]2025-06-07 18:55:16 - INFO -\n",
    "Epochs:   2%| | 2/100 [04:35<7:29:19, 275.10s/it, train_loss=0.6212, val_loss=0.4619, best_val_f1=0.4055, lr=1.00e-04, b2025-06-07 18:59:51 - INFO -\n",
    "Epochs:   3%| | 3/100 [09:09<7:23:49, 274.53s/it, train_loss=0.5819, val_loss=0.4295, best_val_f1=0.4055, lr=1.00e-04, b2025-06-07 19:04:25 - INFO -\n",
    "Epochs:   4%| | 4/100 [13:42<7:18:31, 274.08s/it, train_loss=0.5628, val_loss=0.4437, best_val_f1=0.4055, lr=1.00e-04, b2025-06-07 19:08:59 - INFO -\n",
    "Epochs:   5%| | 5/100 [18:16<7:13:28, 273.78s/it, train_loss=0.5452, val_loss=0.3942, best_val_f1=0.4858, lr=1.00e-04, b2025-06-07 19:13:32 - INFO -\n",
    "Epochs:   6%| | 6/100 [22:49<7:08:41, 273.63s/it, train_loss=0.5334, val_loss=0.4563, best_val_f1=0.4858, lr=1.00e-04, b2025-06-07 19:18:05 - INFO -\n",
    "Epochs:   7%| | 7/100 [27:22<7:04:01, 273.57s/it, train_loss=0.5319, val_loss=0.3738, best_val_f1=0.5137, lr=1.00e-04, b2025-06-07 19:22:39 - INFO -\n",
    "Epochs:   8%| | 8/100 [31:56<6:59:20, 273.48s/it, train_loss=0.5181, val_loss=0.4369, best_val_f1=0.5695, lr=1.00e-04, b2025-06-07 19:27:12 - INFO -\n",
    "Epochs:   9%| | 9/100 [36:29<6:54:50, 273.52s/it, train_loss=0.5220, val_loss=0.4202, best_val_f1=0.5695, lr=1.00e-04, b2025-06-07 19:31:46 - INFO -\n",
    "Epochs:  10%| | 10/100 [41:03<6:50:17, 273.52s/it, train_loss=0.5286, val_loss=0.4167, best_val_f1=0.5695, lr=1.00e-04, 2025-06-07 19:36:19 - INFO -\n",
    "Epochs:  11%| | 11/100 [45:36<6:45:44, 273.53s/it, train_loss=0.5065, val_loss=0.3864, best_val_f1=0.5695, lr=1.00e-04, 2025-06-07 19:40:53 - INFO -\n",
    "Epochs:  12%| | 12/100 [50:10<6:41:03, 273.45s/it, train_loss=0.5158, val_loss=0.5175, best_val_f1=0.5695, lr=5.00e-05, 2025-06-07 19:45:26 - INFO -\n",
    "Epochs:  13%|| 13/100 [54:43<6:36:23, 273.37s/it, train_loss=0.5035, val_loss=0.3785, best_val_f1=0.5940, lr=5.00e-05, 2025-06-07 19:49:59 - INFO -\n",
    "Epochs:  14%|| 14/100 [59:16<6:31:50, 273.38s/it, train_loss=0.4842, val_loss=0.3838, best_val_f1=0.5981, lr=5.00e-05, 2025-06-07 19:54:33 - INFO -\n",
    "Epochs:  15%|| 15/100 [1:03:50<6:27:17, 273.38s/it, train_loss=0.4644, val_loss=0.3493, best_val_f1=0.6106, lr=5.00e-052025-06-07 19:59:06 - INFO -\n",
    "Epochs:  16%|| 16/100 [1:08:23<6:22:46, 273.41s/it, train_loss=0.4887, val_loss=0.3737, best_val_f1=0.6106, lr=5.00e-052025-06-07 20:03:39 - INFO -\n",
    "Epochs:  17%|| 17/100 [1:12:57<6:18:12, 273.41s/it, train_loss=0.4775, val_loss=0.3565, best_val_f1=0.6106, lr=5.00e-052025-06-07 20:08:13 - INFO -\n",
    "Epochs:  18%|| 18/100 [1:17:30<6:13:42, 273.44s/it, train_loss=0.4635, val_loss=0.3704, best_val_f1=0.6106, lr=2.50e-052025-06-07 20:12:46 - INFO -\n",
    "Epochs:  19%|| 19/100 [1:22:04<6:09:15, 273.53s/it, train_loss=0.4501, val_loss=0.3635, best_val_f1=0.6131, lr=2.50e-052025-06-07 20:17:20 - INFO -\n",
    "Epochs:  20%|| 20/100 [1:26:37<6:04:39, 273.49s/it, train_loss=0.4379, val_loss=0.3638, best_val_f1=0.6179, lr=2.50e-052025-06-07 20:21:53 - INFO -\n",
    "Epochs:  21%|| 21/100 [1:31:10<6:00:01, 273.43s/it, train_loss=0.4494, val_loss=0.3543, best_val_f1=0.6179, lr=2.50e-052025-06-07 20:26:27 - INFO -\n",
    "Epochs:  22%|| 22/100 [1:35:44<5:55:26, 273.42s/it, train_loss=0.4616, val_loss=0.3616, best_val_f1=0.6659, lr=2.50e-052025-06-07 20:31:00 - INFO -\n",
    "Epochs:  23%|| 23/100 [1:40:17<5:50:54, 273.44s/it, train_loss=0.4381, val_loss=0.3532, best_val_f1=0.6659, lr=2.50e-052025-06-07 20:35:34 - INFO -\n",
    "Epochs:  24%|| 24/100 [1:44:51<5:46:22, 273.45s/it, train_loss=0.4423, val_loss=0.3635, best_val_f1=0.6659, lr=1.25e-052025-06-07 20:40:07 - INFO -\n",
    "Epochs:  25%|| 25/100 [1:49:24<5:41:52, 273.49s/it, train_loss=0.4291, val_loss=0.3473, best_val_f1=0.6659, lr=1.25e-052025-06-07 20:44:41 - INFO -\n",
    "Epochs:  26%|| 26/100 [1:53:58<5:37:12, 273.42s/it, train_loss=0.4403, val_loss=0.3380, best_val_f1=0.6659, lr=1.25e-052025-06-07 20:49:14 - INFO -\n",
    "Epochs:  27%|| 27/100 [1:58:31<5:32:38, 273.40s/it, train_loss=0.4312, val_loss=0.3374, best_val_f1=0.6659, lr=1.25e-052025-06-07 20:53:47 - INFO -\n",
    "Epochs:  28%|| 28/100 [2:03:05<5:28:07, 273.44s/it, train_loss=0.4393, val_loss=0.3441, best_val_f1=0.6659, lr=1.25e-052025-06-07 20:58:21 - INFO -\n",
    "Epochs:  29%|| 29/100 [2:07:38<5:23:35, 273.46s/it, train_loss=0.4226, val_loss=0.3392, best_val_f1=0.6659, lr=1.25e-052025-06-07 21:02:54 - INFO -\n",
    "Epochs:  30%|| 30/100 [2:12:11<5:19:02, 273.46s/it, train_loss=0.4240, val_loss=0.3525, best_val_f1=0.6659, lr=6.25e-062025-06-07 21:07:28 - INFO -\n",
    "Epochs:  31%|| 31/100 [2:16:45<5:14:28, 273.46s/it, train_loss=0.4249, val_loss=0.3492, best_val_f1=0.6659, lr=6.25e-062025-06-07 21:12:01 - INFO -\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a84badf",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_PATH = CHECKPOINT_ROOT / \"lstm_gnn_generalizable_optimized.pt\"\n",
    "model_generalizable_optimized = EEGCNNBiLSTMGCN(\n",
    "    # Parameters for the CNN_BiLSTM_Encoder (temporal encoder)\n",
    "    cnn_dropout_prob = 0.25,\n",
    "    lstm_hidden_dim = 160,\n",
    "    lstm_out_dim = 128,\n",
    "    lstm_dropout_prob = 0.25,\n",
    "    lstm_num_layers = 2,\n",
    "    # Parameters for the EEGGCN (graph neural network)\n",
    "    gcn_hidden_channels = 192,\n",
    "    gcn_out_channels = 128,\n",
    "    gcn_num_layers = 4,\n",
    "    gcn_dropout_prob = 0.5, # slightly higher dropout to avoid overfitting\n",
    "    num_classes = 1,\n",
    "    num_channels = 19,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1c4b3a",
   "metadata": {},
   "source": [
    "### Test 8: Narrow but Deep GCN model\n",
    "\n",
    "```\n",
    "Epochs:   4%| | 4/100 [02:55<4:41:30, 175.95s/it, train_loss=0.6275, val_loss=0.5123, best_val_f1=0.4575, lr=1.00e-04, b2025-06-06 12:18:56 - INFO - \n",
    "Epochs:   5%| | 5/100 [05:45<4:32:22, 172.02s/it, train_loss=0.5959, val_loss=0.4826, best_val_f1=0.4603, lr=1.00e-04, b2025-06-06 12:21:46 - INFO - \n",
    "Epochs:   6%| | 6/100 [08:32<4:26:22, 170.03s/it, train_loss=0.5773, val_loss=0.4660, best_val_f1=0.4748, lr=1.00e-04, b2025-06-06 12:24:33 - INFO - \n",
    "Epochs:   7%| | 7/100 [11:22<4:23:33, 170.04s/it, train_loss=0.5825, val_loss=0.4700, best_val_f1=0.4915, lr=1.00e-04, b2025-06-06 12:27:23 - INFO - \n",
    "Epochs:   8%| | 8/100 [14:10<4:19:29, 169.23s/it, train_loss=0.5716, val_loss=0.4447, best_val_f1=0.4915, lr=1.00e-04, b2025-06-06 12:30:11 - INFO - \n",
    "Epochs:   9%| | 9/100 [16:53<4:13:31, 167.15s/it, train_loss=0.5577, val_loss=0.4234, best_val_f1=0.4915, lr=1.00e-04, b2025-06-06 12:32:54 - INFO - \n",
    "Epochs:  10%| | 10/100 [19:39<4:10:06, 166.74s/it, train_loss=0.5602, val_loss=0.4572, best_val_f1=0.5157, lr=1.00e-04, 2025-06-06 12:35:40 - INFO - \n",
    "Epochs:  11%| | 11/100 [22:25<4:06:50, 166.41s/it, train_loss=0.5455, val_loss=0.4128, best_val_f1=0.5157, lr=1.00e-04, 2025-06-06 12:38:26 - INFO - \n",
    "...\n",
    "Epochs:  14%|| 14/100 [30:48<4:00:02, 167.47s/it, train_loss=0.5264, val_loss=0.3987, best_val_f1=0.5157, lr=5.00e-05, 2025-06-06 12:46:49 - INFO - \n",
    "Epochs:  21%|| 21/100 [50:13<3:38:18, 165.81s/it, train_loss=0.4978, val_loss=0.3812, best_val_f1=0.5604, lr=5.00e-05, 2025-06-06 13:06:14 - INFO - \n",
    "...\n",
    "Epochs:  23%|| 23/100 [55:42<3:31:40, 164.94s/it, train_loss=0.4842, val_loss=0.3861, best_val_f1=0.5604, lr=5.00e-05, 2025-06-06 13:11:43 - INFO - \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff01da2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_PATH = CHECKPOINT_ROOT / \"lstm_gnn_narrow_deep_model.pt\"\n",
    "narrow_deep_model = EEGCNNBiLSTMGCN(\n",
    "    # --- Simplify the Temporal Encoder ---\n",
    "    cnn_dropout_prob = 0.2,\n",
    "    lstm_hidden_dim = 64,  # Reduced\n",
    "    lstm_out_dim = 64,     # Reduced\n",
    "    lstm_dropout_prob = 0.2,\n",
    "    # --- Focus on the GCN ---\n",
    "    gcn_hidden_channels = 128, # Keep GCN capacity high\n",
    "    gcn_out_channels = 64,\n",
    "    gcn_num_layers = 5,      # Try going even deeper\n",
    "    gcn_dropout_prob = 0.5,\n",
    "    num_classes = 1,\n",
    "    num_channels = 19,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59ef8b3",
   "metadata": {},
   "source": [
    "### Test 9: First best model, with wider + deeper GCN\n",
    "\n",
    "```\n",
    "Epochs:   2%| | 2/100 [03:04<5:00:35, 184.03s/it, train_loss=0.6262, val_loss=0.4520, best_val_f1=0.4011, lr=1.00e-04, b2025-06-06 13:19:08 - INFO - \n",
    "Epochs:   3%| | 3/100 [06:04<4:53:44, 181.70s/it, train_loss=0.6001, val_loss=0.4397, best_val_f1=0.4011, lr=1.00e-04, b2025-06-06 13:22:08 - INFO - \n",
    "Epochs:   4%| | 4/100 [09:03<4:49:14, 180.78s/it, train_loss=0.5907, val_loss=0.4279, best_val_f1=0.4439, lr=1.00e-04, b2025-06-06 13:25:07 - INFO - \n",
    "...\n",
    "Epochs:   7%| | 7/100 [17:56<4:36:15, 178.23s/it, train_loss=0.5604, val_loss=0.4318, best_val_f1=0.4439, lr=1.00e-04, b2025-06-06 13:34:00 - INFO - \n",
    "...\n",
    "Epochs:  11%| | 11/100 [29:57<4:26:12, 179.47s/it, train_loss=0.5255, val_loss=0.3946, best_val_f1=0.4688, lr=1.00e-04, 2025-06-06 13:46:01 - INFO - \n",
    "...\n",
    "Epochs:  33%|| 33/100 [11:42<3:16:12, 175.71s/it, train_loss=0.4578, val_loss=0.4292, best_val_f1=0.6372, lr=2.50e-05, 2025-06-06 16:07:37 - INFO - \n",
    "Epochs:  34%|| 34/100 [14:37<3:12:49, 175.30s/it, train_loss=0.4565, val_loss=0.3764, best_val_f1=0.6372, lr=2.50e-05, 2025-06-06 16:10:31 - INFO - \n",
    "Epochs:  35%|| 35/100 [17:32<3:09:38, 175.05s/it, train_loss=0.4616, val_loss=0.4782, best_val_f1=0.6372, lr=2.50e-05, 2025-06-06 16:13:26 - INFO - \n",
    "...\n",
    "Epochs:  41%|| 41/100 [35:02<2:51:48, 174.72s/it, train_loss=0.4352, val_loss=0.4368, best_val_f1=0.6372, lr=1.25e-05, 2025-06-06 16:30:56 - INFO - \n",
    "Epochs:  42%|| 42/100 [37:58<2:49:18, 175.15s/it, train_loss=0.4346, val_loss=0.4322, best_val_f1=0.6372, lr=1.25e-05, 2025-06-06 16:33:52 - INFO - \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a1b36f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'EEGCNNBiLSTMGNN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m SAVE_PATH \u001b[38;5;241m=\u001b[39m CHECKPOINT_ROOT \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlstm_gnn_new_old_best_model.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m new_old_best_model \u001b[38;5;241m=\u001b[39m \u001b[43mEEGCNNBiLSTMGNN\u001b[49m(\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# Parameters for the CNN_BiLSTM_Encoder (temporal encoder)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     cnn_dropout \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.25\u001b[39m,\n\u001b[1;32m      5\u001b[0m     lstm_hidden_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m128\u001b[39m,\n\u001b[1;32m      6\u001b[0m     lstm_out_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m128\u001b[39m,\n\u001b[1;32m      7\u001b[0m     lstm_dropout \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.25\u001b[39m,\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# Parameters for the EEGGCN (graph neural network)\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     gcn_hidden_channels \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m128\u001b[39m,\n\u001b[1;32m     10\u001b[0m     gcn_out_channels \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m128\u001b[39m, \u001b[38;5;66;03m# from 64 to 128\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     num_gcn_layers \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m, \u001b[38;5;66;03m# from 3 to 4\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     gcn_dropout \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m,\n\u001b[1;32m     13\u001b[0m     num_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     14\u001b[0m     num_channels \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m19\u001b[39m,\n\u001b[1;32m     15\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'EEGCNNBiLSTMGNN' is not defined"
     ]
    }
   ],
   "source": [
    "SAVE_PATH = CHECKPOINT_ROOT / \"lstm_gnn_new_old_best_model.pt\"\n",
    "new_old_best_model = EEGCNNBiLSTMGCN(\n",
    "    # Parameters for the CNN_BiLSTM_Encoder (temporal encoder)\n",
    "    cnn_dropout_prob = 0.25,\n",
    "    lstm_hidden_dim = 128,\n",
    "    lstm_out_dim = 128,\n",
    "    lstm_dropout_prob = 0.25,\n",
    "    # Parameters for the EEGGCN (graph neural network)\n",
    "    gcn_hidden_channels = 128,\n",
    "    gcn_out_channels = 128, # from 64 to 128\n",
    "    gcn_num_layers = 4, # from 3 to 4\n",
    "    gcn_dropout_prob = 0.5,\n",
    "    num_classes = 1,\n",
    "    num_channels = 19,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351da028",
   "metadata": {},
   "source": [
    "### Best model + attention BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e32174c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modules to reload:\n",
      "\n",
      "\n",
      "Modules to skip:\n",
      "\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src.layers.hybrid.cnn_bilstm_attention_gnn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maimport\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhybrid\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcnn_bilstm_attention_gnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EEGCNNBiLSTMAttentionGNN\n\u001b[1;32m      4\u001b[0m SAVE_PATH \u001b[38;5;241m=\u001b[39m CHECKPOINT_ROOT \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlstm_gnn_attention_bilst.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m model_attention_bilstm \u001b[38;5;241m=\u001b[39m EEGCNNBiLSTMAttentionGNN(\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# Parameters for the CNN_BiLSTM_Encoder (temporal encoder)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     cnn_dropout \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.25\u001b[39m, \u001b[38;5;66;03m# slightly higher dropout to avoid overfitting\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     20\u001b[0m     num_layers\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m,  \u001b[38;5;66;03m# Number of layers in the GCN\u001b[39;00m\n\u001b[1;32m     21\u001b[0m )\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'src.layers.hybrid.cnn_bilstm_attention_gnn'"
     ]
    }
   ],
   "source": [
    "%aimport\n",
    "from layers.hybrid.cnn_bilstm_attention_gcn import EEGCNNBiLSTMAttentionGNN\n",
    "\n",
    "SAVE_PATH = CHECKPOINT_ROOT / \"lstm_gnn_attention_bilst.pt\"\n",
    "model_attention_bilstm = EEGCNNBiLSTMAttentionGNN(\n",
    "    # Parameters for the CNN_BiLSTM_Encoder (temporal encoder)\n",
    "    cnn_dropout = 0.25, # slightly higher dropout to avoid overfitting\n",
    "    lstm_hidden_dim = 128,\n",
    "    lstm_out_dim = 128,\n",
    "    lstm_dropout = 0.25, # slightly higher dropout to avoid overfitting\n",
    "    # Parameters for the EEGGCN (graph neural network)\n",
    "    gcn_hidden_channels = 192,\n",
    "    gcn_out_channels = 128,\n",
    "    num_gcn_layers = 4,\n",
    "    gcn_dropout = 0.6, # slightly higher dropout to avoid overfitting\n",
    "    num_classes = 1,\n",
    "    num_channels = 19,\n",
    "    # General parameters\n",
    "    use_batch_norm= True,\n",
    "    num_layers= 2,  # Number of layers in the GCN\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a8a5fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 18:55:16 - INFO - Starting training setup...\n",
      "2025-06-07 18:55:16 - INFO - Model type: GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 18:55:16 - INFO - Device: cuda\n",
      "2025-06-07 18:55:16 - INFO - Batch size: 64\n",
      "2025-06-07 18:55:16 - INFO - Number of epochs: 100\n",
      "2025-06-07 18:55:16 - INFO - Patience: 10\n",
      "2025-06-07 18:55:16 - INFO - Monitor metric: val_f1\n",
      "2025-06-07 18:55:16 - INFO - Total training batches per epoch: 163\n",
      "2025-06-07 18:55:16 - INFO - Starting training from epoch 1 to 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modules to reload:\n",
      "\n",
      "\n",
      "Modules to skip:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   1%|                                                                                  | 1/100 [00:00<?, ?it/s]2025-06-07 18:55:16 - INFO - \n",
      "Epoch 1/100 - Training phase\n",
      "2025-06-07 18:55:19 - INFO - Processing batch 1/163\n",
      "2025-06-07 18:55:19 - INFO - Batch shapes - x: torch.Size([1216, 3000]), edge_index: torch.Size([2, 21888]), y: torch.Size([64, 1])\n",
      "2025-06-07 18:55:21 - INFO - Batch 1/163 - Loss: 0.7608 - Avg batch time: 2.35s\n",
      "2025-06-07 18:55:33 - INFO - Processing batch 11/163\n",
      "2025-06-07 18:55:35 - INFO - Batch 11/163 - Loss: 0.6650 - Avg batch time: 1.39s\n",
      "2025-06-07 18:55:47 - INFO - Processing batch 21/163\n",
      "2025-06-07 18:55:49 - INFO - Batch 21/163 - Loss: 0.6441 - Avg batch time: 1.39s\n",
      "2025-06-07 18:56:01 - INFO - Processing batch 31/163\n",
      "2025-06-07 18:56:03 - INFO - Batch 31/163 - Loss: 0.6227 - Avg batch time: 1.38s\n",
      "2025-06-07 18:56:15 - INFO - Processing batch 41/163\n",
      "2025-06-07 18:56:16 - INFO - Batch 41/163 - Loss: 0.6367 - Avg batch time: 1.38s\n",
      "2025-06-07 18:56:29 - INFO - Processing batch 51/163\n",
      "2025-06-07 18:56:30 - INFO - Batch 51/163 - Loss: 0.6114 - Avg batch time: 1.38s\n",
      "2025-06-07 18:56:43 - INFO - Processing batch 61/163\n",
      "2025-06-07 18:56:44 - INFO - Batch 61/163 - Loss: 0.5856 - Avg batch time: 1.38s\n",
      "2025-06-07 18:56:57 - INFO - Processing batch 71/163\n",
      "2025-06-07 18:56:58 - INFO - Batch 71/163 - Loss: 0.5467 - Avg batch time: 1.38s\n",
      "2025-06-07 18:57:11 - INFO - Processing batch 81/163\n",
      "2025-06-07 18:57:12 - INFO - Batch 81/163 - Loss: 0.5502 - Avg batch time: 1.38s\n",
      "2025-06-07 18:57:24 - INFO - Processing batch 91/163\n",
      "2025-06-07 18:57:26 - INFO - Batch 91/163 - Loss: 0.6267 - Avg batch time: 1.39s\n",
      "2025-06-07 18:57:38 - INFO - Processing batch 101/163\n",
      "2025-06-07 18:57:40 - INFO - Batch 101/163 - Loss: 0.6995 - Avg batch time: 1.38s\n",
      "2025-06-07 18:57:52 - INFO - Processing batch 111/163\n",
      "2025-06-07 18:57:54 - INFO - Batch 111/163 - Loss: 0.6704 - Avg batch time: 1.38s\n",
      "2025-06-07 18:58:06 - INFO - Processing batch 121/163\n",
      "2025-06-07 18:58:07 - INFO - Batch 121/163 - Loss: 0.5513 - Avg batch time: 1.38s\n",
      "2025-06-07 18:58:20 - INFO - Processing batch 131/163\n",
      "2025-06-07 18:58:21 - INFO - Batch 131/163 - Loss: 0.5943 - Avg batch time: 1.38s\n",
      "2025-06-07 18:58:34 - INFO - Processing batch 141/163\n",
      "2025-06-07 18:58:35 - INFO - Batch 141/163 - Loss: 0.5353 - Avg batch time: 1.38s\n",
      "2025-06-07 18:58:48 - INFO - Processing batch 151/163\n",
      "2025-06-07 18:58:49 - INFO - Batch 151/163 - Loss: 0.6839 - Avg batch time: 1.38s\n",
      "2025-06-07 18:59:02 - INFO - Processing batch 161/163\n",
      "2025-06-07 18:59:03 - INFO - Batch 161/163 - Loss: 0.6071 - Avg batch time: 1.37s\n",
      "2025-06-07 18:59:05 - INFO - \n",
      "Epoch 1 training completed in 229.04s\n",
      "2025-06-07 18:59:05 - INFO - Average training loss: 0.6212\n",
      "Epochs:   2%| | 2/100 [04:35<7:29:19, 275.10s/it, train_loss=0.6212, val_loss=0.4619, best_val_f1=0.4055, lr=1.00e-04, b2025-06-07 18:59:51 - INFO - \n",
      "Epoch 2/100 - Training phase\n",
      "2025-06-07 18:59:53 - INFO - Processing batch 1/163\n",
      "2025-06-07 18:59:53 - INFO - Batch shapes - x: torch.Size([1216, 3000]), edge_index: torch.Size([2, 21888]), y: torch.Size([64, 1])\n",
      "2025-06-07 18:59:55 - INFO - Batch 1/163 - Loss: 0.6564 - Avg batch time: 1.39s\n",
      "2025-06-07 19:00:07 - INFO - Processing batch 11/163\n",
      "2025-06-07 19:00:09 - INFO - Batch 11/163 - Loss: 0.5856 - Avg batch time: 1.40s\n",
      "2025-06-07 19:00:21 - INFO - Processing batch 21/163\n",
      "2025-06-07 19:00:23 - INFO - Batch 21/163 - Loss: 0.5892 - Avg batch time: 1.38s\n",
      "2025-06-07 19:00:35 - INFO - Processing batch 31/163\n",
      "2025-06-07 19:00:36 - INFO - Batch 31/163 - Loss: 0.6160 - Avg batch time: 1.38s\n",
      "2025-06-07 19:00:49 - INFO - Processing batch 41/163\n",
      "2025-06-07 19:00:50 - INFO - Batch 41/163 - Loss: 0.5318 - Avg batch time: 1.38s\n",
      "2025-06-07 19:01:03 - INFO - Processing batch 51/163\n",
      "2025-06-07 19:01:04 - INFO - Batch 51/163 - Loss: 0.5836 - Avg batch time: 1.39s\n",
      "2025-06-07 19:01:17 - INFO - Processing batch 61/163\n",
      "2025-06-07 19:01:18 - INFO - Batch 61/163 - Loss: 0.5870 - Avg batch time: 1.39s\n",
      "2025-06-07 19:01:31 - INFO - Processing batch 71/163\n",
      "2025-06-07 19:01:32 - INFO - Batch 71/163 - Loss: 0.5782 - Avg batch time: 1.38s\n",
      "2025-06-07 19:01:45 - INFO - Processing batch 81/163\n",
      "2025-06-07 19:01:46 - INFO - Batch 81/163 - Loss: 0.4488 - Avg batch time: 1.39s\n",
      "2025-06-07 19:01:59 - INFO - Processing batch 91/163\n",
      "2025-06-07 19:02:00 - INFO - Batch 91/163 - Loss: 0.6107 - Avg batch time: 1.39s\n",
      "2025-06-07 19:02:12 - INFO - Processing batch 101/163\n",
      "2025-06-07 19:02:14 - INFO - Batch 101/163 - Loss: 0.6420 - Avg batch time: 1.38s\n",
      "2025-06-07 19:02:26 - INFO - Processing batch 111/163\n",
      "2025-06-07 19:02:28 - INFO - Batch 111/163 - Loss: 0.5760 - Avg batch time: 1.39s\n",
      "2025-06-07 19:02:40 - INFO - Processing batch 121/163\n",
      "2025-06-07 19:02:42 - INFO - Batch 121/163 - Loss: 0.6081 - Avg batch time: 1.38s\n",
      "2025-06-07 19:02:54 - INFO - Processing batch 131/163\n",
      "2025-06-07 19:02:56 - INFO - Batch 131/163 - Loss: 0.5463 - Avg batch time: 1.39s\n",
      "2025-06-07 19:03:08 - INFO - Processing batch 141/163\n",
      "2025-06-07 19:03:09 - INFO - Batch 141/163 - Loss: 0.5691 - Avg batch time: 1.38s\n",
      "2025-06-07 19:03:22 - INFO - Processing batch 151/163\n",
      "2025-06-07 19:03:23 - INFO - Batch 151/163 - Loss: 0.6591 - Avg batch time: 1.38s\n",
      "2025-06-07 19:03:36 - INFO - Processing batch 161/163\n",
      "2025-06-07 19:03:37 - INFO - Batch 161/163 - Loss: 0.4834 - Avg batch time: 1.38s\n",
      "2025-06-07 19:03:39 - INFO - \n",
      "Epoch 2 training completed in 228.19s\n",
      "2025-06-07 19:03:39 - INFO - Average training loss: 0.5819\n",
      "Epochs:   3%| | 3/100 [09:09<7:23:49, 274.53s/it, train_loss=0.5819, val_loss=0.4295, best_val_f1=0.4055, lr=1.00e-04, b2025-06-07 19:04:25 - INFO - \n",
      "Epoch 3/100 - Training phase\n",
      "2025-06-07 19:04:27 - INFO - Processing batch 1/163\n",
      "2025-06-07 19:04:27 - INFO - Batch shapes - x: torch.Size([1216, 3000]), edge_index: torch.Size([2, 21888]), y: torch.Size([64, 1])\n",
      "2025-06-07 19:04:29 - INFO - Batch 1/163 - Loss: 0.5003 - Avg batch time: 1.44s\n",
      "2025-06-07 19:04:41 - INFO - Processing batch 11/163\n",
      "2025-06-07 19:04:43 - INFO - Batch 11/163 - Loss: 0.6860 - Avg batch time: 1.39s\n",
      "2025-06-07 19:04:55 - INFO - Processing batch 21/163\n",
      "2025-06-07 19:04:57 - INFO - Batch 21/163 - Loss: 0.5652 - Avg batch time: 1.38s\n",
      "2025-06-07 19:05:09 - INFO - Processing batch 31/163\n",
      "2025-06-07 19:05:10 - INFO - Batch 31/163 - Loss: 0.5241 - Avg batch time: 1.39s\n",
      "2025-06-07 19:05:23 - INFO - Processing batch 41/163\n",
      "2025-06-07 19:05:24 - INFO - Batch 41/163 - Loss: 0.5688 - Avg batch time: 1.39s\n",
      "2025-06-07 19:05:37 - INFO - Processing batch 51/163\n",
      "2025-06-07 19:05:38 - INFO - Batch 51/163 - Loss: 0.5925 - Avg batch time: 1.39s\n",
      "2025-06-07 19:05:51 - INFO - Processing batch 61/163\n",
      "2025-06-07 19:05:52 - INFO - Batch 61/163 - Loss: 0.6200 - Avg batch time: 1.38s\n",
      "2025-06-07 19:06:05 - INFO - Processing batch 71/163\n",
      "2025-06-07 19:06:06 - INFO - Batch 71/163 - Loss: 0.5203 - Avg batch time: 1.38s\n",
      "2025-06-07 19:06:18 - INFO - Processing batch 81/163\n",
      "2025-06-07 19:06:20 - INFO - Batch 81/163 - Loss: 0.6344 - Avg batch time: 1.38s\n",
      "2025-06-07 19:06:32 - INFO - Processing batch 91/163\n",
      "2025-06-07 19:06:34 - INFO - Batch 91/163 - Loss: 0.5086 - Avg batch time: 1.38s\n",
      "2025-06-07 19:06:46 - INFO - Processing batch 101/163\n",
      "2025-06-07 19:06:48 - INFO - Batch 101/163 - Loss: 0.5644 - Avg batch time: 1.38s\n",
      "2025-06-07 19:07:00 - INFO - Processing batch 111/163\n",
      "2025-06-07 19:07:01 - INFO - Batch 111/163 - Loss: 0.5425 - Avg batch time: 1.39s\n",
      "2025-06-07 19:07:14 - INFO - Processing batch 121/163\n",
      "2025-06-07 19:07:15 - INFO - Batch 121/163 - Loss: 0.7799 - Avg batch time: 1.38s\n",
      "2025-06-07 19:07:28 - INFO - Processing batch 131/163\n",
      "2025-06-07 19:07:29 - INFO - Batch 131/163 - Loss: 0.5264 - Avg batch time: 1.38s\n",
      "2025-06-07 19:07:42 - INFO - Processing batch 141/163\n",
      "2025-06-07 19:07:43 - INFO - Batch 141/163 - Loss: 0.5425 - Avg batch time: 1.39s\n",
      "2025-06-07 19:07:55 - INFO - Processing batch 151/163\n",
      "2025-06-07 19:07:57 - INFO - Batch 151/163 - Loss: 0.4691 - Avg batch time: 1.39s\n",
      "2025-06-07 19:08:09 - INFO - Processing batch 161/163\n",
      "2025-06-07 19:08:11 - INFO - Batch 161/163 - Loss: 0.5542 - Avg batch time: 1.38s\n",
      "2025-06-07 19:08:13 - INFO - \n",
      "Epoch 3 training completed in 227.57s\n",
      "2025-06-07 19:08:13 - INFO - Average training loss: 0.5628\n",
      "Epochs:   4%| | 4/100 [13:42<7:18:31, 274.08s/it, train_loss=0.5628, val_loss=0.4437, best_val_f1=0.4055, lr=1.00e-04, b2025-06-07 19:08:59 - INFO - \n",
      "Epoch 4/100 - Training phase\n",
      "2025-06-07 19:09:01 - INFO - Processing batch 1/163\n",
      "2025-06-07 19:09:01 - INFO - Batch shapes - x: torch.Size([1216, 3000]), edge_index: torch.Size([2, 21888]), y: torch.Size([64, 1])\n",
      "2025-06-07 19:09:02 - INFO - Batch 1/163 - Loss: 0.5468 - Avg batch time: 1.42s\n",
      "2025-06-07 19:09:15 - INFO - Processing batch 11/163\n",
      "2025-06-07 19:09:16 - INFO - Batch 11/163 - Loss: 0.6276 - Avg batch time: 1.39s\n",
      "2025-06-07 19:09:29 - INFO - Processing batch 21/163\n",
      "2025-06-07 19:09:30 - INFO - Batch 21/163 - Loss: 0.4224 - Avg batch time: 1.38s\n",
      "2025-06-07 19:09:43 - INFO - Processing batch 31/163\n",
      "2025-06-07 19:09:44 - INFO - Batch 31/163 - Loss: 0.6056 - Avg batch time: 1.38s\n",
      "2025-06-07 19:09:56 - INFO - Processing batch 41/163\n",
      "2025-06-07 19:09:58 - INFO - Batch 41/163 - Loss: 0.6172 - Avg batch time: 1.39s\n",
      "2025-06-07 19:10:10 - INFO - Processing batch 51/163\n",
      "2025-06-07 19:10:12 - INFO - Batch 51/163 - Loss: 0.5110 - Avg batch time: 1.39s\n",
      "2025-06-07 19:10:24 - INFO - Processing batch 61/163\n",
      "2025-06-07 19:10:26 - INFO - Batch 61/163 - Loss: 0.5219 - Avg batch time: 1.38s\n",
      "2025-06-07 19:10:38 - INFO - Processing batch 71/163\n",
      "2025-06-07 19:10:39 - INFO - Batch 71/163 - Loss: 0.5329 - Avg batch time: 1.38s\n",
      "2025-06-07 19:10:52 - INFO - Processing batch 81/163\n",
      "2025-06-07 19:10:53 - INFO - Batch 81/163 - Loss: 0.4520 - Avg batch time: 1.38s\n",
      "2025-06-07 19:11:06 - INFO - Processing batch 91/163\n",
      "2025-06-07 19:11:07 - INFO - Batch 91/163 - Loss: 0.5676 - Avg batch time: 1.38s\n",
      "2025-06-07 19:11:20 - INFO - Processing batch 101/163\n",
      "2025-06-07 19:11:21 - INFO - Batch 101/163 - Loss: 0.5148 - Avg batch time: 1.38s\n",
      "2025-06-07 19:11:33 - INFO - Processing batch 111/163\n",
      "2025-06-07 19:11:35 - INFO - Batch 111/163 - Loss: 0.5464 - Avg batch time: 1.38s\n",
      "2025-06-07 19:11:47 - INFO - Processing batch 121/163\n",
      "2025-06-07 19:11:49 - INFO - Batch 121/163 - Loss: 0.4956 - Avg batch time: 1.38s\n",
      "2025-06-07 19:12:01 - INFO - Processing batch 131/163\n",
      "2025-06-07 19:12:02 - INFO - Batch 131/163 - Loss: 0.4299 - Avg batch time: 1.38s\n",
      "2025-06-07 19:12:15 - INFO - Processing batch 141/163\n",
      "2025-06-07 19:12:16 - INFO - Batch 141/163 - Loss: 0.6664 - Avg batch time: 1.38s\n",
      "2025-06-07 19:12:29 - INFO - Processing batch 151/163\n",
      "2025-06-07 19:12:30 - INFO - Batch 151/163 - Loss: 0.6383 - Avg batch time: 1.39s\n",
      "2025-06-07 19:12:43 - INFO - Processing batch 161/163\n",
      "2025-06-07 19:12:44 - INFO - Batch 161/163 - Loss: 0.5089 - Avg batch time: 1.37s\n",
      "2025-06-07 19:12:46 - INFO - \n",
      "Epoch 4 training completed in 227.29s\n",
      "2025-06-07 19:12:46 - INFO - Average training loss: 0.5452\n",
      "Epochs:   5%| | 5/100 [18:16<7:13:28, 273.78s/it, train_loss=0.5452, val_loss=0.3942, best_val_f1=0.4858, lr=1.00e-04, b2025-06-07 19:13:32 - INFO - \n",
      "Epoch 5/100 - Training phase\n",
      "2025-06-07 19:13:34 - INFO - Processing batch 1/163\n",
      "2025-06-07 19:13:34 - INFO - Batch shapes - x: torch.Size([1216, 3000]), edge_index: torch.Size([2, 21888]), y: torch.Size([64, 1])\n",
      "2025-06-07 19:13:36 - INFO - Batch 1/163 - Loss: 0.5033 - Avg batch time: 1.41s\n",
      "2025-06-07 19:13:48 - INFO - Processing batch 11/163\n",
      "2025-06-07 19:13:50 - INFO - Batch 11/163 - Loss: 0.4848 - Avg batch time: 1.39s\n",
      "2025-06-07 19:14:02 - INFO - Processing batch 21/163\n",
      "2025-06-07 19:14:03 - INFO - Batch 21/163 - Loss: 0.5311 - Avg batch time: 1.39s\n",
      "2025-06-07 19:14:16 - INFO - Processing batch 31/163\n",
      "2025-06-07 19:14:17 - INFO - Batch 31/163 - Loss: 0.5745 - Avg batch time: 1.39s\n",
      "2025-06-07 19:14:30 - INFO - Processing batch 41/163\n",
      "2025-06-07 19:14:31 - INFO - Batch 41/163 - Loss: 0.4751 - Avg batch time: 1.38s\n",
      "2025-06-07 19:14:44 - INFO - Processing batch 51/163\n",
      "2025-06-07 19:14:45 - INFO - Batch 51/163 - Loss: 0.5182 - Avg batch time: 1.38s\n",
      "2025-06-07 19:14:57 - INFO - Processing batch 61/163\n",
      "2025-06-07 19:14:59 - INFO - Batch 61/163 - Loss: 0.4241 - Avg batch time: 1.39s\n",
      "2025-06-07 19:15:11 - INFO - Processing batch 71/163\n",
      "2025-06-07 19:15:13 - INFO - Batch 71/163 - Loss: 0.5866 - Avg batch time: 1.38s\n",
      "2025-06-07 19:15:25 - INFO - Processing batch 81/163\n",
      "2025-06-07 19:15:27 - INFO - Batch 81/163 - Loss: 0.4995 - Avg batch time: 1.39s\n",
      "2025-06-07 19:15:39 - INFO - Processing batch 91/163\n",
      "2025-06-07 19:15:40 - INFO - Batch 91/163 - Loss: 0.4968 - Avg batch time: 1.39s\n",
      "2025-06-07 19:15:53 - INFO - Processing batch 101/163\n",
      "2025-06-07 19:15:54 - INFO - Batch 101/163 - Loss: 0.6256 - Avg batch time: 1.38s\n",
      "2025-06-07 19:16:07 - INFO - Processing batch 111/163\n",
      "2025-06-07 19:16:08 - INFO - Batch 111/163 - Loss: 0.5270 - Avg batch time: 1.39s\n",
      "2025-06-07 19:16:21 - INFO - Processing batch 121/163\n",
      "2025-06-07 19:16:22 - INFO - Batch 121/163 - Loss: 0.5594 - Avg batch time: 1.38s\n",
      "2025-06-07 19:16:34 - INFO - Processing batch 131/163\n",
      "2025-06-07 19:16:36 - INFO - Batch 131/163 - Loss: 0.5838 - Avg batch time: 1.39s\n",
      "2025-06-07 19:16:48 - INFO - Processing batch 141/163\n",
      "2025-06-07 19:16:50 - INFO - Batch 141/163 - Loss: 0.5865 - Avg batch time: 1.39s\n",
      "2025-06-07 19:17:02 - INFO - Processing batch 151/163\n",
      "2025-06-07 19:17:04 - INFO - Batch 151/163 - Loss: 0.5153 - Avg batch time: 1.39s\n",
      "2025-06-07 19:17:16 - INFO - Processing batch 161/163\n",
      "2025-06-07 19:17:17 - INFO - Batch 161/163 - Loss: 0.5803 - Avg batch time: 1.38s\n",
      "2025-06-07 19:17:19 - INFO - \n",
      "Epoch 5 training completed in 227.40s\n",
      "2025-06-07 19:17:19 - INFO - Average training loss: 0.5334\n",
      "Epochs:   6%| | 6/100 [22:49<7:08:41, 273.63s/it, train_loss=0.5334, val_loss=0.4563, best_val_f1=0.4858, lr=1.00e-04, b2025-06-07 19:18:05 - INFO - \n",
      "Epoch 6/100 - Training phase\n",
      "2025-06-07 19:18:08 - INFO - Processing batch 1/163\n",
      "2025-06-07 19:18:08 - INFO - Batch shapes - x: torch.Size([1216, 3000]), edge_index: torch.Size([2, 21888]), y: torch.Size([64, 1])\n",
      "2025-06-07 19:18:09 - INFO - Batch 1/163 - Loss: 0.5405 - Avg batch time: 1.41s\n",
      "2025-06-07 19:18:22 - INFO - Processing batch 11/163\n",
      "2025-06-07 19:18:23 - INFO - Batch 11/163 - Loss: 0.4477 - Avg batch time: 1.39s\n",
      "2025-06-07 19:18:35 - INFO - Processing batch 21/163\n",
      "2025-06-07 19:18:37 - INFO - Batch 21/163 - Loss: 0.5928 - Avg batch time: 1.39s\n",
      "2025-06-07 19:18:49 - INFO - Processing batch 31/163\n",
      "2025-06-07 19:18:51 - INFO - Batch 31/163 - Loss: 0.4940 - Avg batch time: 1.39s\n",
      "2025-06-07 19:19:03 - INFO - Processing batch 41/163\n",
      "2025-06-07 19:19:05 - INFO - Batch 41/163 - Loss: 0.5566 - Avg batch time: 1.38s\n",
      "2025-06-07 19:19:17 - INFO - Processing batch 51/163\n",
      "2025-06-07 19:19:18 - INFO - Batch 51/163 - Loss: 0.4290 - Avg batch time: 1.39s\n",
      "2025-06-07 19:19:31 - INFO - Processing batch 61/163\n",
      "2025-06-07 19:19:32 - INFO - Batch 61/163 - Loss: 0.5643 - Avg batch time: 1.39s\n",
      "2025-06-07 19:19:45 - INFO - Processing batch 71/163\n",
      "2025-06-07 19:19:46 - INFO - Batch 71/163 - Loss: 0.5218 - Avg batch time: 1.38s\n",
      "2025-06-07 19:19:59 - INFO - Processing batch 81/163\n",
      "2025-06-07 19:20:00 - INFO - Batch 81/163 - Loss: 0.4940 - Avg batch time: 1.38s\n",
      "2025-06-07 19:20:13 - INFO - Processing batch 91/163\n",
      "2025-06-07 19:20:14 - INFO - Batch 91/163 - Loss: 0.4807 - Avg batch time: 1.39s\n",
      "2025-06-07 19:20:26 - INFO - Processing batch 101/163\n",
      "2025-06-07 19:20:28 - INFO - Batch 101/163 - Loss: 0.5369 - Avg batch time: 1.38s\n",
      "2025-06-07 19:20:40 - INFO - Processing batch 111/163\n",
      "2025-06-07 19:20:42 - INFO - Batch 111/163 - Loss: 0.6204 - Avg batch time: 1.38s\n",
      "2025-06-07 19:20:54 - INFO - Processing batch 121/163\n",
      "2025-06-07 19:20:55 - INFO - Batch 121/163 - Loss: 0.5362 - Avg batch time: 1.39s\n",
      "2025-06-07 19:21:08 - INFO - Processing batch 131/163\n",
      "2025-06-07 19:21:09 - INFO - Batch 131/163 - Loss: 0.5743 - Avg batch time: 1.38s\n",
      "2025-06-07 19:21:22 - INFO - Processing batch 141/163\n",
      "2025-06-07 19:21:23 - INFO - Batch 141/163 - Loss: 0.4880 - Avg batch time: 1.39s\n",
      "2025-06-07 19:21:36 - INFO - Processing batch 151/163\n",
      "2025-06-07 19:21:37 - INFO - Batch 151/163 - Loss: 0.4645 - Avg batch time: 1.39s\n",
      "2025-06-07 19:21:49 - INFO - Processing batch 161/163\n",
      "2025-06-07 19:21:51 - INFO - Batch 161/163 - Loss: 0.4914 - Avg batch time: 1.38s\n",
      "2025-06-07 19:21:53 - INFO - \n",
      "Epoch 6 training completed in 227.48s\n",
      "2025-06-07 19:21:53 - INFO - Average training loss: 0.5319\n",
      "Epochs:   7%| | 7/100 [27:22<7:04:01, 273.57s/it, train_loss=0.5319, val_loss=0.3738, best_val_f1=0.5137, lr=1.00e-04, b2025-06-07 19:22:39 - INFO - \n",
      "Epoch 7/100 - Training phase\n",
      "2025-06-07 19:22:41 - INFO - Processing batch 1/163\n",
      "2025-06-07 19:22:41 - INFO - Batch shapes - x: torch.Size([1216, 3000]), edge_index: torch.Size([2, 21888]), y: torch.Size([64, 1])\n",
      "2025-06-07 19:22:42 - INFO - Batch 1/163 - Loss: 0.5998 - Avg batch time: 1.42s\n",
      "2025-06-07 19:22:55 - INFO - Processing batch 11/163\n",
      "2025-06-07 19:22:56 - INFO - Batch 11/163 - Loss: 0.5103 - Avg batch time: 1.39s\n",
      "2025-06-07 19:23:09 - INFO - Processing batch 21/163\n",
      "2025-06-07 19:23:10 - INFO - Batch 21/163 - Loss: 0.6480 - Avg batch time: 1.38s\n",
      "2025-06-07 19:23:23 - INFO - Processing batch 31/163\n",
      "2025-06-07 19:23:24 - INFO - Batch 31/163 - Loss: 0.5389 - Avg batch time: 1.38s\n",
      "2025-06-07 19:23:37 - INFO - Processing batch 41/163\n",
      "2025-06-07 19:23:38 - INFO - Batch 41/163 - Loss: 0.4633 - Avg batch time: 1.39s\n",
      "2025-06-07 19:23:50 - INFO - Processing batch 51/163\n",
      "2025-06-07 19:23:52 - INFO - Batch 51/163 - Loss: 0.5174 - Avg batch time: 1.39s\n",
      "2025-06-07 19:24:04 - INFO - Processing batch 61/163\n",
      "2025-06-07 19:24:06 - INFO - Batch 61/163 - Loss: 0.5413 - Avg batch time: 1.39s\n",
      "2025-06-07 19:24:18 - INFO - Processing batch 71/163\n",
      "2025-06-07 19:24:20 - INFO - Batch 71/163 - Loss: 0.4716 - Avg batch time: 1.39s\n",
      "2025-06-07 19:24:32 - INFO - Processing batch 81/163\n",
      "2025-06-07 19:24:33 - INFO - Batch 81/163 - Loss: 0.5074 - Avg batch time: 1.38s\n",
      "2025-06-07 19:24:46 - INFO - Processing batch 91/163\n",
      "2025-06-07 19:24:47 - INFO - Batch 91/163 - Loss: 0.6028 - Avg batch time: 1.39s\n",
      "2025-06-07 19:25:00 - INFO - Processing batch 101/163\n",
      "2025-06-07 19:25:01 - INFO - Batch 101/163 - Loss: 0.4400 - Avg batch time: 1.38s\n",
      "2025-06-07 19:25:14 - INFO - Processing batch 111/163\n",
      "2025-06-07 19:25:15 - INFO - Batch 111/163 - Loss: 0.5264 - Avg batch time: 1.38s\n",
      "2025-06-07 19:25:27 - INFO - Processing batch 121/163\n",
      "2025-06-07 19:25:29 - INFO - Batch 121/163 - Loss: 0.5233 - Avg batch time: 1.39s\n",
      "2025-06-07 19:25:41 - INFO - Processing batch 131/163\n",
      "2025-06-07 19:25:43 - INFO - Batch 131/163 - Loss: 0.4961 - Avg batch time: 1.38s\n",
      "2025-06-07 19:25:55 - INFO - Processing batch 141/163\n",
      "2025-06-07 19:25:56 - INFO - Batch 141/163 - Loss: 0.4304 - Avg batch time: 1.38s\n",
      "2025-06-07 19:26:09 - INFO - Processing batch 151/163\n",
      "2025-06-07 19:26:10 - INFO - Batch 151/163 - Loss: 0.3865 - Avg batch time: 1.38s\n",
      "2025-06-07 19:26:23 - INFO - Processing batch 161/163\n",
      "2025-06-07 19:26:24 - INFO - Batch 161/163 - Loss: 0.5140 - Avg batch time: 1.38s\n",
      "2025-06-07 19:26:26 - INFO - \n",
      "Epoch 7 training completed in 227.36s\n",
      "2025-06-07 19:26:26 - INFO - Average training loss: 0.5181\n",
      "Epochs:   8%| | 8/100 [31:56<6:59:20, 273.48s/it, train_loss=0.5181, val_loss=0.4369, best_val_f1=0.5695, lr=1.00e-04, b2025-06-07 19:27:12 - INFO - \n",
      "Epoch 8/100 - Training phase\n",
      "2025-06-07 19:27:14 - INFO - Processing batch 1/163\n",
      "2025-06-07 19:27:14 - INFO - Batch shapes - x: torch.Size([1216, 3000]), edge_index: torch.Size([2, 21888]), y: torch.Size([64, 1])\n",
      "2025-06-07 19:27:16 - INFO - Batch 1/163 - Loss: 0.4704 - Avg batch time: 1.42s\n",
      "2025-06-07 19:27:28 - INFO - Processing batch 11/163\n",
      "2025-06-07 19:27:30 - INFO - Batch 11/163 - Loss: 0.5520 - Avg batch time: 1.39s\n",
      "2025-06-07 19:27:42 - INFO - Processing batch 21/163\n",
      "2025-06-07 19:27:44 - INFO - Batch 21/163 - Loss: 0.4766 - Avg batch time: 1.38s\n",
      "2025-06-07 19:27:56 - INFO - Processing batch 31/163\n",
      "2025-06-07 19:27:57 - INFO - Batch 31/163 - Loss: 0.4651 - Avg batch time: 1.39s\n",
      "2025-06-07 19:28:10 - INFO - Processing batch 41/163\n",
      "2025-06-07 19:28:11 - INFO - Batch 41/163 - Loss: 0.4275 - Avg batch time: 1.39s\n",
      "2025-06-07 19:28:24 - INFO - Processing batch 51/163\n",
      "2025-06-07 19:28:25 - INFO - Batch 51/163 - Loss: 0.5074 - Avg batch time: 1.39s\n",
      "2025-06-07 19:28:38 - INFO - Processing batch 61/163\n",
      "2025-06-07 19:28:39 - INFO - Batch 61/163 - Loss: 0.5036 - Avg batch time: 1.39s\n",
      "2025-06-07 19:28:52 - INFO - Processing batch 71/163\n",
      "2025-06-07 19:28:53 - INFO - Batch 71/163 - Loss: 0.5477 - Avg batch time: 1.39s\n",
      "2025-06-07 19:29:05 - INFO - Processing batch 81/163\n",
      "2025-06-07 19:29:07 - INFO - Batch 81/163 - Loss: 0.4993 - Avg batch time: 1.39s\n",
      "2025-06-07 19:29:19 - INFO - Processing batch 91/163\n",
      "2025-06-07 19:29:21 - INFO - Batch 91/163 - Loss: 0.5566 - Avg batch time: 1.38s\n",
      "2025-06-07 19:29:33 - INFO - Processing batch 101/163\n",
      "2025-06-07 19:29:35 - INFO - Batch 101/163 - Loss: 0.4237 - Avg batch time: 1.39s\n",
      "2025-06-07 19:29:47 - INFO - Processing batch 111/163\n",
      "2025-06-07 19:29:48 - INFO - Batch 111/163 - Loss: 0.5596 - Avg batch time: 1.38s\n",
      "2025-06-07 19:30:01 - INFO - Processing batch 121/163\n",
      "2025-06-07 19:30:02 - INFO - Batch 121/163 - Loss: 0.5898 - Avg batch time: 1.39s\n",
      "2025-06-07 19:30:15 - INFO - Processing batch 131/163\n",
      "2025-06-07 19:30:16 - INFO - Batch 131/163 - Loss: 0.5113 - Avg batch time: 1.39s\n",
      "2025-06-07 19:30:29 - INFO - Processing batch 141/163\n",
      "2025-06-07 19:30:30 - INFO - Batch 141/163 - Loss: 0.5639 - Avg batch time: 1.39s\n",
      "2025-06-07 19:30:43 - INFO - Processing batch 151/163\n",
      "2025-06-07 19:30:44 - INFO - Batch 151/163 - Loss: 0.5239 - Avg batch time: 1.39s\n",
      "2025-06-07 19:30:56 - INFO - Processing batch 161/163\n",
      "2025-06-07 19:30:58 - INFO - Batch 161/163 - Loss: 0.5335 - Avg batch time: 1.38s\n",
      "2025-06-07 19:31:00 - INFO - \n",
      "Epoch 8 training completed in 227.60s\n",
      "2025-06-07 19:31:00 - INFO - Average training loss: 0.5220\n",
      "Epochs:   9%| | 9/100 [36:29<6:54:50, 273.52s/it, train_loss=0.5220, val_loss=0.4202, best_val_f1=0.5695, lr=1.00e-04, b2025-06-07 19:31:46 - INFO - \n",
      "Epoch 9/100 - Training phase\n",
      "2025-06-07 19:31:48 - INFO - Processing batch 1/163\n",
      "2025-06-07 19:31:48 - INFO - Batch shapes - x: torch.Size([1216, 3000]), edge_index: torch.Size([2, 21888]), y: torch.Size([64, 1])\n",
      "2025-06-07 19:31:49 - INFO - Batch 1/163 - Loss: 0.6036 - Avg batch time: 1.42s\n",
      "2025-06-07 19:32:02 - INFO - Processing batch 11/163\n",
      "2025-06-07 19:32:03 - INFO - Batch 11/163 - Loss: 0.7166 - Avg batch time: 1.39s\n",
      "2025-06-07 19:32:16 - INFO - Processing batch 21/163\n",
      "2025-06-07 19:32:17 - INFO - Batch 21/163 - Loss: 0.5273 - Avg batch time: 1.38s\n",
      "2025-06-07 19:32:30 - INFO - Processing batch 31/163\n",
      "2025-06-07 19:32:31 - INFO - Batch 31/163 - Loss: 0.4349 - Avg batch time: 1.38s\n",
      "2025-06-07 19:32:43 - INFO - Processing batch 41/163\n",
      "2025-06-07 19:32:45 - INFO - Batch 41/163 - Loss: 0.6113 - Avg batch time: 1.38s\n",
      "2025-06-07 19:32:57 - INFO - Processing batch 51/163\n",
      "2025-06-07 19:32:59 - INFO - Batch 51/163 - Loss: 0.5297 - Avg batch time: 1.39s\n",
      "2025-06-07 19:33:11 - INFO - Processing batch 61/163\n",
      "2025-06-07 19:33:13 - INFO - Batch 61/163 - Loss: 0.5582 - Avg batch time: 1.39s\n",
      "2025-06-07 19:33:25 - INFO - Processing batch 71/163\n",
      "2025-06-07 19:33:26 - INFO - Batch 71/163 - Loss: 0.5138 - Avg batch time: 1.39s\n",
      "2025-06-07 19:33:39 - INFO - Processing batch 81/163\n",
      "2025-06-07 19:33:40 - INFO - Batch 81/163 - Loss: 0.5359 - Avg batch time: 1.39s\n",
      "2025-06-07 19:33:53 - INFO - Processing batch 91/163\n",
      "2025-06-07 19:33:54 - INFO - Batch 91/163 - Loss: 0.5192 - Avg batch time: 1.38s\n",
      "2025-06-07 19:34:07 - INFO - Processing batch 101/163\n",
      "2025-06-07 19:34:08 - INFO - Batch 101/163 - Loss: 0.6522 - Avg batch time: 1.38s\n",
      "2025-06-07 19:34:20 - INFO - Processing batch 111/163\n",
      "2025-06-07 19:34:22 - INFO - Batch 111/163 - Loss: 0.5413 - Avg batch time: 1.39s\n",
      "2025-06-07 19:34:34 - INFO - Processing batch 121/163\n",
      "2025-06-07 19:34:36 - INFO - Batch 121/163 - Loss: 0.5142 - Avg batch time: 1.39s\n",
      "2025-06-07 19:34:48 - INFO - Processing batch 131/163\n",
      "2025-06-07 19:34:50 - INFO - Batch 131/163 - Loss: 0.4609 - Avg batch time: 1.39s\n",
      "2025-06-07 19:35:02 - INFO - Processing batch 141/163\n",
      "2025-06-07 19:35:03 - INFO - Batch 141/163 - Loss: 0.5326 - Avg batch time: 1.38s\n",
      "2025-06-07 19:35:16 - INFO - Processing batch 151/163\n",
      "2025-06-07 19:35:17 - INFO - Batch 151/163 - Loss: 0.5631 - Avg batch time: 1.39s\n",
      "2025-06-07 19:35:30 - INFO - Processing batch 161/163\n",
      "2025-06-07 19:35:31 - INFO - Batch 161/163 - Loss: 0.3724 - Avg batch time: 1.37s\n",
      "2025-06-07 19:35:33 - INFO - \n",
      "Epoch 9 training completed in 227.44s\n",
      "2025-06-07 19:35:33 - INFO - Average training loss: 0.5286\n",
      "Epochs:  10%| | 10/100 [41:03<6:50:17, 273.52s/it, train_loss=0.5286, val_loss=0.4167, best_val_f1=0.5695, lr=1.00e-04, 2025-06-07 19:36:19 - INFO - \n",
      "Epoch 10/100 - Training phase\n",
      "2025-06-07 19:36:22 - INFO - Processing batch 1/163\n",
      "2025-06-07 19:36:22 - INFO - Batch shapes - x: torch.Size([1216, 3000]), edge_index: torch.Size([2, 21888]), y: torch.Size([64, 1])\n",
      "2025-06-07 19:36:23 - INFO - Batch 1/163 - Loss: 0.4638 - Avg batch time: 1.41s\n",
      "2025-06-07 19:36:36 - INFO - Processing batch 11/163\n",
      "2025-06-07 19:36:37 - INFO - Batch 11/163 - Loss: 0.4396 - Avg batch time: 1.39s\n",
      "2025-06-07 19:36:50 - INFO - Processing batch 21/163\n",
      "2025-06-07 19:36:51 - INFO - Batch 21/163 - Loss: 0.6483 - Avg batch time: 1.38s\n",
      "2025-06-07 19:37:03 - INFO - Processing batch 31/163\n",
      "2025-06-07 19:37:05 - INFO - Batch 31/163 - Loss: 0.4841 - Avg batch time: 1.38s\n",
      "2025-06-07 19:37:17 - INFO - Processing batch 41/163\n",
      "2025-06-07 19:37:19 - INFO - Batch 41/163 - Loss: 0.5526 - Avg batch time: 1.38s\n",
      "2025-06-07 19:37:31 - INFO - Processing batch 51/163\n",
      "2025-06-07 19:37:32 - INFO - Batch 51/163 - Loss: 0.3973 - Avg batch time: 1.38s\n",
      "2025-06-07 19:37:45 - INFO - Processing batch 61/163\n",
      "2025-06-07 19:37:46 - INFO - Batch 61/163 - Loss: 0.4391 - Avg batch time: 1.38s\n",
      "2025-06-07 19:37:59 - INFO - Processing batch 71/163\n",
      "2025-06-07 19:38:00 - INFO - Batch 71/163 - Loss: 0.5412 - Avg batch time: 1.39s\n",
      "2025-06-07 19:38:13 - INFO - Processing batch 81/163\n",
      "2025-06-07 19:38:14 - INFO - Batch 81/163 - Loss: 0.4798 - Avg batch time: 1.38s\n",
      "2025-06-07 19:38:27 - INFO - Processing batch 91/163\n",
      "2025-06-07 19:38:28 - INFO - Batch 91/163 - Loss: 0.4834 - Avg batch time: 1.39s\n",
      "2025-06-07 19:38:40 - INFO - Processing batch 101/163\n",
      "2025-06-07 19:38:42 - INFO - Batch 101/163 - Loss: 0.5182 - Avg batch time: 1.39s\n",
      "2025-06-07 19:38:54 - INFO - Processing batch 111/163\n",
      "2025-06-07 19:38:56 - INFO - Batch 111/163 - Loss: 0.5030 - Avg batch time: 1.39s\n",
      "2025-06-07 19:39:08 - INFO - Processing batch 121/163\n",
      "2025-06-07 19:39:10 - INFO - Batch 121/163 - Loss: 0.4663 - Avg batch time: 1.39s\n",
      "2025-06-07 19:39:22 - INFO - Processing batch 131/163\n",
      "2025-06-07 19:39:23 - INFO - Batch 131/163 - Loss: 0.5481 - Avg batch time: 1.38s\n",
      "2025-06-07 19:39:36 - INFO - Processing batch 141/163\n",
      "2025-06-07 19:39:37 - INFO - Batch 141/163 - Loss: 0.5385 - Avg batch time: 1.39s\n",
      "2025-06-07 19:39:50 - INFO - Processing batch 151/163\n",
      "2025-06-07 19:39:51 - INFO - Batch 151/163 - Loss: 0.4879 - Avg batch time: 1.39s\n",
      "2025-06-07 19:40:04 - INFO - Processing batch 161/163\n",
      "2025-06-07 19:40:05 - INFO - Batch 161/163 - Loss: 0.5379 - Avg batch time: 1.38s\n",
      "2025-06-07 19:40:07 - INFO - \n",
      "Epoch 10 training completed in 227.72s\n",
      "2025-06-07 19:40:07 - INFO - Average training loss: 0.5065\n",
      "Epochs:  11%| | 11/100 [45:36<6:45:44, 273.53s/it, train_loss=0.5065, val_loss=0.3864, best_val_f1=0.5695, lr=1.00e-04, 2025-06-07 19:40:53 - INFO - \n",
      "Epoch 11/100 - Training phase\n",
      "2025-06-07 19:40:55 - INFO - Processing batch 1/163\n",
      "2025-06-07 19:40:55 - INFO - Batch shapes - x: torch.Size([1216, 3000]), edge_index: torch.Size([2, 21888]), y: torch.Size([64, 1])\n",
      "2025-06-07 19:40:56 - INFO - Batch 1/163 - Loss: 0.5210 - Avg batch time: 1.42s\n",
      "2025-06-07 19:41:09 - INFO - Processing batch 11/163\n",
      "2025-06-07 19:41:10 - INFO - Batch 11/163 - Loss: 0.5921 - Avg batch time: 1.39s\n",
      "2025-06-07 19:41:23 - INFO - Processing batch 21/163\n",
      "2025-06-07 19:41:24 - INFO - Batch 21/163 - Loss: 0.4863 - Avg batch time: 1.39s\n",
      "2025-06-07 19:41:37 - INFO - Processing batch 31/163\n",
      "2025-06-07 19:41:38 - INFO - Batch 31/163 - Loss: 0.7008 - Avg batch time: 1.38s\n",
      "2025-06-07 19:41:51 - INFO - Processing batch 41/163\n",
      "2025-06-07 19:41:52 - INFO - Batch 41/163 - Loss: 0.5320 - Avg batch time: 1.39s\n",
      "2025-06-07 19:42:04 - INFO - Processing batch 51/163\n",
      "2025-06-07 19:42:06 - INFO - Batch 51/163 - Loss: 0.3898 - Avg batch time: 1.39s\n",
      "2025-06-07 19:42:18 - INFO - Processing batch 61/163\n",
      "2025-06-07 19:42:20 - INFO - Batch 61/163 - Loss: 0.4934 - Avg batch time: 1.38s\n",
      "2025-06-07 19:42:32 - INFO - Processing batch 71/163\n",
      "2025-06-07 19:42:33 - INFO - Batch 71/163 - Loss: 0.5919 - Avg batch time: 1.38s\n",
      "2025-06-07 19:42:46 - INFO - Processing batch 81/163\n",
      "2025-06-07 19:42:47 - INFO - Batch 81/163 - Loss: 0.4224 - Avg batch time: 1.39s\n",
      "2025-06-07 19:43:00 - INFO - Processing batch 91/163\n",
      "2025-06-07 19:43:01 - INFO - Batch 91/163 - Loss: 0.4036 - Avg batch time: 1.39s\n",
      "2025-06-07 19:43:14 - INFO - Processing batch 101/163\n",
      "2025-06-07 19:43:15 - INFO - Batch 101/163 - Loss: 0.4712 - Avg batch time: 1.39s\n",
      "2025-06-07 19:43:28 - INFO - Processing batch 111/163\n",
      "2025-06-07 19:43:29 - INFO - Batch 111/163 - Loss: 0.5198 - Avg batch time: 1.38s\n",
      "2025-06-07 19:43:41 - INFO - Processing batch 121/163\n",
      "2025-06-07 19:43:43 - INFO - Batch 121/163 - Loss: 0.4826 - Avg batch time: 1.39s\n",
      "2025-06-07 19:43:55 - INFO - Processing batch 131/163\n",
      "2025-06-07 19:43:57 - INFO - Batch 131/163 - Loss: 0.4654 - Avg batch time: 1.39s\n",
      "2025-06-07 19:44:09 - INFO - Processing batch 141/163\n",
      "2025-06-07 19:44:11 - INFO - Batch 141/163 - Loss: 0.5045 - Avg batch time: 1.39s\n",
      "2025-06-07 19:44:23 - INFO - Processing batch 151/163\n",
      "2025-06-07 19:44:24 - INFO - Batch 151/163 - Loss: 0.4444 - Avg batch time: 1.39s\n",
      "2025-06-07 19:44:37 - INFO - Processing batch 161/163\n",
      "2025-06-07 19:44:38 - INFO - Batch 161/163 - Loss: 0.6318 - Avg batch time: 1.38s\n",
      "2025-06-07 19:44:40 - INFO - \n",
      "Epoch 11 training completed in 227.47s\n",
      "2025-06-07 19:44:40 - INFO - Average training loss: 0.5158\n",
      "Epochs:  12%| | 12/100 [50:10<6:41:03, 273.45s/it, train_loss=0.5158, val_loss=0.5175, best_val_f1=0.5695, lr=5.00e-05, 2025-06-07 19:45:26 - INFO - \n",
      "Epoch 12/100 - Training phase\n",
      "2025-06-07 19:45:28 - INFO - Processing batch 1/163\n",
      "2025-06-07 19:45:28 - INFO - Batch shapes - x: torch.Size([1216, 3000]), edge_index: torch.Size([2, 21888]), y: torch.Size([64, 1])\n",
      "2025-06-07 19:45:30 - INFO - Batch 1/163 - Loss: 0.5709 - Avg batch time: 1.39s\n",
      "2025-06-07 19:45:42 - INFO - Processing batch 11/163\n",
      "2025-06-07 19:45:43 - INFO - Batch 11/163 - Loss: 0.4491 - Avg batch time: 1.39s\n",
      "2025-06-07 19:45:56 - INFO - Processing batch 21/163\n",
      "2025-06-07 19:45:57 - INFO - Batch 21/163 - Loss: 0.5612 - Avg batch time: 1.38s\n",
      "2025-06-07 19:46:10 - INFO - Processing batch 31/163\n",
      "2025-06-07 19:46:11 - INFO - Batch 31/163 - Loss: 0.4959 - Avg batch time: 1.38s\n",
      "2025-06-07 19:46:24 - INFO - Processing batch 41/163\n",
      "2025-06-07 19:46:25 - INFO - Batch 41/163 - Loss: 0.5336 - Avg batch time: 1.39s\n",
      "2025-06-07 19:46:37 - INFO - Processing batch 51/163\n",
      "2025-06-07 19:46:39 - INFO - Batch 51/163 - Loss: 0.4441 - Avg batch time: 1.39s\n",
      "2025-06-07 19:46:51 - INFO - Processing batch 61/163\n",
      "2025-06-07 19:46:53 - INFO - Batch 61/163 - Loss: 0.5050 - Avg batch time: 1.39s\n",
      "2025-06-07 19:47:05 - INFO - Processing batch 71/163\n",
      "2025-06-07 19:47:07 - INFO - Batch 71/163 - Loss: 0.4966 - Avg batch time: 1.39s\n",
      "2025-06-07 19:47:19 - INFO - Processing batch 81/163\n",
      "2025-06-07 19:47:20 - INFO - Batch 81/163 - Loss: 0.4571 - Avg batch time: 1.39s\n",
      "2025-06-07 19:47:33 - INFO - Processing batch 91/163\n",
      "2025-06-07 19:47:34 - INFO - Batch 91/163 - Loss: 0.6085 - Avg batch time: 1.39s\n",
      "2025-06-07 19:47:47 - INFO - Processing batch 101/163\n",
      "2025-06-07 19:47:48 - INFO - Batch 101/163 - Loss: 0.4898 - Avg batch time: 1.38s\n",
      "2025-06-07 19:48:01 - INFO - Processing batch 111/163\n",
      "2025-06-07 19:48:02 - INFO - Batch 111/163 - Loss: 0.5020 - Avg batch time: 1.39s\n",
      "2025-06-07 19:48:15 - INFO - Processing batch 121/163\n",
      "2025-06-07 19:48:16 - INFO - Batch 121/163 - Loss: 0.4788 - Avg batch time: 1.39s\n",
      "2025-06-07 19:48:28 - INFO - Processing batch 131/163\n",
      "2025-06-07 19:48:30 - INFO - Batch 131/163 - Loss: 0.3844 - Avg batch time: 1.39s\n",
      "2025-06-07 19:48:42 - INFO - Processing batch 141/163\n",
      "2025-06-07 19:48:44 - INFO - Batch 141/163 - Loss: 0.5898 - Avg batch time: 1.39s\n",
      "2025-06-07 19:48:56 - INFO - Processing batch 151/163\n",
      "2025-06-07 19:48:58 - INFO - Batch 151/163 - Loss: 0.5153 - Avg batch time: 1.39s\n",
      "2025-06-07 19:49:10 - INFO - Processing batch 161/163\n",
      "2025-06-07 19:49:11 - INFO - Batch 161/163 - Loss: 0.4376 - Avg batch time: 1.38s\n",
      "2025-06-07 19:49:13 - INFO - \n",
      "Epoch 12 training completed in 227.30s\n",
      "2025-06-07 19:49:13 - INFO - Average training loss: 0.5035\n",
      "Epochs:  13%|| 13/100 [54:43<6:36:23, 273.37s/it, train_loss=0.5035, val_loss=0.3785, best_val_f1=0.5940, lr=5.00e-05, 2025-06-07 19:49:59 - INFO - \n",
      "Epoch 13/100 - Training phase\n",
      "2025-06-07 19:50:01 - INFO - Processing batch 1/163\n",
      "2025-06-07 19:50:01 - INFO - Batch shapes - x: torch.Size([1216, 3000]), edge_index: torch.Size([2, 21888]), y: torch.Size([64, 1])\n",
      "2025-06-07 19:50:03 - INFO - Batch 1/163 - Loss: 0.4632 - Avg batch time: 1.41s\n",
      "2025-06-07 19:50:15 - INFO - Processing batch 11/163\n",
      "2025-06-07 19:50:17 - INFO - Batch 11/163 - Loss: 0.4946 - Avg batch time: 1.39s\n",
      "2025-06-07 19:50:29 - INFO - Processing batch 21/163\n",
      "2025-06-07 19:50:31 - INFO - Batch 21/163 - Loss: 0.5145 - Avg batch time: 1.39s\n",
      "2025-06-07 19:50:43 - INFO - Processing batch 31/163\n",
      "2025-06-07 19:50:45 - INFO - Batch 31/163 - Loss: 0.7025 - Avg batch time: 1.38s\n",
      "2025-06-07 19:50:57 - INFO - Processing batch 41/163\n",
      "2025-06-07 19:50:58 - INFO - Batch 41/163 - Loss: 0.4711 - Avg batch time: 1.38s\n",
      "2025-06-07 19:51:11 - INFO - Processing batch 51/163\n",
      "2025-06-07 19:51:12 - INFO - Batch 51/163 - Loss: 0.5271 - Avg batch time: 1.39s\n",
      "2025-06-07 19:51:25 - INFO - Processing batch 61/163\n",
      "2025-06-07 19:51:26 - INFO - Batch 61/163 - Loss: 0.5120 - Avg batch time: 1.38s\n",
      "2025-06-07 19:51:39 - INFO - Processing batch 71/163\n",
      "2025-06-07 19:51:40 - INFO - Batch 71/163 - Loss: 0.4380 - Avg batch time: 1.39s\n",
      "2025-06-07 19:51:52 - INFO - Processing batch 81/163\n",
      "2025-06-07 19:51:54 - INFO - Batch 81/163 - Loss: 0.3694 - Avg batch time: 1.39s\n",
      "2025-06-07 19:52:06 - INFO - Processing batch 91/163\n",
      "2025-06-07 19:52:08 - INFO - Batch 91/163 - Loss: 0.4569 - Avg batch time: 1.38s\n",
      "2025-06-07 19:52:20 - INFO - Processing batch 101/163\n",
      "2025-06-07 19:52:22 - INFO - Batch 101/163 - Loss: 0.5347 - Avg batch time: 1.39s\n",
      "2025-06-07 19:52:34 - INFO - Processing batch 111/163\n",
      "2025-06-07 19:52:35 - INFO - Batch 111/163 - Loss: 0.4381 - Avg batch time: 1.39s\n",
      "2025-06-07 19:52:48 - INFO - Processing batch 121/163\n",
      "2025-06-07 19:52:49 - INFO - Batch 121/163 - Loss: 0.4086 - Avg batch time: 1.38s\n",
      "2025-06-07 19:53:02 - INFO - Processing batch 131/163\n",
      "2025-06-07 19:53:03 - INFO - Batch 131/163 - Loss: 0.4908 - Avg batch time: 1.39s\n",
      "2025-06-07 19:53:16 - INFO - Processing batch 141/163\n",
      "2025-06-07 19:53:17 - INFO - Batch 141/163 - Loss: 0.5564 - Avg batch time: 1.39s\n",
      "2025-06-07 19:53:29 - INFO - Processing batch 151/163\n",
      "2025-06-07 19:53:31 - INFO - Batch 151/163 - Loss: 0.4375 - Avg batch time: 1.39s\n",
      "2025-06-07 19:53:43 - INFO - Processing batch 161/163\n",
      "2025-06-07 19:53:45 - INFO - Batch 161/163 - Loss: 0.4226 - Avg batch time: 1.38s\n",
      "2025-06-07 19:53:47 - INFO - \n",
      "Epoch 13 training completed in 227.48s\n",
      "2025-06-07 19:53:47 - INFO - Average training loss: 0.4842\n",
      "Epochs:  14%|| 14/100 [59:16<6:31:50, 273.38s/it, train_loss=0.4842, val_loss=0.3838, best_val_f1=0.5981, lr=5.00e-05, 2025-06-07 19:54:33 - INFO - \n",
      "Epoch 14/100 - Training phase\n",
      "2025-06-07 19:54:35 - INFO - Processing batch 1/163\n",
      "2025-06-07 19:54:35 - INFO - Batch shapes - x: torch.Size([1216, 3000]), edge_index: torch.Size([2, 21888]), y: torch.Size([64, 1])\n",
      "2025-06-07 19:54:36 - INFO - Batch 1/163 - Loss: 0.4640 - Avg batch time: 1.43s\n",
      "2025-06-07 19:54:49 - INFO - Processing batch 11/163\n",
      "2025-06-07 19:54:50 - INFO - Batch 11/163 - Loss: 0.5353 - Avg batch time: 1.38s\n",
      "2025-06-07 19:55:03 - INFO - Processing batch 21/163\n",
      "2025-06-07 19:55:04 - INFO - Batch 21/163 - Loss: 0.4246 - Avg batch time: 1.38s\n",
      "2025-06-07 19:55:17 - INFO - Processing batch 31/163\n",
      "2025-06-07 19:55:18 - INFO - Batch 31/163 - Loss: 0.4239 - Avg batch time: 1.39s\n",
      "2025-06-07 19:55:30 - INFO - Processing batch 41/163\n",
      "2025-06-07 19:55:32 - INFO - Batch 41/163 - Loss: 0.4203 - Avg batch time: 1.38s\n",
      "2025-06-07 19:55:44 - INFO - Processing batch 51/163\n",
      "2025-06-07 19:55:46 - INFO - Batch 51/163 - Loss: 0.4391 - Avg batch time: 1.38s\n",
      "2025-06-07 19:55:58 - INFO - Processing batch 61/163\n",
      "2025-06-07 19:55:59 - INFO - Batch 61/163 - Loss: 0.4476 - Avg batch time: 1.39s\n",
      "2025-06-07 19:56:12 - INFO - Processing batch 71/163\n",
      "2025-06-07 19:56:13 - INFO - Batch 71/163 - Loss: 0.4425 - Avg batch time: 1.38s\n",
      "2025-06-07 19:56:26 - INFO - Processing batch 81/163\n",
      "2025-06-07 19:56:27 - INFO - Batch 81/163 - Loss: 0.4440 - Avg batch time: 1.38s\n",
      "2025-06-07 19:56:40 - INFO - Processing batch 91/163\n",
      "2025-06-07 19:56:41 - INFO - Batch 91/163 - Loss: 0.3502 - Avg batch time: 1.39s\n",
      "2025-06-07 19:56:53 - INFO - Processing batch 101/163\n",
      "2025-06-07 19:56:55 - INFO - Batch 101/163 - Loss: 0.4731 - Avg batch time: 1.39s\n",
      "2025-06-07 19:57:07 - INFO - Processing batch 111/163\n",
      "2025-06-07 19:57:09 - INFO - Batch 111/163 - Loss: 0.5211 - Avg batch time: 1.39s\n",
      "2025-06-07 19:57:21 - INFO - Processing batch 121/163\n",
      "2025-06-07 19:57:23 - INFO - Batch 121/163 - Loss: 0.3995 - Avg batch time: 1.39s\n",
      "2025-06-07 19:57:35 - INFO - Processing batch 131/163\n",
      "2025-06-07 19:57:37 - INFO - Batch 131/163 - Loss: 0.3748 - Avg batch time: 1.39s\n",
      "2025-06-07 19:57:49 - INFO - Processing batch 141/163\n",
      "2025-06-07 19:57:50 - INFO - Batch 141/163 - Loss: 0.5193 - Avg batch time: 1.38s\n",
      "2025-06-07 19:58:03 - INFO - Processing batch 151/163\n",
      "2025-06-07 19:58:04 - INFO - Batch 151/163 - Loss: 0.4345 - Avg batch time: 1.39s\n",
      "2025-06-07 19:58:17 - INFO - Processing batch 161/163\n",
      "2025-06-07 19:58:18 - INFO - Batch 161/163 - Loss: 0.4614 - Avg batch time: 1.38s\n",
      "2025-06-07 19:58:20 - INFO - \n",
      "Epoch 14 training completed in 227.41s\n",
      "2025-06-07 19:58:20 - INFO - Average training loss: 0.4644\n",
      "Epochs:  15%|| 15/100 [1:03:50<6:27:17, 273.38s/it, train_loss=0.4644, val_loss=0.3493, best_val_f1=0.6106, lr=5.00e-052025-06-07 19:59:06 - INFO - \n",
      "Epoch 15/100 - Training phase\n",
      "2025-06-07 19:59:08 - INFO - Processing batch 1/163\n",
      "2025-06-07 19:59:08 - INFO - Batch shapes - x: torch.Size([1216, 3000]), edge_index: torch.Size([2, 21888]), y: torch.Size([64, 1])\n",
      "2025-06-07 19:59:10 - INFO - Batch 1/163 - Loss: 0.4838 - Avg batch time: 1.40s\n",
      "2025-06-07 19:59:22 - INFO - Processing batch 11/163\n",
      "2025-06-07 19:59:24 - INFO - Batch 11/163 - Loss: 0.4336 - Avg batch time: 1.39s\n",
      "2025-06-07 19:59:36 - INFO - Processing batch 21/163\n",
      "2025-06-07 19:59:38 - INFO - Batch 21/163 - Loss: 0.5153 - Avg batch time: 1.38s\n",
      "2025-06-07 19:59:50 - INFO - Processing batch 31/163\n",
      "2025-06-07 19:59:51 - INFO - Batch 31/163 - Loss: 0.6611 - Avg batch time: 1.38s\n",
      "2025-06-07 20:00:04 - INFO - Processing batch 41/163\n",
      "2025-06-07 20:00:05 - INFO - Batch 41/163 - Loss: 0.3178 - Avg batch time: 1.38s\n",
      "2025-06-07 20:00:18 - INFO - Processing batch 51/163\n",
      "2025-06-07 20:00:19 - INFO - Batch 51/163 - Loss: 0.5275 - Avg batch time: 1.39s\n",
      "2025-06-07 20:00:32 - INFO - Processing batch 61/163\n",
      "2025-06-07 20:00:33 - INFO - Batch 61/163 - Loss: 0.4292 - Avg batch time: 1.39s\n",
      "2025-06-07 20:00:45 - INFO - Processing batch 71/163\n",
      "2025-06-07 20:00:47 - INFO - Batch 71/163 - Loss: 0.4490 - Avg batch time: 1.39s\n",
      "2025-06-07 20:00:59 - INFO - Processing batch 81/163\n",
      "2025-06-07 20:01:01 - INFO - Batch 81/163 - Loss: 0.4852 - Avg batch time: 1.39s\n",
      "2025-06-07 20:01:13 - INFO - Processing batch 91/163\n",
      "2025-06-07 20:01:15 - INFO - Batch 91/163 - Loss: 0.5774 - Avg batch time: 1.39s\n",
      "2025-06-07 20:01:27 - INFO - Processing batch 101/163\n",
      "2025-06-07 20:01:28 - INFO - Batch 101/163 - Loss: 0.4735 - Avg batch time: 1.38s\n",
      "2025-06-07 20:01:41 - INFO - Processing batch 111/163\n",
      "2025-06-07 20:01:42 - INFO - Batch 111/163 - Loss: 0.4806 - Avg batch time: 1.39s\n",
      "2025-06-07 20:01:55 - INFO - Processing batch 121/163\n",
      "2025-06-07 20:01:56 - INFO - Batch 121/163 - Loss: 0.5322 - Avg batch time: 1.39s\n",
      "2025-06-07 20:02:09 - INFO - Processing batch 131/163\n",
      "2025-06-07 20:02:10 - INFO - Batch 131/163 - Loss: 0.4444 - Avg batch time: 1.39s\n",
      "2025-06-07 20:02:23 - INFO - Processing batch 141/163\n",
      "2025-06-07 20:02:24 - INFO - Batch 141/163 - Loss: 0.6015 - Avg batch time: 1.39s\n",
      "2025-06-07 20:02:36 - INFO - Processing batch 151/163\n",
      "2025-06-07 20:02:38 - INFO - Batch 151/163 - Loss: 0.5444 - Avg batch time: 1.39s\n",
      "2025-06-07 20:02:50 - INFO - Processing batch 161/163\n",
      "2025-06-07 20:02:52 - INFO - Batch 161/163 - Loss: 0.3874 - Avg batch time: 1.38s\n",
      "2025-06-07 20:02:54 - INFO - \n",
      "Epoch 15 training completed in 227.61s\n",
      "2025-06-07 20:02:54 - INFO - Average training loss: 0.4887\n",
      "Epochs:  16%|| 16/100 [1:08:23<6:22:46, 273.41s/it, train_loss=0.4887, val_loss=0.3737, best_val_f1=0.6106, lr=5.00e-052025-06-07 20:03:39 - INFO - \n",
      "Epoch 16/100 - Training phase\n",
      "2025-06-07 20:03:42 - INFO - Processing batch 1/163\n",
      "2025-06-07 20:03:42 - INFO - Batch shapes - x: torch.Size([1216, 3000]), edge_index: torch.Size([2, 21888]), y: torch.Size([64, 1])\n",
      "2025-06-07 20:03:43 - INFO - Batch 1/163 - Loss: 0.5745 - Avg batch time: 1.42s\n",
      "2025-06-07 20:03:56 - INFO - Processing batch 11/163\n",
      "2025-06-07 20:03:57 - INFO - Batch 11/163 - Loss: 0.4073 - Avg batch time: 1.39s\n",
      "2025-06-07 20:04:09 - INFO - Processing batch 21/163\n",
      "2025-06-07 20:04:11 - INFO - Batch 21/163 - Loss: 0.4279 - Avg batch time: 1.39s\n",
      "2025-06-07 20:04:23 - INFO - Processing batch 31/163\n",
      "2025-06-07 20:04:25 - INFO - Batch 31/163 - Loss: 0.4761 - Avg batch time: 1.38s\n",
      "2025-06-07 20:04:37 - INFO - Processing batch 41/163\n",
      "2025-06-07 20:04:39 - INFO - Batch 41/163 - Loss: 0.4059 - Avg batch time: 1.39s\n",
      "2025-06-07 20:04:51 - INFO - Processing batch 51/163\n",
      "2025-06-07 20:04:52 - INFO - Batch 51/163 - Loss: 0.4354 - Avg batch time: 1.39s\n",
      "2025-06-07 20:05:05 - INFO - Processing batch 61/163\n",
      "2025-06-07 20:05:06 - INFO - Batch 61/163 - Loss: 0.4517 - Avg batch time: 1.39s\n",
      "2025-06-07 20:05:19 - INFO - Processing batch 71/163\n",
      "2025-06-07 20:05:20 - INFO - Batch 71/163 - Loss: 0.3302 - Avg batch time: 1.38s\n",
      "2025-06-07 20:05:33 - INFO - Processing batch 81/163\n",
      "2025-06-07 20:05:34 - INFO - Batch 81/163 - Loss: 0.4885 - Avg batch time: 1.38s\n",
      "2025-06-07 20:05:46 - INFO - Processing batch 91/163\n",
      "2025-06-07 20:05:48 - INFO - Batch 91/163 - Loss: 0.4137 - Avg batch time: 1.39s\n",
      "2025-06-07 20:06:00 - INFO - Processing batch 101/163\n",
      "2025-06-07 20:06:02 - INFO - Batch 101/163 - Loss: 0.4185 - Avg batch time: 1.38s\n",
      "2025-06-07 20:06:14 - INFO - Processing batch 111/163\n",
      "2025-06-07 20:06:16 - INFO - Batch 111/163 - Loss: 0.4129 - Avg batch time: 1.39s\n",
      "2025-06-07 20:06:28 - INFO - Processing batch 121/163\n",
      "2025-06-07 20:06:29 - INFO - Batch 121/163 - Loss: 0.3576 - Avg batch time: 1.38s\n",
      "2025-06-07 20:06:42 - INFO - Processing batch 131/163\n",
      "2025-06-07 20:06:43 - INFO - Batch 131/163 - Loss: 0.5566 - Avg batch time: 1.39s\n",
      "2025-06-07 20:06:56 - INFO - Processing batch 141/163\n",
      "2025-06-07 20:06:57 - INFO - Batch 141/163 - Loss: 0.6142 - Avg batch time: 1.39s\n",
      "2025-06-07 20:07:10 - INFO - Processing batch 151/163\n",
      "2025-06-07 20:07:11 - INFO - Batch 151/163 - Loss: 0.4826 - Avg batch time: 1.39s\n",
      "2025-06-07 20:07:23 - INFO - Processing batch 161/163\n",
      "2025-06-07 20:07:25 - INFO - Batch 161/163 - Loss: 0.4904 - Avg batch time: 1.38s\n",
      "2025-06-07 20:07:27 - INFO - \n",
      "Epoch 16 training completed in 227.37s\n",
      "2025-06-07 20:07:27 - INFO - Average training loss: 0.4775\n",
      "Epochs:  17%|| 17/100 [1:12:57<6:18:12, 273.41s/it, train_loss=0.4775, val_loss=0.3565, best_val_f1=0.6106, lr=5.00e-052025-06-07 20:08:13 - INFO - \n",
      "Epoch 17/100 - Training phase\n",
      "2025-06-07 20:08:15 - INFO - Processing batch 1/163\n",
      "2025-06-07 20:08:15 - INFO - Batch shapes - x: torch.Size([1216, 3000]), edge_index: torch.Size([2, 21888]), y: torch.Size([64, 1])\n",
      "2025-06-07 20:08:17 - INFO - Batch 1/163 - Loss: 0.4250 - Avg batch time: 1.39s\n",
      "2025-06-07 20:08:29 - INFO - Processing batch 11/163\n",
      "2025-06-07 20:08:31 - INFO - Batch 11/163 - Loss: 0.3864 - Avg batch time: 1.39s\n",
      "2025-06-07 20:08:43 - INFO - Processing batch 21/163\n",
      "2025-06-07 20:08:44 - INFO - Batch 21/163 - Loss: 0.5374 - Avg batch time: 1.38s\n",
      "2025-06-07 20:08:57 - INFO - Processing batch 31/163\n",
      "2025-06-07 20:08:58 - INFO - Batch 31/163 - Loss: 0.4111 - Avg batch time: 1.38s\n",
      "2025-06-07 20:09:11 - INFO - Processing batch 41/163\n",
      "2025-06-07 20:09:12 - INFO - Batch 41/163 - Loss: 0.5422 - Avg batch time: 1.38s\n",
      "2025-06-07 20:09:25 - INFO - Processing batch 51/163\n",
      "2025-06-07 20:09:26 - INFO - Batch 51/163 - Loss: 0.4397 - Avg batch time: 1.39s\n",
      "2025-06-07 20:09:38 - INFO - Processing batch 61/163\n",
      "2025-06-07 20:09:40 - INFO - Batch 61/163 - Loss: 0.4390 - Avg batch time: 1.39s\n",
      "2025-06-07 20:09:52 - INFO - Processing batch 71/163\n",
      "2025-06-07 20:09:54 - INFO - Batch 71/163 - Loss: 0.3623 - Avg batch time: 1.39s\n",
      "2025-06-07 20:10:06 - INFO - Processing batch 81/163\n",
      "2025-06-07 20:10:08 - INFO - Batch 81/163 - Loss: 0.4420 - Avg batch time: 1.39s\n",
      "2025-06-07 20:10:20 - INFO - Processing batch 91/163\n",
      "2025-06-07 20:10:21 - INFO - Batch 91/163 - Loss: 0.4719 - Avg batch time: 1.38s\n",
      "2025-06-07 20:10:34 - INFO - Processing batch 101/163\n",
      "2025-06-07 20:10:35 - INFO - Batch 101/163 - Loss: 0.5455 - Avg batch time: 1.39s\n",
      "2025-06-07 20:10:48 - INFO - Processing batch 111/163\n",
      "2025-06-07 20:10:49 - INFO - Batch 111/163 - Loss: 0.4409 - Avg batch time: 1.39s\n",
      "2025-06-07 20:11:02 - INFO - Processing batch 121/163\n",
      "2025-06-07 20:11:03 - INFO - Batch 121/163 - Loss: 0.4641 - Avg batch time: 1.39s\n",
      "2025-06-07 20:11:16 - INFO - Processing batch 131/163\n",
      "2025-06-07 20:11:17 - INFO - Batch 131/163 - Loss: 0.4280 - Avg batch time: 1.39s\n",
      "2025-06-07 20:11:29 - INFO - Processing batch 141/163\n",
      "2025-06-07 20:11:31 - INFO - Batch 141/163 - Loss: 0.5665 - Avg batch time: 1.39s\n",
      "2025-06-07 20:11:43 - INFO - Processing batch 151/163\n",
      "2025-06-07 20:11:45 - INFO - Batch 151/163 - Loss: 0.3879 - Avg batch time: 1.39s\n",
      "2025-06-07 20:11:57 - INFO - Processing batch 161/163\n",
      "2025-06-07 20:11:58 - INFO - Batch 161/163 - Loss: 0.5566 - Avg batch time: 1.38s\n",
      "2025-06-07 20:12:00 - INFO - \n",
      "Epoch 17 training completed in 227.59s\n",
      "2025-06-07 20:12:00 - INFO - Average training loss: 0.4635\n",
      "Epochs:  18%|| 18/100 [1:17:30<6:13:42, 273.44s/it, train_loss=0.4635, val_loss=0.3704, best_val_f1=0.6106, lr=2.50e-052025-06-07 20:12:46 - INFO - \n",
      "Epoch 18/100 - Training phase\n",
      "2025-06-07 20:12:49 - INFO - Processing batch 1/163\n",
      "2025-06-07 20:12:49 - INFO - Batch shapes - x: torch.Size([1216, 3000]), edge_index: torch.Size([2, 21888]), y: torch.Size([64, 1])\n",
      "2025-06-07 20:12:50 - INFO - Batch 1/163 - Loss: 0.4651 - Avg batch time: 1.40s\n",
      "2025-06-07 20:13:03 - INFO - Processing batch 11/163\n",
      "2025-06-07 20:13:04 - INFO - Batch 11/163 - Loss: 0.4788 - Avg batch time: 1.39s\n",
      "2025-06-07 20:13:17 - INFO - Processing batch 21/163\n",
      "2025-06-07 20:13:18 - INFO - Batch 21/163 - Loss: 0.5457 - Avg batch time: 1.38s\n",
      "2025-06-07 20:13:30 - INFO - Processing batch 31/163\n",
      "2025-06-07 20:13:32 - INFO - Batch 31/163 - Loss: 0.4191 - Avg batch time: 1.39s\n",
      "2025-06-07 20:13:44 - INFO - Processing batch 41/163\n",
      "2025-06-07 20:13:46 - INFO - Batch 41/163 - Loss: 0.3807 - Avg batch time: 1.39s\n",
      "2025-06-07 20:13:58 - INFO - Processing batch 51/163\n",
      "2025-06-07 20:14:00 - INFO - Batch 51/163 - Loss: 0.4671 - Avg batch time: 1.38s\n",
      "2025-06-07 20:14:12 - INFO - Processing batch 61/163\n",
      "2025-06-07 20:14:13 - INFO - Batch 61/163 - Loss: 0.4742 - Avg batch time: 1.39s\n",
      "2025-06-07 20:14:26 - INFO - Processing batch 71/163\n",
      "2025-06-07 20:14:27 - INFO - Batch 71/163 - Loss: 0.4574 - Avg batch time: 1.39s\n",
      "2025-06-07 20:14:40 - INFO - Processing batch 81/163\n",
      "2025-06-07 20:14:41 - INFO - Batch 81/163 - Loss: 0.5484 - Avg batch time: 1.39s\n",
      "2025-06-07 20:14:54 - INFO - Processing batch 91/163\n",
      "2025-06-07 20:14:55 - INFO - Batch 91/163 - Loss: 0.4520 - Avg batch time: 1.39s\n",
      "2025-06-07 20:15:08 - INFO - Processing batch 101/163\n",
      "2025-06-07 20:15:09 - INFO - Batch 101/163 - Loss: 0.4779 - Avg batch time: 1.38s\n",
      "2025-06-07 20:15:21 - INFO - Processing batch 111/163\n",
      "2025-06-07 20:15:23 - INFO - Batch 111/163 - Loss: 0.5054 - Avg batch time: 1.39s\n",
      "2025-06-07 20:15:35 - INFO - Processing batch 121/163\n",
      "2025-06-07 20:15:37 - INFO - Batch 121/163 - Loss: 0.4457 - Avg batch time: 1.38s\n",
      "2025-06-07 20:15:49 - INFO - Processing batch 131/163\n",
      "2025-06-07 20:15:51 - INFO - Batch 131/163 - Loss: 0.4422 - Avg batch time: 1.39s\n",
      "2025-06-07 20:16:03 - INFO - Processing batch 141/163\n",
      "2025-06-07 20:16:04 - INFO - Batch 141/163 - Loss: 0.3860 - Avg batch time: 1.39s\n",
      "2025-06-07 20:16:17 - INFO - Processing batch 151/163\n",
      "2025-06-07 20:16:18 - INFO - Batch 151/163 - Loss: 0.3071 - Avg batch time: 1.38s\n",
      "2025-06-07 20:16:31 - INFO - Processing batch 161/163\n",
      "2025-06-07 20:16:32 - INFO - Batch 161/163 - Loss: 0.3893 - Avg batch time: 1.38s\n",
      "2025-06-07 20:16:34 - INFO - \n",
      "Epoch 18 training completed in 227.66s\n",
      "2025-06-07 20:16:34 - INFO - Average training loss: 0.4501\n",
      "Epochs:  19%|| 19/100 [1:22:04<6:09:15, 273.53s/it, train_loss=0.4501, val_loss=0.3635, best_val_f1=0.6131, lr=2.50e-052025-06-07 20:17:20 - INFO - \n",
      "Epoch 19/100 - Training phase\n",
      "2025-06-07 20:17:23 - INFO - Processing batch 1/163\n",
      "2025-06-07 20:17:23 - INFO - Batch shapes - x: torch.Size([1216, 3000]), edge_index: torch.Size([2, 21888]), y: torch.Size([64, 1])\n",
      "2025-06-07 20:17:24 - INFO - Batch 1/163 - Loss: 0.3070 - Avg batch time: 1.40s\n",
      "2025-06-07 20:17:36 - INFO - Processing batch 11/163\n",
      "2025-06-07 20:17:38 - INFO - Batch 11/163 - Loss: 0.5058 - Avg batch time: 1.39s\n",
      "2025-06-07 20:17:50 - INFO - Processing batch 21/163\n",
      "2025-06-07 20:17:52 - INFO - Batch 21/163 - Loss: 0.4049 - Avg batch time: 1.39s\n",
      "2025-06-07 20:18:04 - INFO - Processing batch 31/163\n",
      "2025-06-07 20:18:06 - INFO - Batch 31/163 - Loss: 0.4292 - Avg batch time: 1.39s\n",
      "2025-06-07 20:18:18 - INFO - Processing batch 41/163\n",
      "2025-06-07 20:18:19 - INFO - Batch 41/163 - Loss: 0.3573 - Avg batch time: 1.38s\n",
      "2025-06-07 20:18:32 - INFO - Processing batch 51/163\n",
      "2025-06-07 20:18:33 - INFO - Batch 51/163 - Loss: 0.3485 - Avg batch time: 1.39s\n",
      "2025-06-07 20:18:46 - INFO - Processing batch 61/163\n",
      "2025-06-07 20:18:47 - INFO - Batch 61/163 - Loss: 0.3209 - Avg batch time: 1.39s\n",
      "2025-06-07 20:19:00 - INFO - Processing batch 71/163\n",
      "2025-06-07 20:19:01 - INFO - Batch 71/163 - Loss: 0.5571 - Avg batch time: 1.39s\n",
      "2025-06-07 20:19:14 - INFO - Processing batch 81/163\n",
      "2025-06-07 20:19:15 - INFO - Batch 81/163 - Loss: 0.4457 - Avg batch time: 1.39s\n",
      "2025-06-07 20:19:27 - INFO - Processing batch 91/163\n",
      "2025-06-07 20:19:29 - INFO - Batch 91/163 - Loss: 0.5145 - Avg batch time: 1.38s\n",
      "2025-06-07 20:19:41 - INFO - Processing batch 101/163\n",
      "2025-06-07 20:19:43 - INFO - Batch 101/163 - Loss: 0.3411 - Avg batch time: 1.39s\n",
      "2025-06-07 20:19:55 - INFO - Processing batch 111/163\n",
      "2025-06-07 20:19:57 - INFO - Batch 111/163 - Loss: 0.5116 - Avg batch time: 1.39s\n",
      "2025-06-07 20:20:09 - INFO - Processing batch 121/163\n",
      "2025-06-07 20:20:10 - INFO - Batch 121/163 - Loss: 0.4313 - Avg batch time: 1.38s\n",
      "2025-06-07 20:20:23 - INFO - Processing batch 131/163\n",
      "2025-06-07 20:20:24 - INFO - Batch 131/163 - Loss: 0.2848 - Avg batch time: 1.39s\n",
      "2025-06-07 20:20:37 - INFO - Processing batch 141/163\n",
      "2025-06-07 20:20:38 - INFO - Batch 141/163 - Loss: 0.4062 - Avg batch time: 1.38s\n",
      "2025-06-07 20:20:51 - INFO - Processing batch 151/163\n",
      "2025-06-07 20:20:52 - INFO - Batch 151/163 - Loss: 0.4604 - Avg batch time: 1.39s\n",
      "2025-06-07 20:21:04 - INFO - Processing batch 161/163\n",
      "2025-06-07 20:21:06 - INFO - Batch 161/163 - Loss: 0.5768 - Avg batch time: 1.37s\n",
      "2025-06-07 20:21:08 - INFO - \n",
      "Epoch 19 training completed in 227.58s\n",
      "2025-06-07 20:21:08 - INFO - Average training loss: 0.4379\n",
      "Epochs:  20%|| 20/100 [1:26:37<6:04:39, 273.49s/it, train_loss=0.4379, val_loss=0.3638, best_val_f1=0.6179, lr=2.50e-052025-06-07 20:21:53 - INFO - \n",
      "Epoch 20/100 - Training phase\n",
      "2025-06-07 20:21:56 - INFO - Processing batch 1/163\n",
      "2025-06-07 20:21:56 - INFO - Batch shapes - x: torch.Size([1216, 3000]), edge_index: torch.Size([2, 21888]), y: torch.Size([64, 1])\n",
      "2025-06-07 20:21:57 - INFO - Batch 1/163 - Loss: 0.3718 - Avg batch time: 1.42s\n",
      "2025-06-07 20:22:10 - INFO - Processing batch 11/163\n",
      "2025-06-07 20:22:11 - INFO - Batch 11/163 - Loss: 0.4809 - Avg batch time: 1.39s\n",
      "2025-06-07 20:22:24 - INFO - Processing batch 21/163\n",
      "2025-06-07 20:22:25 - INFO - Batch 21/163 - Loss: 0.5305 - Avg batch time: 1.39s\n",
      "2025-06-07 20:22:37 - INFO - Processing batch 31/163\n",
      "2025-06-07 20:22:39 - INFO - Batch 31/163 - Loss: 0.5270 - Avg batch time: 1.38s\n",
      "2025-06-07 20:22:51 - INFO - Processing batch 41/163\n",
      "2025-06-07 20:22:53 - INFO - Batch 41/163 - Loss: 0.4774 - Avg batch time: 1.38s\n",
      "2025-06-07 20:23:05 - INFO - Processing batch 51/163\n",
      "2025-06-07 20:23:06 - INFO - Batch 51/163 - Loss: 0.4433 - Avg batch time: 1.38s\n",
      "2025-06-07 20:23:19 - INFO - Processing batch 61/163\n",
      "2025-06-07 20:23:20 - INFO - Batch 61/163 - Loss: 0.4237 - Avg batch time: 1.38s\n",
      "2025-06-07 20:23:33 - INFO - Processing batch 71/163\n",
      "2025-06-07 20:23:34 - INFO - Batch 71/163 - Loss: 0.4994 - Avg batch time: 1.38s\n",
      "2025-06-07 20:23:47 - INFO - Processing batch 81/163\n",
      "2025-06-07 20:23:48 - INFO - Batch 81/163 - Loss: 0.4276 - Avg batch time: 1.38s\n",
      "2025-06-07 20:24:00 - INFO - Processing batch 91/163\n",
      "2025-06-07 20:24:02 - INFO - Batch 91/163 - Loss: 0.3785 - Avg batch time: 1.39s\n",
      "2025-06-07 20:24:14 - INFO - Processing batch 101/163\n",
      "2025-06-07 20:24:16 - INFO - Batch 101/163 - Loss: 0.4562 - Avg batch time: 1.39s\n",
      "2025-06-07 20:24:28 - INFO - Processing batch 111/163\n",
      "2025-06-07 20:24:30 - INFO - Batch 111/163 - Loss: 0.3815 - Avg batch time: 1.38s\n",
      "2025-06-07 20:24:42 - INFO - Processing batch 121/163\n",
      "2025-06-07 20:24:43 - INFO - Batch 121/163 - Loss: 0.3444 - Avg batch time: 1.39s\n",
      "2025-06-07 20:24:56 - INFO - Processing batch 131/163\n",
      "2025-06-07 20:24:57 - INFO - Batch 131/163 - Loss: 0.4367 - Avg batch time: 1.38s\n",
      "2025-06-07 20:25:10 - INFO - Processing batch 141/163\n",
      "2025-06-07 20:25:11 - INFO - Batch 141/163 - Loss: 0.3967 - Avg batch time: 1.38s\n",
      "2025-06-07 20:25:24 - INFO - Processing batch 151/163\n",
      "2025-06-07 20:25:25 - INFO - Batch 151/163 - Loss: 0.3997 - Avg batch time: 1.38s\n",
      "2025-06-07 20:25:37 - INFO - Processing batch 161/163\n",
      "2025-06-07 20:25:39 - INFO - Batch 161/163 - Loss: 0.3858 - Avg batch time: 1.38s\n",
      "2025-06-07 20:25:41 - INFO - \n",
      "Epoch 20 training completed in 227.19s\n",
      "2025-06-07 20:25:41 - INFO - Average training loss: 0.4494\n",
      "Epochs:  21%|| 21/100 [1:31:10<6:00:01, 273.43s/it, train_loss=0.4494, val_loss=0.3543, best_val_f1=0.6179, lr=2.50e-052025-06-07 20:26:27 - INFO - \n",
      "Epoch 21/100 - Training phase\n",
      "2025-06-07 20:26:29 - INFO - Processing batch 1/163\n",
      "2025-06-07 20:26:29 - INFO - Batch shapes - x: torch.Size([1216, 3000]), edge_index: torch.Size([2, 21888]), y: torch.Size([64, 1])\n",
      "2025-06-07 20:26:31 - INFO - Batch 1/163 - Loss: 0.5869 - Avg batch time: 1.40s\n",
      "2025-06-07 20:26:43 - INFO - Processing batch 11/163\n",
      "2025-06-07 20:26:45 - INFO - Batch 11/163 - Loss: 0.4117 - Avg batch time: 1.38s\n",
      "2025-06-07 20:26:57 - INFO - Processing batch 21/163\n",
      "2025-06-07 20:26:59 - INFO - Batch 21/163 - Loss: 0.4455 - Avg batch time: 1.39s\n",
      "2025-06-07 20:27:11 - INFO - Processing batch 31/163\n",
      "2025-06-07 20:27:12 - INFO - Batch 31/163 - Loss: 0.5301 - Avg batch time: 1.39s\n",
      "2025-06-07 20:27:25 - INFO - Processing batch 41/163\n",
      "2025-06-07 20:27:26 - INFO - Batch 41/163 - Loss: 0.4357 - Avg batch time: 1.39s\n",
      "2025-06-07 20:27:39 - INFO - Processing batch 51/163\n",
      "2025-06-07 20:27:40 - INFO - Batch 51/163 - Loss: 0.3658 - Avg batch time: 1.39s\n",
      "2025-06-07 20:27:53 - INFO - Processing batch 61/163\n",
      "2025-06-07 20:27:54 - INFO - Batch 61/163 - Loss: 0.3585 - Avg batch time: 1.39s\n",
      "2025-06-07 20:28:06 - INFO - Processing batch 71/163\n",
      "2025-06-07 20:28:08 - INFO - Batch 71/163 - Loss: 0.4979 - Avg batch time: 1.39s\n",
      "2025-06-07 20:28:20 - INFO - Processing batch 81/163\n",
      "2025-06-07 20:28:22 - INFO - Batch 81/163 - Loss: 0.4478 - Avg batch time: 1.39s\n",
      "2025-06-07 20:28:34 - INFO - Processing batch 91/163\n",
      "2025-06-07 20:28:36 - INFO - Batch 91/163 - Loss: 0.3868 - Avg batch time: 1.38s\n",
      "2025-06-07 20:28:48 - INFO - Processing batch 101/163\n",
      "2025-06-07 20:28:49 - INFO - Batch 101/163 - Loss: 0.5202 - Avg batch time: 1.39s\n",
      "2025-06-07 20:29:02 - INFO - Processing batch 111/163\n",
      "2025-06-07 20:29:03 - INFO - Batch 111/163 - Loss: 0.4411 - Avg batch time: 1.38s\n",
      "2025-06-07 20:29:16 - INFO - Processing batch 121/163\n",
      "2025-06-07 20:29:17 - INFO - Batch 121/163 - Loss: 0.4757 - Avg batch time: 1.39s\n",
      "2025-06-07 20:29:30 - INFO - Processing batch 131/163\n",
      "2025-06-07 20:29:31 - INFO - Batch 131/163 - Loss: 0.3162 - Avg batch time: 1.39s\n",
      "2025-06-07 20:29:43 - INFO - Processing batch 141/163\n",
      "2025-06-07 20:29:45 - INFO - Batch 141/163 - Loss: 0.4158 - Avg batch time: 1.39s\n",
      "2025-06-07 20:29:57 - INFO - Processing batch 151/163\n",
      "2025-06-07 20:29:59 - INFO - Batch 151/163 - Loss: 0.4490 - Avg batch time: 1.38s\n",
      "2025-06-07 20:30:11 - INFO - Processing batch 161/163\n",
      "2025-06-07 20:30:12 - INFO - Batch 161/163 - Loss: 0.4244 - Avg batch time: 1.38s\n",
      "2025-06-07 20:30:14 - INFO - \n",
      "Epoch 21 training completed in 227.68s\n",
      "2025-06-07 20:30:14 - INFO - Average training loss: 0.4616\n",
      "Epochs:  22%|| 22/100 [1:35:44<5:55:26, 273.42s/it, train_loss=0.4616, val_loss=0.3616, best_val_f1=0.6659, lr=2.50e-052025-06-07 20:31:00 - INFO - \n",
      "Epoch 22/100 - Training phase\n",
      "2025-06-07 20:31:03 - INFO - Processing batch 1/163\n",
      "2025-06-07 20:31:03 - INFO - Batch shapes - x: torch.Size([1216, 3000]), edge_index: torch.Size([2, 21888]), y: torch.Size([64, 1])\n",
      "2025-06-07 20:31:04 - INFO - Batch 1/163 - Loss: 0.4828 - Avg batch time: 1.43s\n",
      "2025-06-07 20:31:17 - INFO - Processing batch 11/163\n",
      "2025-06-07 20:31:18 - INFO - Batch 11/163 - Loss: 0.4392 - Avg batch time: 1.39s\n",
      "2025-06-07 20:31:30 - INFO - Processing batch 21/163\n",
      "2025-06-07 20:31:32 - INFO - Batch 21/163 - Loss: 0.4646 - Avg batch time: 1.39s\n",
      "2025-06-07 20:31:44 - INFO - Processing batch 31/163\n",
      "2025-06-07 20:31:46 - INFO - Batch 31/163 - Loss: 0.4593 - Avg batch time: 1.38s\n",
      "2025-06-07 20:31:58 - INFO - Processing batch 41/163\n",
      "2025-06-07 20:32:00 - INFO - Batch 41/163 - Loss: 0.4076 - Avg batch time: 1.38s\n",
      "2025-06-07 20:32:12 - INFO - Processing batch 51/163\n",
      "2025-06-07 20:32:13 - INFO - Batch 51/163 - Loss: 0.4472 - Avg batch time: 1.38s\n",
      "2025-06-07 20:32:26 - INFO - Processing batch 61/163\n",
      "2025-06-07 20:32:27 - INFO - Batch 61/163 - Loss: 0.3898 - Avg batch time: 1.38s\n",
      "2025-06-07 20:32:40 - INFO - Processing batch 71/163\n",
      "2025-06-07 20:32:41 - INFO - Batch 71/163 - Loss: 0.3326 - Avg batch time: 1.38s\n",
      "2025-06-07 20:32:54 - INFO - Processing batch 81/163\n",
      "2025-06-07 20:32:55 - INFO - Batch 81/163 - Loss: 0.4282 - Avg batch time: 1.38s\n",
      "2025-06-07 20:33:07 - INFO - Processing batch 91/163\n",
      "2025-06-07 20:33:09 - INFO - Batch 91/163 - Loss: 0.4497 - Avg batch time: 1.39s\n",
      "2025-06-07 20:33:21 - INFO - Processing batch 101/163\n",
      "2025-06-07 20:33:23 - INFO - Batch 101/163 - Loss: 0.3582 - Avg batch time: 1.38s\n",
      "2025-06-07 20:33:35 - INFO - Processing batch 111/163\n",
      "2025-06-07 20:33:36 - INFO - Batch 111/163 - Loss: 0.3999 - Avg batch time: 1.39s\n",
      "2025-06-07 20:33:49 - INFO - Processing batch 121/163\n",
      "2025-06-07 20:33:50 - INFO - Batch 121/163 - Loss: 0.4244 - Avg batch time: 1.38s\n",
      "2025-06-07 20:34:03 - INFO - Processing batch 131/163\n",
      "2025-06-07 20:34:04 - INFO - Batch 131/163 - Loss: 0.6265 - Avg batch time: 1.39s\n",
      "2025-06-07 20:34:17 - INFO - Processing batch 141/163\n",
      "2025-06-07 20:34:18 - INFO - Batch 141/163 - Loss: 0.3876 - Avg batch time: 1.39s\n",
      "2025-06-07 20:34:31 - INFO - Processing batch 151/163\n",
      "2025-06-07 20:34:32 - INFO - Batch 151/163 - Loss: 0.5069 - Avg batch time: 1.39s\n",
      "2025-06-07 20:34:44 - INFO - Processing batch 161/163\n",
      "2025-06-07 20:34:46 - INFO - Batch 161/163 - Loss: 0.4358 - Avg batch time: 1.37s\n",
      "2025-06-07 20:34:48 - INFO - \n",
      "Epoch 22 training completed in 227.54s\n",
      "2025-06-07 20:34:48 - INFO - Average training loss: 0.4381\n",
      "Epochs:  23%|| 23/100 [1:40:17<5:50:54, 273.44s/it, train_loss=0.4381, val_loss=0.3532, best_val_f1=0.6659, lr=2.50e-052025-06-07 20:35:34 - INFO - \n",
      "Epoch 23/100 - Training phase\n",
      "2025-06-07 20:35:36 - INFO - Processing batch 1/163\n",
      "2025-06-07 20:35:36 - INFO - Batch shapes - x: torch.Size([1216, 3000]), edge_index: torch.Size([2, 21888]), y: torch.Size([64, 1])\n",
      "2025-06-07 20:35:38 - INFO - Batch 1/163 - Loss: 0.4356 - Avg batch time: 1.42s\n",
      "2025-06-07 20:35:50 - INFO - Processing batch 11/163\n",
      "2025-06-07 20:35:51 - INFO - Batch 11/163 - Loss: 0.4415 - Avg batch time: 1.39s\n",
      "2025-06-07 20:36:04 - INFO - Processing batch 21/163\n",
      "2025-06-07 20:36:05 - INFO - Batch 21/163 - Loss: 0.5377 - Avg batch time: 1.38s\n",
      "2025-06-07 20:36:18 - INFO - Processing batch 31/163\n",
      "2025-06-07 20:36:19 - INFO - Batch 31/163 - Loss: 0.4439 - Avg batch time: 1.39s\n",
      "2025-06-07 20:36:32 - INFO - Processing batch 41/163\n",
      "2025-06-07 20:36:33 - INFO - Batch 41/163 - Loss: 0.4833 - Avg batch time: 1.39s\n",
      "2025-06-07 20:36:46 - INFO - Processing batch 51/163\n",
      "2025-06-07 20:36:47 - INFO - Batch 51/163 - Loss: 0.4046 - Avg batch time: 1.38s\n",
      "2025-06-07 20:36:59 - INFO - Processing batch 61/163\n",
      "2025-06-07 20:37:01 - INFO - Batch 61/163 - Loss: 0.3891 - Avg batch time: 1.38s\n",
      "2025-06-07 20:37:13 - INFO - Processing batch 71/163\n",
      "2025-06-07 20:37:15 - INFO - Batch 71/163 - Loss: 0.4677 - Avg batch time: 1.39s\n",
      "2025-06-07 20:37:27 - INFO - Processing batch 81/163\n",
      "2025-06-07 20:37:28 - INFO - Batch 81/163 - Loss: 0.4225 - Avg batch time: 1.38s\n",
      "2025-06-07 20:37:41 - INFO - Processing batch 91/163\n",
      "2025-06-07 20:37:42 - INFO - Batch 91/163 - Loss: 0.3586 - Avg batch time: 1.39s\n",
      "2025-06-07 20:37:55 - INFO - Processing batch 101/163\n",
      "2025-06-07 20:37:56 - INFO - Batch 101/163 - Loss: 0.3646 - Avg batch time: 1.39s\n",
      "2025-06-07 20:38:09 - INFO - Processing batch 111/163\n",
      "2025-06-07 20:38:10 - INFO - Batch 111/163 - Loss: 0.3632 - Avg batch time: 1.39s\n",
      "2025-06-07 20:38:23 - INFO - Processing batch 121/163\n",
      "2025-06-07 20:38:24 - INFO - Batch 121/163 - Loss: 0.3494 - Avg batch time: 1.39s\n",
      "2025-06-07 20:38:36 - INFO - Processing batch 131/163\n",
      "2025-06-07 20:38:38 - INFO - Batch 131/163 - Loss: 0.4600 - Avg batch time: 1.39s\n",
      "2025-06-07 20:38:50 - INFO - Processing batch 141/163\n",
      "2025-06-07 20:38:52 - INFO - Batch 141/163 - Loss: 0.4966 - Avg batch time: 1.39s\n",
      "2025-06-07 20:39:04 - INFO - Processing batch 151/163\n",
      "2025-06-07 20:39:06 - INFO - Batch 151/163 - Loss: 0.4328 - Avg batch time: 1.38s\n",
      "2025-06-07 20:39:18 - INFO - Processing batch 161/163\n",
      "2025-06-07 20:39:19 - INFO - Batch 161/163 - Loss: 0.4687 - Avg batch time: 1.38s\n",
      "2025-06-07 20:39:21 - INFO - \n",
      "Epoch 23 training completed in 227.69s\n",
      "2025-06-07 20:39:21 - INFO - Average training loss: 0.4423\n",
      "Epochs:  24%|| 24/100 [1:44:51<5:46:22, 273.45s/it, train_loss=0.4423, val_loss=0.3635, best_val_f1=0.6659, lr=1.25e-052025-06-07 20:40:07 - INFO - \n",
      "Epoch 24/100 - Training phase\n",
      "2025-06-07 20:40:09 - INFO - Processing batch 1/163\n",
      "2025-06-07 20:40:09 - INFO - Batch shapes - x: torch.Size([1216, 3000]), edge_index: torch.Size([2, 21888]), y: torch.Size([64, 1])\n",
      "2025-06-07 20:40:11 - INFO - Batch 1/163 - Loss: 0.4111 - Avg batch time: 1.42s\n",
      "2025-06-07 20:40:23 - INFO - Processing batch 11/163\n",
      "2025-06-07 20:40:25 - INFO - Batch 11/163 - Loss: 0.4862 - Avg batch time: 1.39s\n",
      "2025-06-07 20:40:37 - INFO - Processing batch 21/163\n",
      "2025-06-07 20:40:39 - INFO - Batch 21/163 - Loss: 0.4190 - Avg batch time: 1.38s\n",
      "2025-06-07 20:40:51 - INFO - Processing batch 31/163\n",
      "2025-06-07 20:40:53 - INFO - Batch 31/163 - Loss: 0.4250 - Avg batch time: 1.38s\n",
      "2025-06-07 20:41:05 - INFO - Processing batch 41/163\n",
      "2025-06-07 20:41:06 - INFO - Batch 41/163 - Loss: 0.3968 - Avg batch time: 1.38s\n",
      "2025-06-07 20:41:19 - INFO - Processing batch 51/163\n",
      "2025-06-07 20:41:20 - INFO - Batch 51/163 - Loss: 0.4000 - Avg batch time: 1.39s\n",
      "2025-06-07 20:41:33 - INFO - Processing batch 61/163\n",
      "2025-06-07 20:41:34 - INFO - Batch 61/163 - Loss: 0.3735 - Avg batch time: 1.38s\n",
      "2025-06-07 20:41:47 - INFO - Processing batch 71/163\n",
      "2025-06-07 20:41:48 - INFO - Batch 71/163 - Loss: 0.5180 - Avg batch time: 1.38s\n",
      "2025-06-07 20:42:00 - INFO - Processing batch 81/163\n",
      "2025-06-07 20:42:02 - INFO - Batch 81/163 - Loss: 0.3302 - Avg batch time: 1.39s\n",
      "2025-06-07 20:42:14 - INFO - Processing batch 91/163\n",
      "2025-06-07 20:42:16 - INFO - Batch 91/163 - Loss: 0.3622 - Avg batch time: 1.38s\n",
      "2025-06-07 20:42:28 - INFO - Processing batch 101/163\n",
      "2025-06-07 20:42:30 - INFO - Batch 101/163 - Loss: 0.4283 - Avg batch time: 1.39s\n",
      "2025-06-07 20:42:42 - INFO - Processing batch 111/163\n",
      "2025-06-07 20:42:43 - INFO - Batch 111/163 - Loss: 0.3221 - Avg batch time: 1.38s\n",
      "2025-06-07 20:42:56 - INFO - Processing batch 121/163\n",
      "2025-06-07 20:42:57 - INFO - Batch 121/163 - Loss: 0.4800 - Avg batch time: 1.38s\n",
      "2025-06-07 20:43:10 - INFO - Processing batch 131/163\n",
      "2025-06-07 20:43:11 - INFO - Batch 131/163 - Loss: 0.4146 - Avg batch time: 1.39s\n",
      "2025-06-07 20:43:24 - INFO - Processing batch 141/163\n",
      "2025-06-07 20:43:25 - INFO - Batch 141/163 - Loss: 0.4609 - Avg batch time: 1.38s\n",
      "2025-06-07 20:43:37 - INFO - Processing batch 151/163\n",
      "2025-06-07 20:43:39 - INFO - Batch 151/163 - Loss: 0.4024 - Avg batch time: 1.39s\n",
      "2025-06-07 20:43:51 - INFO - Processing batch 161/163\n",
      "2025-06-07 20:43:53 - INFO - Batch 161/163 - Loss: 0.4694 - Avg batch time: 1.38s\n",
      "2025-06-07 20:43:55 - INFO - \n",
      "Epoch 24 training completed in 227.45s\n",
      "2025-06-07 20:43:55 - INFO - Average training loss: 0.4291\n",
      "Epochs:  25%|| 25/100 [1:49:24<5:41:52, 273.49s/it, train_loss=0.4291, val_loss=0.3473, best_val_f1=0.6659, lr=1.25e-052025-06-07 20:44:41 - INFO - \n",
      "Epoch 25/100 - Training phase\n",
      "2025-06-07 20:44:43 - INFO - Processing batch 1/163\n",
      "2025-06-07 20:44:43 - INFO - Batch shapes - x: torch.Size([1216, 3000]), edge_index: torch.Size([2, 21888]), y: torch.Size([64, 1])\n",
      "2025-06-07 20:44:44 - INFO - Batch 1/163 - Loss: 0.4515 - Avg batch time: 1.39s\n",
      "2025-06-07 20:44:57 - INFO - Processing batch 11/163\n",
      "2025-06-07 20:44:58 - INFO - Batch 11/163 - Loss: 0.5195 - Avg batch time: 1.39s\n",
      "2025-06-07 20:45:11 - INFO - Processing batch 21/163\n",
      "2025-06-07 20:45:12 - INFO - Batch 21/163 - Loss: 0.3924 - Avg batch time: 1.38s\n",
      "2025-06-07 20:45:25 - INFO - Processing batch 31/163\n",
      "2025-06-07 20:45:26 - INFO - Batch 31/163 - Loss: 0.3814 - Avg batch time: 1.38s\n",
      "2025-06-07 20:45:38 - INFO - Processing batch 41/163\n",
      "2025-06-07 20:45:40 - INFO - Batch 41/163 - Loss: 0.4128 - Avg batch time: 1.39s\n",
      "2025-06-07 20:45:52 - INFO - Processing batch 51/163\n",
      "2025-06-07 20:45:54 - INFO - Batch 51/163 - Loss: 0.4355 - Avg batch time: 1.38s\n",
      "2025-06-07 20:46:06 - INFO - Processing batch 61/163\n",
      "2025-06-07 20:46:08 - INFO - Batch 61/163 - Loss: 0.4894 - Avg batch time: 1.39s\n",
      "2025-06-07 20:46:20 - INFO - Processing batch 71/163\n",
      "2025-06-07 20:46:21 - INFO - Batch 71/163 - Loss: 0.5338 - Avg batch time: 1.38s\n",
      "2025-06-07 20:46:34 - INFO - Processing batch 81/163\n",
      "2025-06-07 20:46:35 - INFO - Batch 81/163 - Loss: 0.5464 - Avg batch time: 1.39s\n",
      "2025-06-07 20:46:48 - INFO - Processing batch 91/163\n",
      "2025-06-07 20:46:49 - INFO - Batch 91/163 - Loss: 0.3745 - Avg batch time: 1.38s\n",
      "2025-06-07 20:47:02 - INFO - Processing batch 101/163\n",
      "2025-06-07 20:47:03 - INFO - Batch 101/163 - Loss: 0.4711 - Avg batch time: 1.39s\n",
      "2025-06-07 20:47:15 - INFO - Processing batch 111/163\n",
      "2025-06-07 20:47:17 - INFO - Batch 111/163 - Loss: 0.4775 - Avg batch time: 1.39s\n",
      "2025-06-07 20:47:29 - INFO - Processing batch 121/163\n",
      "2025-06-07 20:47:31 - INFO - Batch 121/163 - Loss: 0.4237 - Avg batch time: 1.39s\n",
      "2025-06-07 20:47:43 - INFO - Processing batch 131/163\n",
      "2025-06-07 20:47:45 - INFO - Batch 131/163 - Loss: 0.3667 - Avg batch time: 1.38s\n",
      "2025-06-07 20:47:57 - INFO - Processing batch 141/163\n",
      "2025-06-07 20:47:59 - INFO - Batch 141/163 - Loss: 0.6471 - Avg batch time: 1.39s\n",
      "2025-06-07 20:48:11 - INFO - Processing batch 151/163\n",
      "2025-06-07 20:48:12 - INFO - Batch 151/163 - Loss: 0.4205 - Avg batch time: 1.39s\n",
      "2025-06-07 20:48:25 - INFO - Processing batch 161/163\n",
      "2025-06-07 20:48:26 - INFO - Batch 161/163 - Loss: 0.3375 - Avg batch time: 1.38s\n",
      "2025-06-07 20:48:28 - INFO - \n",
      "Epoch 25 training completed in 227.41s\n",
      "2025-06-07 20:48:28 - INFO - Average training loss: 0.4403\n",
      "Epochs:  26%|| 26/100 [1:53:58<5:37:12, 273.42s/it, train_loss=0.4403, val_loss=0.3380, best_val_f1=0.6659, lr=1.25e-052025-06-07 20:49:14 - INFO - \n",
      "Epoch 26/100 - Training phase\n",
      "2025-06-07 20:49:16 - INFO - Processing batch 1/163\n",
      "2025-06-07 20:49:16 - INFO - Batch shapes - x: torch.Size([1216, 3000]), edge_index: torch.Size([2, 21888]), y: torch.Size([64, 1])\n",
      "2025-06-07 20:49:18 - INFO - Batch 1/163 - Loss: 0.3448 - Avg batch time: 1.39s\n",
      "2025-06-07 20:49:30 - INFO - Processing batch 11/163\n",
      "2025-06-07 20:49:32 - INFO - Batch 11/163 - Loss: 0.4707 - Avg batch time: 1.39s\n",
      "2025-06-07 20:49:44 - INFO - Processing batch 21/163\n",
      "2025-06-07 20:49:46 - INFO - Batch 21/163 - Loss: 0.4983 - Avg batch time: 1.38s\n",
      "2025-06-07 20:49:58 - INFO - Processing batch 31/163\n",
      "2025-06-07 20:49:59 - INFO - Batch 31/163 - Loss: 0.4596 - Avg batch time: 1.38s\n",
      "2025-06-07 20:50:12 - INFO - Processing batch 41/163\n",
      "2025-06-07 20:50:13 - INFO - Batch 41/163 - Loss: 0.5003 - Avg batch time: 1.39s\n",
      "2025-06-07 20:50:26 - INFO - Processing batch 51/163\n",
      "2025-06-07 20:50:27 - INFO - Batch 51/163 - Loss: 0.4234 - Avg batch time: 1.39s\n",
      "2025-06-07 20:50:40 - INFO - Processing batch 61/163\n",
      "2025-06-07 20:50:41 - INFO - Batch 61/163 - Loss: 0.4583 - Avg batch time: 1.39s\n",
      "2025-06-07 20:50:53 - INFO - Processing batch 71/163\n",
      "2025-06-07 20:50:55 - INFO - Batch 71/163 - Loss: 0.4403 - Avg batch time: 1.39s\n",
      "2025-06-07 20:51:07 - INFO - Processing batch 81/163\n",
      "2025-06-07 20:51:09 - INFO - Batch 81/163 - Loss: 0.4625 - Avg batch time: 1.39s\n",
      "2025-06-07 20:51:21 - INFO - Processing batch 91/163\n",
      "2025-06-07 20:51:23 - INFO - Batch 91/163 - Loss: 0.5250 - Avg batch time: 1.39s\n",
      "2025-06-07 20:51:35 - INFO - Processing batch 101/163\n",
      "2025-06-07 20:51:36 - INFO - Batch 101/163 - Loss: 0.3609 - Avg batch time: 1.39s\n",
      "2025-06-07 20:51:49 - INFO - Processing batch 111/163\n",
      "2025-06-07 20:51:50 - INFO - Batch 111/163 - Loss: 0.5664 - Avg batch time: 1.38s\n",
      "2025-06-07 20:52:03 - INFO - Processing batch 121/163\n",
      "2025-06-07 20:52:04 - INFO - Batch 121/163 - Loss: 0.3320 - Avg batch time: 1.38s\n",
      "2025-06-07 20:52:17 - INFO - Processing batch 131/163\n",
      "2025-06-07 20:52:18 - INFO - Batch 131/163 - Loss: 0.4341 - Avg batch time: 1.39s\n",
      "2025-06-07 20:52:30 - INFO - Processing batch 141/163\n",
      "2025-06-07 20:52:32 - INFO - Batch 141/163 - Loss: 0.3551 - Avg batch time: 1.39s\n",
      "2025-06-07 20:52:44 - INFO - Processing batch 151/163\n",
      "2025-06-07 20:52:46 - INFO - Batch 151/163 - Loss: 0.4600 - Avg batch time: 1.39s\n",
      "2025-06-07 20:52:58 - INFO - Processing batch 161/163\n",
      "2025-06-07 20:53:00 - INFO - Batch 161/163 - Loss: 0.4111 - Avg batch time: 1.38s\n",
      "2025-06-07 20:53:01 - INFO - \n",
      "Epoch 26 training completed in 227.54s\n",
      "2025-06-07 20:53:01 - INFO - Average training loss: 0.4312\n",
      "Epochs:  27%|| 27/100 [1:58:31<5:32:38, 273.40s/it, train_loss=0.4312, val_loss=0.3374, best_val_f1=0.6659, lr=1.25e-052025-06-07 20:53:47 - INFO - \n",
      "Epoch 27/100 - Training phase\n",
      "2025-06-07 20:53:50 - INFO - Processing batch 1/163\n",
      "2025-06-07 20:53:50 - INFO - Batch shapes - x: torch.Size([1216, 3000]), edge_index: torch.Size([2, 21888]), y: torch.Size([64, 1])\n",
      "2025-06-07 20:53:51 - INFO - Batch 1/163 - Loss: 0.4969 - Avg batch time: 1.39s\n",
      "2025-06-07 20:54:04 - INFO - Processing batch 11/163\n",
      "2025-06-07 20:54:05 - INFO - Batch 11/163 - Loss: 0.4106 - Avg batch time: 1.39s\n",
      "2025-06-07 20:54:18 - INFO - Processing batch 21/163\n",
      "2025-06-07 20:54:19 - INFO - Batch 21/163 - Loss: 0.3530 - Avg batch time: 1.39s\n",
      "2025-06-07 20:54:31 - INFO - Processing batch 31/163\n",
      "2025-06-07 20:54:33 - INFO - Batch 31/163 - Loss: 0.3888 - Avg batch time: 1.39s\n",
      "2025-06-07 20:54:45 - INFO - Processing batch 41/163\n",
      "2025-06-07 20:54:47 - INFO - Batch 41/163 - Loss: 0.4620 - Avg batch time: 1.39s\n",
      "2025-06-07 20:54:59 - INFO - Processing batch 51/163\n",
      "2025-06-07 20:55:01 - INFO - Batch 51/163 - Loss: 0.3770 - Avg batch time: 1.39s\n",
      "2025-06-07 20:55:13 - INFO - Processing batch 61/163\n",
      "2025-06-07 20:55:14 - INFO - Batch 61/163 - Loss: 0.4422 - Avg batch time: 1.38s\n",
      "2025-06-07 20:55:27 - INFO - Processing batch 71/163\n",
      "2025-06-07 20:55:28 - INFO - Batch 71/163 - Loss: 0.4618 - Avg batch time: 1.38s\n",
      "2025-06-07 20:55:41 - INFO - Processing batch 81/163\n",
      "2025-06-07 20:55:42 - INFO - Batch 81/163 - Loss: 0.4766 - Avg batch time: 1.38s\n",
      "2025-06-07 20:55:55 - INFO - Processing batch 91/163\n",
      "2025-06-07 20:55:56 - INFO - Batch 91/163 - Loss: 0.4119 - Avg batch time: 1.39s\n",
      "2025-06-07 20:56:08 - INFO - Processing batch 101/163\n",
      "2025-06-07 20:56:10 - INFO - Batch 101/163 - Loss: 0.5818 - Avg batch time: 1.38s\n",
      "2025-06-07 20:56:22 - INFO - Processing batch 111/163\n",
      "2025-06-07 20:56:24 - INFO - Batch 111/163 - Loss: 0.5070 - Avg batch time: 1.39s\n",
      "2025-06-07 20:56:36 - INFO - Processing batch 121/163\n",
      "2025-06-07 20:56:38 - INFO - Batch 121/163 - Loss: 0.3555 - Avg batch time: 1.38s\n",
      "2025-06-07 20:56:50 - INFO - Processing batch 131/163\n",
      "2025-06-07 20:56:51 - INFO - Batch 131/163 - Loss: 0.4338 - Avg batch time: 1.39s\n",
      "2025-06-07 20:57:04 - INFO - Processing batch 141/163\n",
      "2025-06-07 20:57:05 - INFO - Batch 141/163 - Loss: 0.4040 - Avg batch time: 1.39s\n",
      "2025-06-07 20:57:18 - INFO - Processing batch 151/163\n",
      "2025-06-07 20:57:19 - INFO - Batch 151/163 - Loss: 0.4188 - Avg batch time: 1.38s\n",
      "2025-06-07 20:57:32 - INFO - Processing batch 161/163\n",
      "2025-06-07 20:57:33 - INFO - Batch 161/163 - Loss: 0.4123 - Avg batch time: 1.38s\n",
      "2025-06-07 20:57:35 - INFO - \n",
      "Epoch 27 training completed in 227.57s\n",
      "2025-06-07 20:57:35 - INFO - Average training loss: 0.4393\n",
      "Epochs:  28%|| 28/100 [2:03:05<5:28:07, 273.44s/it, train_loss=0.4393, val_loss=0.3441, best_val_f1=0.6659, lr=1.25e-052025-06-07 20:58:21 - INFO - \n",
      "Epoch 28/100 - Training phase\n",
      "2025-06-07 20:58:23 - INFO - Processing batch 1/163\n",
      "2025-06-07 20:58:23 - INFO - Batch shapes - x: torch.Size([1216, 3000]), edge_index: torch.Size([2, 21888]), y: torch.Size([64, 1])\n",
      "2025-06-07 20:58:25 - INFO - Batch 1/163 - Loss: 0.4794 - Avg batch time: 1.41s\n",
      "2025-06-07 20:58:37 - INFO - Processing batch 11/163\n",
      "2025-06-07 20:58:39 - INFO - Batch 11/163 - Loss: 0.6393 - Avg batch time: 1.39s\n",
      "2025-06-07 20:58:51 - INFO - Processing batch 21/163\n",
      "2025-06-07 20:58:53 - INFO - Batch 21/163 - Loss: 0.4108 - Avg batch time: 1.38s\n",
      "2025-06-07 20:59:05 - INFO - Processing batch 31/163\n",
      "2025-06-07 20:59:06 - INFO - Batch 31/163 - Loss: 0.4165 - Avg batch time: 1.38s\n",
      "2025-06-07 20:59:19 - INFO - Processing batch 41/163\n",
      "2025-06-07 20:59:20 - INFO - Batch 41/163 - Loss: 0.3812 - Avg batch time: 1.39s\n",
      "2025-06-07 20:59:33 - INFO - Processing batch 51/163\n",
      "2025-06-07 20:59:34 - INFO - Batch 51/163 - Loss: 0.3644 - Avg batch time: 1.39s\n",
      "2025-06-07 20:59:47 - INFO - Processing batch 61/163\n",
      "2025-06-07 20:59:48 - INFO - Batch 61/163 - Loss: 0.3530 - Avg batch time: 1.39s\n",
      "2025-06-07 21:00:01 - INFO - Processing batch 71/163\n",
      "2025-06-07 21:00:02 - INFO - Batch 71/163 - Loss: 0.3676 - Avg batch time: 1.38s\n",
      "2025-06-07 21:00:14 - INFO - Processing batch 81/163\n",
      "2025-06-07 21:00:16 - INFO - Batch 81/163 - Loss: 0.5479 - Avg batch time: 1.39s\n",
      "2025-06-07 21:00:28 - INFO - Processing batch 91/163\n",
      "2025-06-07 21:00:30 - INFO - Batch 91/163 - Loss: 0.3998 - Avg batch time: 1.39s\n",
      "2025-06-07 21:00:42 - INFO - Processing batch 101/163\n",
      "2025-06-07 21:00:44 - INFO - Batch 101/163 - Loss: 0.4065 - Avg batch time: 1.38s\n",
      "2025-06-07 21:00:56 - INFO - Processing batch 111/163\n",
      "2025-06-07 21:00:57 - INFO - Batch 111/163 - Loss: 0.4485 - Avg batch time: 1.39s\n",
      "2025-06-07 21:01:10 - INFO - Processing batch 121/163\n",
      "2025-06-07 21:01:11 - INFO - Batch 121/163 - Loss: 0.3443 - Avg batch time: 1.38s\n",
      "2025-06-07 21:01:24 - INFO - Processing batch 131/163\n",
      "2025-06-07 21:01:25 - INFO - Batch 131/163 - Loss: 0.4267 - Avg batch time: 1.39s\n",
      "2025-06-07 21:01:38 - INFO - Processing batch 141/163\n",
      "2025-06-07 21:01:39 - INFO - Batch 141/163 - Loss: 0.3958 - Avg batch time: 1.38s\n",
      "2025-06-07 21:01:51 - INFO - Processing batch 151/163\n",
      "2025-06-07 21:01:53 - INFO - Batch 151/163 - Loss: 0.3537 - Avg batch time: 1.38s\n",
      "2025-06-07 21:02:05 - INFO - Processing batch 161/163\n",
      "2025-06-07 21:02:07 - INFO - Batch 161/163 - Loss: 0.5454 - Avg batch time: 1.38s\n",
      "2025-06-07 21:02:09 - INFO - \n",
      "Epoch 28 training completed in 227.72s\n",
      "2025-06-07 21:02:09 - INFO - Average training loss: 0.4226\n",
      "Epochs:  29%|| 29/100 [2:07:38<5:23:35, 273.46s/it, train_loss=0.4226, val_loss=0.3392, best_val_f1=0.6659, lr=1.25e-052025-06-07 21:02:54 - INFO - \n",
      "Epoch 29/100 - Training phase\n",
      "2025-06-07 21:02:57 - INFO - Processing batch 1/163\n",
      "2025-06-07 21:02:57 - INFO - Batch shapes - x: torch.Size([1216, 3000]), edge_index: torch.Size([2, 21888]), y: torch.Size([64, 1])\n",
      "2025-06-07 21:02:58 - INFO - Batch 1/163 - Loss: 0.4216 - Avg batch time: 1.42s\n",
      "2025-06-07 21:03:11 - INFO - Processing batch 11/163\n",
      "2025-06-07 21:03:12 - INFO - Batch 11/163 - Loss: 0.3670 - Avg batch time: 1.39s\n",
      "2025-06-07 21:03:25 - INFO - Processing batch 21/163\n",
      "2025-06-07 21:03:26 - INFO - Batch 21/163 - Loss: 0.3467 - Avg batch time: 1.39s\n",
      "2025-06-07 21:03:38 - INFO - Processing batch 31/163\n",
      "2025-06-07 21:03:40 - INFO - Batch 31/163 - Loss: 0.4551 - Avg batch time: 1.39s\n",
      "2025-06-07 21:03:52 - INFO - Processing batch 41/163\n",
      "2025-06-07 21:03:54 - INFO - Batch 41/163 - Loss: 0.4151 - Avg batch time: 1.39s\n",
      "2025-06-07 21:04:06 - INFO - Processing batch 51/163\n",
      "2025-06-07 21:04:08 - INFO - Batch 51/163 - Loss: 0.3591 - Avg batch time: 1.39s\n",
      "2025-06-07 21:04:20 - INFO - Processing batch 61/163\n",
      "2025-06-07 21:04:21 - INFO - Batch 61/163 - Loss: 0.4113 - Avg batch time: 1.39s\n",
      "2025-06-07 21:04:34 - INFO - Processing batch 71/163\n",
      "2025-06-07 21:04:35 - INFO - Batch 71/163 - Loss: 0.5219 - Avg batch time: 1.39s\n",
      "2025-06-07 21:04:48 - INFO - Processing batch 81/163\n",
      "2025-06-07 21:04:49 - INFO - Batch 81/163 - Loss: 0.3882 - Avg batch time: 1.39s\n",
      "2025-06-07 21:05:02 - INFO - Processing batch 91/163\n",
      "2025-06-07 21:05:03 - INFO - Batch 91/163 - Loss: 0.4121 - Avg batch time: 1.39s\n",
      "2025-06-07 21:05:16 - INFO - Processing batch 101/163\n",
      "2025-06-07 21:05:17 - INFO - Batch 101/163 - Loss: 0.4206 - Avg batch time: 1.39s\n",
      "2025-06-07 21:05:29 - INFO - Processing batch 111/163\n",
      "2025-06-07 21:05:31 - INFO - Batch 111/163 - Loss: 0.4427 - Avg batch time: 1.39s\n",
      "2025-06-07 21:05:43 - INFO - Processing batch 121/163\n",
      "2025-06-07 21:05:45 - INFO - Batch 121/163 - Loss: 0.4904 - Avg batch time: 1.39s\n",
      "2025-06-07 21:05:57 - INFO - Processing batch 131/163\n",
      "2025-06-07 21:05:58 - INFO - Batch 131/163 - Loss: 0.4058 - Avg batch time: 1.39s\n",
      "2025-06-07 21:06:11 - INFO - Processing batch 141/163\n",
      "2025-06-07 21:06:12 - INFO - Batch 141/163 - Loss: 0.4535 - Avg batch time: 1.39s\n",
      "2025-06-07 21:06:25 - INFO - Processing batch 151/163\n",
      "2025-06-07 21:06:26 - INFO - Batch 151/163 - Loss: 0.5002 - Avg batch time: 1.39s\n",
      "2025-06-07 21:06:39 - INFO - Processing batch 161/163\n",
      "2025-06-07 21:06:40 - INFO - Batch 161/163 - Loss: 0.5785 - Avg batch time: 1.38s\n",
      "2025-06-07 21:06:42 - INFO - \n",
      "Epoch 29 training completed in 227.63s\n",
      "2025-06-07 21:06:42 - INFO - Average training loss: 0.4240\n",
      "Epochs:  30%|| 30/100 [2:12:11<5:19:02, 273.46s/it, train_loss=0.4240, val_loss=0.3525, best_val_f1=0.6659, lr=6.25e-062025-06-07 21:07:28 - INFO - \n",
      "Epoch 30/100 - Training phase\n",
      "2025-06-07 21:07:30 - INFO - Processing batch 1/163\n",
      "2025-06-07 21:07:30 - INFO - Batch shapes - x: torch.Size([1216, 3000]), edge_index: torch.Size([2, 21888]), y: torch.Size([64, 1])\n",
      "2025-06-07 21:07:32 - INFO - Batch 1/163 - Loss: 0.4603 - Avg batch time: 1.40s\n",
      "2025-06-07 21:07:44 - INFO - Processing batch 11/163\n",
      "2025-06-07 21:07:46 - INFO - Batch 11/163 - Loss: 0.3873 - Avg batch time: 1.39s\n",
      "2025-06-07 21:07:58 - INFO - Processing batch 21/163\n",
      "2025-06-07 21:07:59 - INFO - Batch 21/163 - Loss: 0.4638 - Avg batch time: 1.38s\n",
      "2025-06-07 21:08:12 - INFO - Processing batch 31/163\n",
      "2025-06-07 21:08:13 - INFO - Batch 31/163 - Loss: 0.4381 - Avg batch time: 1.38s\n",
      "2025-06-07 21:08:26 - INFO - Processing batch 41/163\n",
      "2025-06-07 21:08:27 - INFO - Batch 41/163 - Loss: 0.6010 - Avg batch time: 1.39s\n",
      "2025-06-07 21:08:40 - INFO - Processing batch 51/163\n",
      "2025-06-07 21:08:41 - INFO - Batch 51/163 - Loss: 0.3403 - Avg batch time: 1.39s\n",
      "2025-06-07 21:08:53 - INFO - Processing batch 61/163\n",
      "2025-06-07 21:08:55 - INFO - Batch 61/163 - Loss: 0.3069 - Avg batch time: 1.39s\n",
      "2025-06-07 21:09:07 - INFO - Processing batch 71/163\n",
      "2025-06-07 21:09:09 - INFO - Batch 71/163 - Loss: 0.3813 - Avg batch time: 1.38s\n",
      "2025-06-07 21:09:21 - INFO - Processing batch 81/163\n",
      "2025-06-07 21:09:23 - INFO - Batch 81/163 - Loss: 0.3836 - Avg batch time: 1.39s\n",
      "2025-06-07 21:09:35 - INFO - Processing batch 91/163\n",
      "2025-06-07 21:09:36 - INFO - Batch 91/163 - Loss: 0.3851 - Avg batch time: 1.38s\n",
      "2025-06-07 21:09:49 - INFO - Processing batch 101/163\n",
      "2025-06-07 21:09:50 - INFO - Batch 101/163 - Loss: 0.4139 - Avg batch time: 1.39s\n",
      "2025-06-07 21:10:03 - INFO - Processing batch 111/163\n",
      "2025-06-07 21:10:04 - INFO - Batch 111/163 - Loss: 0.3672 - Avg batch time: 1.39s\n",
      "2025-06-07 21:10:17 - INFO - Processing batch 121/163\n",
      "2025-06-07 21:10:18 - INFO - Batch 121/163 - Loss: 0.4013 - Avg batch time: 1.39s\n",
      "2025-06-07 21:10:31 - INFO - Processing batch 131/163\n",
      "2025-06-07 21:10:32 - INFO - Batch 131/163 - Loss: 0.4939 - Avg batch time: 1.39s\n",
      "2025-06-07 21:10:44 - INFO - Processing batch 141/163\n",
      "2025-06-07 21:10:46 - INFO - Batch 141/163 - Loss: 0.3842 - Avg batch time: 1.38s\n",
      "2025-06-07 21:10:58 - INFO - Processing batch 151/163\n",
      "2025-06-07 21:11:00 - INFO - Batch 151/163 - Loss: 0.3841 - Avg batch time: 1.39s\n",
      "2025-06-07 21:11:12 - INFO - Processing batch 161/163\n",
      "2025-06-07 21:11:13 - INFO - Batch 161/163 - Loss: 0.4994 - Avg batch time: 1.38s\n",
      "2025-06-07 21:11:15 - INFO - \n",
      "Epoch 30 training completed in 227.62s\n",
      "2025-06-07 21:11:15 - INFO - Average training loss: 0.4249\n",
      "Epochs:  31%|| 31/100 [2:16:45<5:14:28, 273.46s/it, train_loss=0.4249, val_loss=0.3492, best_val_f1=0.6659, lr=6.25e-062025-06-07 21:12:01 - INFO - \n",
      "Epoch 31/100 - Training phase\n",
      "2025-06-07 21:12:04 - INFO - Processing batch 1/163\n",
      "2025-06-07 21:12:04 - INFO - Batch shapes - x: torch.Size([1216, 3000]), edge_index: torch.Size([2, 21888]), y: torch.Size([64, 1])\n",
      "2025-06-07 21:12:05 - INFO - Batch 1/163 - Loss: 0.3702 - Avg batch time: 1.41s\n",
      "2025-06-07 21:12:18 - INFO - Processing batch 11/163\n",
      "2025-06-07 21:12:19 - INFO - Batch 11/163 - Loss: 0.3458 - Avg batch time: 1.39s\n",
      "2025-06-07 21:12:31 - INFO - Processing batch 21/163\n",
      "2025-06-07 21:12:33 - INFO - Batch 21/163 - Loss: 0.3687 - Avg batch time: 1.38s\n",
      "2025-06-07 21:12:45 - INFO - Processing batch 31/163\n",
      "2025-06-07 21:12:47 - INFO - Batch 31/163 - Loss: 0.3974 - Avg batch time: 1.39s\n",
      "2025-06-07 21:12:59 - INFO - Processing batch 41/163\n",
      "2025-06-07 21:13:01 - INFO - Batch 41/163 - Loss: 0.3324 - Avg batch time: 1.39s\n",
      "2025-06-07 21:13:13 - INFO - Processing batch 51/163\n",
      "2025-06-07 21:13:14 - INFO - Batch 51/163 - Loss: 0.3618 - Avg batch time: 1.38s\n",
      "2025-06-07 21:13:27 - INFO - Processing batch 61/163\n",
      "2025-06-07 21:13:28 - INFO - Batch 61/163 - Loss: 0.5209 - Avg batch time: 1.38s\n",
      "2025-06-07 21:13:41 - INFO - Processing batch 71/163\n",
      "2025-06-07 21:13:42 - INFO - Batch 71/163 - Loss: 0.3929 - Avg batch time: 1.38s\n",
      "2025-06-07 21:13:55 - INFO - Processing batch 81/163\n",
      "2025-06-07 21:13:56 - INFO - Batch 81/163 - Loss: 0.3963 - Avg batch time: 1.38s\n",
      "2025-06-07 21:14:08 - INFO - Processing batch 91/163\n",
      "2025-06-07 21:14:10 - INFO - Batch 91/163 - Loss: 0.4867 - Avg batch time: 1.39s\n",
      "2025-06-07 21:14:22 - INFO - Processing batch 101/163\n",
      "2025-06-07 21:14:24 - INFO - Batch 101/163 - Loss: 0.4640 - Avg batch time: 1.39s\n",
      "2025-06-07 21:14:36 - INFO - Processing batch 111/163\n",
      "2025-06-07 21:14:38 - INFO - Batch 111/163 - Loss: 0.2965 - Avg batch time: 1.38s\n",
      "2025-06-07 21:14:50 - INFO - Processing batch 121/163\n",
      "2025-06-07 21:14:51 - INFO - Batch 121/163 - Loss: 0.3899 - Avg batch time: 1.38s\n",
      "2025-06-07 21:15:04 - INFO - Processing batch 131/163\n",
      "2025-06-07 21:15:05 - INFO - Batch 131/163 - Loss: 0.4507 - Avg batch time: 1.39s\n",
      "2025-06-07 21:15:18 - INFO - Processing batch 141/163\n",
      "2025-06-07 21:15:19 - INFO - Batch 141/163 - Loss: 0.3651 - Avg batch time: 1.39s\n",
      "2025-06-07 21:15:32 - INFO - Processing batch 151/163\n",
      "2025-06-07 21:15:33 - INFO - Batch 151/163 - Loss: 0.4668 - Avg batch time: 1.39s\n",
      "2025-06-07 21:15:45 - INFO - Processing batch 161/163\n",
      "2025-06-07 21:15:47 - INFO - Batch 161/163 - Loss: 0.3663 - Avg batch time: 1.38s\n",
      "2025-06-07 21:15:49 - INFO - \n",
      "Epoch 31 training completed in 227.47s\n",
      "2025-06-07 21:15:49 - INFO - Average training loss: 0.4129\n",
      "Epochs:  32%|| 32/100 [2:21:18<5:09:53, 273.44s/it, train_loss=0.4129, val_loss=0.3503, best_val_f1=0.6696, lr=6.25e-062025-06-07 21:16:35 - INFO - \n",
      "Epoch 32/100 - Training phase\n",
      "2025-06-07 21:16:37 - INFO - Processing batch 1/163\n",
      "2025-06-07 21:16:37 - INFO - Batch shapes - x: torch.Size([1216, 3000]), edge_index: torch.Size([2, 21888]), y: torch.Size([64, 1])\n",
      "2025-06-07 21:16:39 - INFO - Batch 1/163 - Loss: 0.5074 - Avg batch time: 1.40s\n",
      "2025-06-07 21:16:51 - INFO - Processing batch 11/163\n",
      "2025-06-07 21:16:52 - INFO - Batch 11/163 - Loss: 0.4759 - Avg batch time: 1.39s\n",
      "2025-06-07 21:17:05 - INFO - Processing batch 21/163\n",
      "2025-06-07 21:17:06 - INFO - Batch 21/163 - Loss: 0.4747 - Avg batch time: 1.38s\n",
      "2025-06-07 21:17:19 - INFO - Processing batch 31/163\n",
      "2025-06-07 21:17:20 - INFO - Batch 31/163 - Loss: 0.4577 - Avg batch time: 1.38s\n",
      "2025-06-07 21:17:33 - INFO - Processing batch 41/163\n",
      "2025-06-07 21:17:34 - INFO - Batch 41/163 - Loss: 0.3640 - Avg batch time: 1.39s\n",
      "2025-06-07 21:17:46 - INFO - Processing batch 51/163\n",
      "2025-06-07 21:17:48 - INFO - Batch 51/163 - Loss: 0.3923 - Avg batch time: 1.39s\n",
      "2025-06-07 21:18:00 - INFO - Processing batch 61/163\n",
      "2025-06-07 21:18:02 - INFO - Batch 61/163 - Loss: 0.5153 - Avg batch time: 1.39s\n",
      "2025-06-07 21:18:14 - INFO - Processing batch 71/163\n",
      "2025-06-07 21:18:16 - INFO - Batch 71/163 - Loss: 0.4565 - Avg batch time: 1.39s\n",
      "2025-06-07 21:18:28 - INFO - Processing batch 81/163\n",
      "2025-06-07 21:18:30 - INFO - Batch 81/163 - Loss: 0.3332 - Avg batch time: 1.39s\n",
      "2025-06-07 21:18:42 - INFO - Processing batch 91/163\n",
      "2025-06-07 21:18:43 - INFO - Batch 91/163 - Loss: 0.4007 - Avg batch time: 1.39s\n",
      "2025-06-07 21:18:56 - INFO - Processing batch 101/163\n",
      "2025-06-07 21:18:57 - INFO - Batch 101/163 - Loss: 0.3382 - Avg batch time: 1.39s\n",
      "2025-06-07 21:19:10 - INFO - Processing batch 111/163\n",
      "2025-06-07 21:19:11 - INFO - Batch 111/163 - Loss: 0.5029 - Avg batch time: 1.39s\n",
      "2025-06-07 21:19:24 - INFO - Processing batch 121/163\n",
      "2025-06-07 21:19:25 - INFO - Batch 121/163 - Loss: 0.4274 - Avg batch time: 1.39s\n",
      "2025-06-07 21:19:37 - INFO - Processing batch 131/163\n",
      "2025-06-07 21:19:39 - INFO - Batch 131/163 - Loss: 0.4300 - Avg batch time: 1.39s\n",
      "2025-06-07 21:19:51 - INFO - Processing batch 141/163\n",
      "2025-06-07 21:19:53 - INFO - Batch 141/163 - Loss: 0.3757 - Avg batch time: 1.38s\n",
      "2025-06-07 21:20:05 - INFO - Processing batch 151/163\n",
      "2025-06-07 21:20:07 - INFO - Batch 151/163 - Loss: 0.3830 - Avg batch time: 1.39s\n",
      "2025-06-07 21:20:19 - INFO - Processing batch 161/163\n",
      "2025-06-07 21:20:20 - INFO - Batch 161/163 - Loss: 0.4099 - Avg batch time: 1.38s\n",
      "2025-06-07 21:20:22 - INFO - \n",
      "Epoch 32 training completed in 227.64s\n",
      "2025-06-07 21:20:22 - INFO - Average training loss: 0.4252\n",
      "Epochs:  33%|| 33/100 [2:25:52<5:05:17, 273.39s/it, train_loss=0.4252, val_loss=0.3338, best_val_f1=0.6696, lr=6.25e-062025-06-07 21:21:08 - INFO - \n",
      "Epoch 33/100 - Training phase\n",
      "2025-06-07 21:21:10 - INFO - Processing batch 1/163\n",
      "2025-06-07 21:21:10 - INFO - Batch shapes - x: torch.Size([1216, 3000]), edge_index: torch.Size([2, 21888]), y: torch.Size([64, 1])\n",
      "2025-06-07 21:21:12 - INFO - Batch 1/163 - Loss: 0.3980 - Avg batch time: 1.40s\n",
      "2025-06-07 21:21:24 - INFO - Processing batch 11/163\n",
      "2025-06-07 21:21:26 - INFO - Batch 11/163 - Loss: 0.5948 - Avg batch time: 1.39s\n",
      "2025-06-07 21:21:38 - INFO - Processing batch 21/163\n",
      "2025-06-07 21:21:39 - INFO - Batch 21/163 - Loss: 0.3539 - Avg batch time: 1.38s\n",
      "2025-06-07 21:21:52 - INFO - Processing batch 31/163\n",
      "2025-06-07 21:21:53 - INFO - Batch 31/163 - Loss: 0.3935 - Avg batch time: 1.39s\n",
      "2025-06-07 21:22:06 - INFO - Processing batch 41/163\n",
      "2025-06-07 21:22:07 - INFO - Batch 41/163 - Loss: 0.4959 - Avg batch time: 1.39s\n",
      "2025-06-07 21:22:20 - INFO - Processing batch 51/163\n",
      "2025-06-07 21:22:21 - INFO - Batch 51/163 - Loss: 0.5491 - Avg batch time: 1.38s\n",
      "2025-06-07 21:22:34 - INFO - Processing batch 61/163\n",
      "2025-06-07 21:22:35 - INFO - Batch 61/163 - Loss: 0.4484 - Avg batch time: 1.38s\n",
      "2025-06-07 21:22:47 - INFO - Processing batch 71/163\n",
      "2025-06-07 21:22:49 - INFO - Batch 71/163 - Loss: 0.4592 - Avg batch time: 1.38s\n",
      "2025-06-07 21:23:01 - INFO - Processing batch 81/163\n",
      "2025-06-07 21:23:03 - INFO - Batch 81/163 - Loss: 0.4334 - Avg batch time: 1.39s\n",
      "2025-06-07 21:23:15 - INFO - Processing batch 91/163\n",
      "2025-06-07 21:23:16 - INFO - Batch 91/163 - Loss: 0.5479 - Avg batch time: 1.38s\n",
      "2025-06-07 21:23:29 - INFO - Processing batch 101/163\n",
      "2025-06-07 21:23:30 - INFO - Batch 101/163 - Loss: 0.3809 - Avg batch time: 1.39s\n",
      "2025-06-07 21:23:43 - INFO - Processing batch 111/163\n",
      "2025-06-07 21:23:44 - INFO - Batch 111/163 - Loss: 0.3727 - Avg batch time: 1.39s\n",
      "2025-06-07 21:23:57 - INFO - Processing batch 121/163\n",
      "2025-06-07 21:23:58 - INFO - Batch 121/163 - Loss: 0.3406 - Avg batch time: 1.39s\n",
      "2025-06-07 21:24:11 - INFO - Processing batch 131/163\n",
      "2025-06-07 21:24:12 - INFO - Batch 131/163 - Loss: 0.4498 - Avg batch time: 1.39s\n",
      "2025-06-07 21:24:24 - INFO - Processing batch 141/163\n",
      "2025-06-07 21:24:26 - INFO - Batch 141/163 - Loss: 0.3891 - Avg batch time: 1.39s\n",
      "2025-06-07 21:24:38 - INFO - Processing batch 151/163\n",
      "2025-06-07 21:24:40 - INFO - Batch 151/163 - Loss: 0.4601 - Avg batch time: 1.39s\n",
      "2025-06-07 21:24:52 - INFO - Processing batch 161/163\n",
      "2025-06-07 21:24:53 - INFO - Batch 161/163 - Loss: 0.3946 - Avg batch time: 1.38s\n",
      "2025-06-07 21:24:55 - INFO - \n",
      "Epoch 33 training completed in 227.50s\n",
      "2025-06-07 21:24:55 - INFO - Average training loss: 0.4119\n",
      "Epochs:  34%|| 34/100 [2:30:25<5:00:42, 273.38s/it, train_loss=0.4119, val_loss=0.3481, best_val_f1=0.6696, lr=6.25e-062025-06-07 21:25:41 - INFO - \n",
      "Epoch 34/100 - Training phase\n",
      "2025-06-07 21:25:44 - INFO - Processing batch 1/163\n",
      "2025-06-07 21:25:44 - INFO - Batch shapes - x: torch.Size([1216, 3000]), edge_index: torch.Size([2, 21888]), y: torch.Size([64, 1])\n",
      "2025-06-07 21:25:45 - INFO - Batch 1/163 - Loss: 0.5058 - Avg batch time: 1.42s\n",
      "2025-06-07 21:25:58 - INFO - Processing batch 11/163\n",
      "2025-06-07 21:25:59 - INFO - Batch 11/163 - Loss: 0.3588 - Avg batch time: 1.39s\n",
      "2025-06-07 21:26:11 - INFO - Processing batch 21/163\n",
      "2025-06-07 21:26:13 - INFO - Batch 21/163 - Loss: 0.2859 - Avg batch time: 1.38s\n",
      "2025-06-07 21:26:25 - INFO - Processing batch 31/163\n",
      "2025-06-07 21:26:27 - INFO - Batch 31/163 - Loss: 0.5617 - Avg batch time: 1.38s\n",
      "2025-06-07 21:26:39 - INFO - Processing batch 41/163\n",
      "2025-06-07 21:26:41 - INFO - Batch 41/163 - Loss: 0.4296 - Avg batch time: 1.39s\n",
      "2025-06-07 21:26:53 - INFO - Processing batch 51/163\n",
      "2025-06-07 21:26:54 - INFO - Batch 51/163 - Loss: 0.4332 - Avg batch time: 1.39s\n",
      "2025-06-07 21:27:07 - INFO - Processing batch 61/163\n",
      "2025-06-07 21:27:08 - INFO - Batch 61/163 - Loss: 0.4668 - Avg batch time: 1.38s\n",
      "2025-06-07 21:27:21 - INFO - Processing batch 71/163\n",
      "2025-06-07 21:27:22 - INFO - Batch 71/163 - Loss: 0.4761 - Avg batch time: 1.39s\n",
      "2025-06-07 21:27:35 - INFO - Processing batch 81/163\n",
      "2025-06-07 21:27:36 - INFO - Batch 81/163 - Loss: 0.4868 - Avg batch time: 1.39s\n",
      "2025-06-07 21:27:48 - INFO - Processing batch 91/163\n",
      "2025-06-07 21:27:50 - INFO - Batch 91/163 - Loss: 0.3797 - Avg batch time: 1.39s\n",
      "2025-06-07 21:28:02 - INFO - Processing batch 101/163\n",
      "2025-06-07 21:28:04 - INFO - Batch 101/163 - Loss: 0.3088 - Avg batch time: 1.39s\n",
      "2025-06-07 21:28:16 - INFO - Processing batch 111/163\n",
      "2025-06-07 21:28:18 - INFO - Batch 111/163 - Loss: 0.3866 - Avg batch time: 1.38s\n",
      "2025-06-07 21:28:30 - INFO - Processing batch 121/163\n",
      "2025-06-07 21:28:31 - INFO - Batch 121/163 - Loss: 0.4805 - Avg batch time: 1.39s\n",
      "2025-06-07 21:28:44 - INFO - Processing batch 131/163\n",
      "2025-06-07 21:28:45 - INFO - Batch 131/163 - Loss: 0.3813 - Avg batch time: 1.39s\n",
      "2025-06-07 21:28:58 - INFO - Processing batch 141/163\n",
      "2025-06-07 21:28:59 - INFO - Batch 141/163 - Loss: 0.4495 - Avg batch time: 1.39s\n",
      "2025-06-07 21:29:12 - INFO - Processing batch 151/163\n",
      "2025-06-07 21:29:13 - INFO - Batch 151/163 - Loss: 0.3709 - Avg batch time: 1.39s\n",
      "2025-06-07 21:29:25 - INFO - Processing batch 161/163\n",
      "2025-06-07 21:29:27 - INFO - Batch 161/163 - Loss: 0.4010 - Avg batch time: 1.38s\n",
      "2025-06-07 21:29:29 - INFO - \n",
      "Epoch 34 training completed in 227.54s\n",
      "2025-06-07 21:29:29 - INFO - Average training loss: 0.4144\n",
      "Epochs:  35%|| 35/100 [2:34:58<4:56:07, 273.34s/it, train_loss=0.4144, val_loss=0.3435, best_val_f1=0.6696, lr=6.25e-062025-06-07 21:30:15 - INFO - \n",
      "Epoch 35/100 - Training phase\n",
      "2025-06-07 21:30:17 - INFO - Processing batch 1/163\n",
      "2025-06-07 21:30:17 - INFO - Batch shapes - x: torch.Size([1216, 3000]), edge_index: torch.Size([2, 21888]), y: torch.Size([64, 1])\n",
      "2025-06-07 21:30:18 - INFO - Batch 1/163 - Loss: 0.3258 - Avg batch time: 1.40s\n",
      "2025-06-07 21:30:31 - INFO - Processing batch 11/163\n",
      "2025-06-07 21:30:32 - INFO - Batch 11/163 - Loss: 0.4889 - Avg batch time: 1.39s\n",
      "2025-06-07 21:30:45 - INFO - Processing batch 21/163\n",
      "Epochs:  35%|| 35/100 [2:35:29<4:57:16, 274.41s/it, train_loss=0.4144, val_loss=0.3435, best_val_f1=0.6696, lr=6.25e-06\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m     torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# train model\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m train_history, val_history \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwandb_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mepochs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpatience\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSAVE_PATH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_gnn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# hidden attribute\u001b[39;49;00m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtry_load_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_wandb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m     40\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/NeuroGraphNet/src/utils/train.py:272\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, criterion, optimizer, device, save_path, scheduler, monitor, patience, num_epochs, grad_clip, overwrite, use_gnn, use_oversampling, wandb_config, wandb_project, wandb_run_name, log_wandb, try_load_checkpoint)\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor GNN mode, batch_data must have \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_index\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;66;03m# cast y_targets to int64 (needed)\u001b[39;00m\n\u001b[0;32m--> 272\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurr_batch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mcurr_batch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mcurr_batch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;66;03m# unsqueeze y_targets to match the shape of the logits. used later!\u001b[39;00m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/venvs/neuro/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venvs/neuro/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/NeuroGraphNet/src/layers/cnn_lstm_gnn.py:112\u001b[0m, in \u001b[0;36mLSTM_GNN_Model.forward\u001b[0;34m(self, x, edge_index, batch_labels)\u001b[0m\n\u001b[1;32m    106\u001b[0m node_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchannel_encoder(x)\n\u001b[1;32m    108\u001b[0m \u001b[38;5;66;03m# Pass the extracted node features (embeddings) and the graph structure\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;66;03m# (edge_index and batch tensors) to the GCN.\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;66;03m# The `batch` tensor correctly maps the flattened `node_features` back\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;66;03m# to their respective graphs for aggregation within the GCN.\u001b[39;00m\n\u001b[0;32m--> 112\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgcn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;66;03m# return predictions logits\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m logits\n",
      "File \u001b[0;32m~/venvs/neuro/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venvs/neuro/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/NeuroGraphNet/src/layers/eeggcn.py:56\u001b[0m, in \u001b[0;36mEEGGCN.forward\u001b[0;34m(self, x, edge_index, batch)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_conv_layers \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_conv_layers): \u001b[38;5;66;03m# Iterate through all GCN layers\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv_layers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn_layers[i](x)\n\u001b[1;32m     58\u001b[0m         x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(x)\n",
      "File \u001b[0;32m~/venvs/neuro/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venvs/neuro/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/venvs/neuro/lib/python3.10/site-packages/torch_geometric/nn/conv/gcn_conv.py:241\u001b[0m, in \u001b[0;36mGCNConv.forward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m    239\u001b[0m cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_edge_index\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 241\u001b[0m     edge_index, edge_weight \u001b[38;5;241m=\u001b[39m \u001b[43mgcn_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# yapf: disable\u001b[39;49;00m\n\u001b[1;32m    242\u001b[0m \u001b[43m        \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_dim\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimproved\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_self_loops\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcached:\n\u001b[1;32m    245\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_edge_index \u001b[38;5;241m=\u001b[39m (edge_index, edge_weight)\n",
      "File \u001b[0;32m~/venvs/neuro/lib/python3.10/site-packages/torch_geometric/nn/conv/gcn_conv.py:99\u001b[0m, in \u001b[0;36mgcn_norm\u001b[0;34m(edge_index, edge_weight, num_nodes, improved, add_self_loops, flow, dtype)\u001b[0m\n\u001b[1;32m     96\u001b[0m num_nodes \u001b[38;5;241m=\u001b[39m maybe_num_nodes(edge_index, num_nodes)\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m add_self_loops:\n\u001b[0;32m---> 99\u001b[0m     edge_index, edge_weight \u001b[38;5;241m=\u001b[39m \u001b[43madd_remaining_self_loops\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m        \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_nodes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m edge_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    103\u001b[0m     edge_weight \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones((edge_index\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m), ), dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m    104\u001b[0m                              device\u001b[38;5;241m=\u001b[39medge_index\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m~/venvs/neuro/lib/python3.10/site-packages/torch_geometric/utils/loop.py:652\u001b[0m, in \u001b[0;36madd_remaining_self_loops\u001b[0;34m(edge_index, edge_attr, fill_value, num_nodes)\u001b[0m\n\u001b[1;32m    648\u001b[0m     is_undirected \u001b[38;5;241m=\u001b[39m edge_index\u001b[38;5;241m.\u001b[39mis_undirected\n\u001b[1;32m    650\u001b[0m edge_index \u001b[38;5;241m=\u001b[39m edge_index[:, mask]\n\u001b[0;32m--> 652\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_scripting\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(edge_index, EdgeIndex):\n\u001b[1;32m    653\u001b[0m     edge_index\u001b[38;5;241m.\u001b[39m_is_undirected \u001b[38;5;241m=\u001b[39m is_undirected\n\u001b[1;32m    655\u001b[0m edge_index \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([edge_index, loop_index], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/venvs/neuro/lib/python3.10/site-packages/torch/_jit_internal.py:103\u001b[0m, in \u001b[0;36mis_scripting\u001b[0;34m()\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m7\u001b[39m):\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28mglobals\u001b[39m()[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBroadcastingList\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m BroadcastingList1\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mis_scripting\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m    104\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;124;03m    Function that returns True when in compilation and False otherwise. This\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03m    is useful especially with the @unused decorator to leave code in your\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;124;03m                return unsupported_linear_op(x)\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%aimport\n",
    "from src.utils.train import train_model\n",
    "\n",
    "# select model to use\n",
    "model = model_generalizable_optimized\n",
    "\n",
    "model = model.to(device)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=config[\"learning_rate\"], weight_decay=config[\"weight_decay\"])\n",
    "# optimizer = Lion(model.parameters(), lr=config[\"learning_rate\"], weight_decay=config[\"weight_decay\"])\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=1e-4,\n",
    "    weight_decay=0.01,\n",
    "    betas=(0.9, 0.999)\n",
    ")\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "loss = nn.BCEWithLogitsLoss() # Not weighted as we use a balanced sampler!\n",
    "\n",
    "# empty cache in order to free up VRAM (if available)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# train model\n",
    "train_history, val_history = train_model(\n",
    "    wandb_config=None,\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    criterion=loss,\n",
    "    scheduler=scheduler,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    num_epochs=config[\"epochs\"],\n",
    "    patience=config[\"patience\"],\n",
    "    save_path=SAVE_PATH,\n",
    "    use_gnn=True,\n",
    "    # hidden attribute\n",
    "    try_load_checkpoint=True,\n",
    "    log_wandb=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0eb2d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch cuda clear cache\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63329a79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from src.utils.plot import plot_training_loss\n",
    "\n",
    "plot_training_loss(train_history[\"loss\"], val_history[\"loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293bb297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modules to reload:\n",
      "\n",
      "\n",
      "Modules to skip:\n",
      "\n",
      " Evaluating model. Loading model from: .checkpoints/lstm_gnn_generalizable_optimized.pt\n",
      "   - Loading checkpoint from: .checkpoints/lstm_gnn_generalizable_optimized.pt\n",
      "   - Detected full checkpoint dictionary.\n",
      "   - Model state successfully loaded.\n",
      " Performing inference on the test set...\n",
      "   Generated 3614 predictions for 3614 IDs.\n",
      " Saved submission (3614 rows)  .submissions/lstm_gnn_generalizable_optimized.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pqejgcvm_s001_t000_0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pqejgcvm_s001_t000_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pqejgcvm_s001_t000_10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pqejgcvm_s001_t000_11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pqejgcvm_s001_t000_12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3609</th>\n",
       "      <td>pqejgvej_s001_t000_95</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3610</th>\n",
       "      <td>pqejgvej_s001_t000_96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3611</th>\n",
       "      <td>pqejgvej_s001_t000_97</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3612</th>\n",
       "      <td>pqejgvej_s001_t000_98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3613</th>\n",
       "      <td>pqejgvej_s001_t000_99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3614 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id  label\n",
       "0      pqejgcvm_s001_t000_0      0\n",
       "1      pqejgcvm_s001_t000_1      0\n",
       "2     pqejgcvm_s001_t000_10      1\n",
       "3     pqejgcvm_s001_t000_11      1\n",
       "4     pqejgcvm_s001_t000_12      1\n",
       "...                     ...    ...\n",
       "3609  pqejgvej_s001_t000_95      0\n",
       "3610  pqejgvej_s001_t000_96      0\n",
       "3611  pqejgvej_s001_t000_97      0\n",
       "3612  pqejgvej_s001_t000_98      0\n",
       "3613  pqejgvej_s001_t000_99      0\n",
       "\n",
       "[3614 rows x 2 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%aimport\n",
    "from src.utils.train import evaluate_model\n",
    "\n",
    "evaluate_model(\n",
    "    model=model,\n",
    "    test_loader=te_loader,\n",
    "    device=device,\n",
    "    checkpoint_path=SAVE_PATH,\n",
    "    submission_path=SUBMISSION_ROOT / f\"{SAVE_PATH.stem}.csv\",\n",
    "    use_gnn=True,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
