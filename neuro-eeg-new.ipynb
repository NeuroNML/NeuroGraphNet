{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97b998b0",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torch_geometric.loader import DataLoader as GeoDataLoader\n",
    "from torch.utils.data import Subset, WeightedRandomSampler\n",
    "# from torch.utils.data import DataLoader\n",
    "from src.utils.seeder import seed_everything\n",
    "\n",
    "# set seaborn theme\n",
    "sns.set_theme()\n",
    "\n",
    "# create useful constants\n",
    "RANDOM_SEED = 42\n",
    "IS_SCITAS = True # set to True if running on SCITAS cluster\n",
    "LOCAL_DATA_ROOT = Path(\"./data\")\n",
    "DATA_ROOT = Path(\"/home/ogut/data\") if IS_SCITAS else LOCAL_DATA_ROOT\n",
    "CHECKPOINT_ROOT = Path(\"./.checkpoints\")\n",
    "SUBMISSION_ROOT = Path(\"./.submissions\")\n",
    "\n",
    "# create directories if they do not exist\n",
    "CHECKPOINT_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "SUBMISSION_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# set dataset root\n",
    "seed_everything(RANDOM_SEED)\n",
    "\n",
    "# setup torch device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d28586",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# import subprocess\n",
    "\n",
    "# # execute feature extraction script\n",
    "# process = None\n",
    "# try:\n",
    "#     process = subprocess.Popen([\"python3\", \"scripts/feature_extractor.py\"])\n",
    "#     process.wait()\n",
    "# except KeyboardInterrupt:\n",
    "#     print(\"Process interrupted, terminating...\")\n",
    "#     if process:\n",
    "#         process.terminate()\n",
    "#         process.wait()\n",
    "# except Exception as e:\n",
    "#     print(f\"Error occurred: {e}\")\n",
    "#     if process:\n",
    "#         process.terminate()\n",
    "#         process.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45999291",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# spacial distance matrix between sensors\n",
    "spatial_distance_file = LOCAL_DATA_ROOT / \"distances_3d.csv\"\n",
    "\n",
    "# training data\n",
    "train_dir = DATA_ROOT / \"train\"\n",
    "train_dir_metadata = train_dir / \"segments.parquet\"\n",
    "train_dataset_correlation_dir = LOCAL_DATA_ROOT / \"graph_dataset_correlation_train\"\n",
    "train_dataset_spatial_dir = LOCAL_DATA_ROOT / \"graph_dataset_spatial_train\"\n",
    "\n",
    "# test data\n",
    "test_dir = DATA_ROOT / \"test\"\n",
    "test_dir_metadata = test_dir / \"segments.parquet\"\n",
    "test_dataset_correlation_dir = LOCAL_DATA_ROOT / \"graph_dataset_correlation_test\"\n",
    "test_dataset_spatial_dir = LOCAL_DATA_ROOT / \"graph_dataset_spatial_test\"\n",
    "\n",
    "# additional features\n",
    "extracted_features_dir = LOCAL_DATA_ROOT / \"extracted_features\"\n",
    "embeddings_dir =  LOCAL_DATA_ROOT / \"embeddings\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83d93851",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from src.utils.index import ensure_eeg_multiindex \n",
    "\n",
    "# Load clips from datasets\n",
    "clips_tr = pd.read_parquet(train_dir_metadata)\n",
    "clips_tr = ensure_eeg_multiindex(clips_tr)\n",
    "clips_tr['id'] = clips_tr.index.map(lambda x: '_'.join(str(i) for i in x))\n",
    "assert clips_tr.id.nunique() == len(clips_tr), \"There are duplicate IDs\"\n",
    "clips_tr = clips_tr[~clips_tr.label.isna()].reset_index()\n",
    "\n",
    "# Load clips from datasets\n",
    "clips_te = pd.read_parquet(test_dir_metadata)\n",
    "clips_te = ensure_eeg_multiindex(clips_te)\n",
    "clips_te['id'] = clips_te.index.map(lambda x: '_'.join(str(i) for i in x))\n",
    "assert clips_te.id.nunique() == len(clips_te), \"There are duplicate IDs\"\n",
    "clips_te = clips_te.reset_index()\n",
    "\n",
    "# sort in order to maintain the same submission order\n",
    "clips_te = clips_te.sort_values(by=\"id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903ea225",
   "metadata": {},
   "source": [
    "## Create + load spatial graph datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d983da8",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-08 17:19:00 - INFO - Initializing GraphEEGDataset...\n",
      "2025-06-08 17:19:00 - INFO - Dataset parameters:\n",
      "2025-06-08 17:19:00 - INFO -   - Root directory: data/graph_dataset_spatial_train\n",
      "2025-06-08 17:19:00 - INFO -   - Edge strategy: spatial\n",
      "2025-06-08 17:19:00 - INFO -   - Top-k neighbors: None\n",
      "2025-06-08 17:19:00 - INFO -   - Correlation threshold: 0.7\n",
      "2025-06-08 17:19:00 - INFO -   - Force reprocess: False\n",
      "2025-06-08 17:19:00 - INFO -   - Bandpass frequencies: (0.5, 50)\n",
      "2025-06-08 17:19:00 - INFO -   - Segment length: 3000\n",
      "2025-06-08 17:19:00 - INFO -   - Apply filtering: True\n",
      "2025-06-08 17:19:00 - INFO -   - Apply rereferencing: True\n",
      "2025-06-08 17:19:00 - INFO -   - Apply normalization: True\n",
      "2025-06-08 17:19:00 - INFO - Dataset parameters:\n",
      "2025-06-08 17:19:00 - INFO -   - Root directory: data/graph_dataset_spatial_train\n",
      "2025-06-08 17:19:00 - INFO -   - Edge strategy: spatial\n",
      "2025-06-08 17:19:00 - INFO -   - Top-k neighbors: None\n",
      "2025-06-08 17:19:00 - INFO -   - Correlation threshold: 0.7\n",
      "2025-06-08 17:19:00 - INFO -   - Force reprocess: False\n",
      "2025-06-08 17:19:00 - INFO -   - Bandpass frequencies: (0.5, 50)\n",
      "2025-06-08 17:19:00 - INFO -   - Segment length: 3000\n",
      "2025-06-08 17:19:00 - INFO -   - Apply filtering: True\n",
      "2025-06-08 17:19:00 - INFO -   - Apply rereferencing: True\n",
      "2025-06-08 17:19:00 - INFO -   - Apply normalization: True\n",
      "2025-06-08 17:19:00 - INFO -   - Sampling rate: 250\n",
      "2025-06-08 17:19:00 - INFO -   - Test mode: False\n",
      "2025-06-08 17:19:00 - INFO -   - Extract graph features: True\n",
      "2025-06-08 17:19:00 - INFO - Initializing graph feature extractor...\n",
      "2025-06-08 17:19:00,229 - src.utils.graph_features - INFO - GraphFeatureExtractor initialized with features: ['degree', 'clustering', 'centrality', 'connectivity', 'path_length', 'efficiency', 'assortativity', 'modularity', 'laplacian_spectrum', 'k_core']\n",
      "2025-06-08 17:19:00 - INFO - GraphFeatureExtractor initialized with features: ['degree', 'clustering', 'centrality', 'connectivity', 'path_length', 'efficiency', 'assortativity', 'modularity', 'laplacian_spectrum', 'k_core']\n",
      "2025-06-08 17:19:00 - INFO - Graph feature types: ['degree', 'clustering', 'centrality', 'connectivity', 'path_length', 'efficiency', 'assortativity', 'modularity', 'laplacian_spectrum', 'k_core']\n",
      "2025-06-08 17:19:00 - INFO - Number of EEG channels: 19\n",
      "2025-06-08 17:19:00 - INFO - Setting up signal filters...\n",
      "2025-06-08 17:19:00 - INFO - Loading spatial distances from data/distances_3d.csv\n",
      "2025-06-08 17:19:00 - INFO - Loading spatial distances from data/distances_3d.csv\n",
      "2025-06-08 17:19:00 - INFO - Loaded 361 spatial distances in 0.01s\n",
      "2025-06-08 17:19:00 - INFO -   - Sampling rate: 250\n",
      "2025-06-08 17:19:00 - INFO -   - Test mode: False\n",
      "2025-06-08 17:19:00 - INFO -   - Extract graph features: True\n",
      "2025-06-08 17:19:00 - INFO - Initializing graph feature extractor...\n",
      "2025-06-08 17:19:00,229 - src.utils.graph_features - INFO - GraphFeatureExtractor initialized with features: ['degree', 'clustering', 'centrality', 'connectivity', 'path_length', 'efficiency', 'assortativity', 'modularity', 'laplacian_spectrum', 'k_core']\n",
      "2025-06-08 17:19:00 - INFO - GraphFeatureExtractor initialized with features: ['degree', 'clustering', 'centrality', 'connectivity', 'path_length', 'efficiency', 'assortativity', 'modularity', 'laplacian_spectrum', 'k_core']\n",
      "2025-06-08 17:19:00 - INFO - Graph feature types: ['degree', 'clustering', 'centrality', 'connectivity', 'path_length', 'efficiency', 'assortativity', 'modularity', 'laplacian_spectrum', 'k_core']\n",
      "2025-06-08 17:19:00 - INFO - Number of EEG channels: 19\n",
      "2025-06-08 17:19:00 - INFO - Setting up signal filters...\n",
      "2025-06-08 17:19:00 - INFO - Loading spatial distances from data/distances_3d.csv\n",
      "2025-06-08 17:19:00 - INFO - Loading spatial distances from data/distances_3d.csv\n",
      "2025-06-08 17:19:00 - INFO - Loaded 361 spatial distances in 0.01s\n",
      "2025-06-08 17:19:00 - INFO - Loaded 361 spatial distance pairs\n",
      "2025-06-08 17:19:00 - INFO - Loaded 361 spatial distance pairs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modules to reload:\n",
      "\n",
      "\n",
      "Modules to skip:\n",
      "\n",
      "Length of train_dataset: 12993\n",
      " Eliminated IDs: []\n"
     ]
    }
   ],
   "source": [
    "%aimport\n",
    "from src.data.dataset_graph import GraphEEGDataset\n",
    "\n",
    "# dataset settings\n",
    "low_bandpass_frequency = 0.5\n",
    "high_bandpass_frequency = 50\n",
    "\n",
    "# additional settings\n",
    "oversampling_power = 1.0\n",
    "\n",
    "# load training dataset\n",
    "dataset_spatial_tr = GraphEEGDataset(\n",
    "    root=train_dataset_spatial_dir,\n",
    "    clips=clips_tr,\n",
    "    signal_folder=train_dir,\n",
    "    extracted_features_dir=extracted_features_dir,\n",
    "    use_selected_features=False,\n",
    "    embeddings_dir=embeddings_dir,\n",
    "    use_embeddings=False,\n",
    "    edge_strategy=\"spatial\",\n",
    "    spatial_distance_file=(\n",
    "        spatial_distance_file\n",
    "    ),\n",
    "    top_k=None,\n",
    "    force_reprocess=False,\n",
    "    bandpass_frequencies=(\n",
    "        low_bandpass_frequency,\n",
    "        high_bandpass_frequency,\n",
    "    ),\n",
    "    segment_length=3000,\n",
    "    apply_filtering=True,\n",
    "    apply_rereferencing=True,\n",
    "    apply_normalization=True,\n",
    "    sampling_rate=250,\n",
    "    # extract graph features\n",
    "    extract_graph_features=True,\n",
    "    graph_feature_types=None # collect all graph features\n",
    ")\n",
    "\n",
    "# Check the length of the dataset\n",
    "print(f\"Length of train_dataset: {len(dataset_spatial_tr)}\")\n",
    "print(f' Eliminated IDs: {dataset_spatial_tr.ids_to_eliminate}')\n",
    "clips_spatial_tr = clips_tr[~clips_tr.index.isin(dataset_spatial_tr.ids_to_eliminate)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11824a6",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-08 17:19:00 - INFO - Initializing GraphEEGDataset...\n",
      "2025-06-08 17:19:00 - INFO - Dataset parameters:\n",
      "2025-06-08 17:19:00 - INFO -   - Root directory: data/graph_dataset_correlation_test\n",
      "2025-06-08 17:19:00 - INFO -   - Edge strategy: spatial\n",
      "2025-06-08 17:19:00 - INFO -   - Top-k neighbors: None\n",
      "2025-06-08 17:19:00 - INFO -   - Correlation threshold: 0.7\n",
      "2025-06-08 17:19:00 - INFO -   - Force reprocess: False\n",
      "2025-06-08 17:19:00 - INFO -   - Bandpass frequencies: (0.5, 50)\n",
      "2025-06-08 17:19:00 - INFO -   - Segment length: 3000\n",
      "2025-06-08 17:19:00 - INFO -   - Apply filtering: True\n",
      "2025-06-08 17:19:00 - INFO -   - Apply rereferencing: True\n",
      "2025-06-08 17:19:00 - INFO -   - Apply normalization: True\n",
      "2025-06-08 17:19:00 - INFO -   - Sampling rate: 250\n",
      "2025-06-08 17:19:00 - INFO -   - Test mode: True\n",
      "2025-06-08 17:19:00 - INFO -   - Extract graph features: True\n",
      "2025-06-08 17:19:00 - INFO - Initializing graph feature extractor...\n",
      "2025-06-08 17:19:00,319 - src.utils.graph_features - INFO - GraphFeatureExtractor initialized with features: ['degree', 'clustering', 'centrality', 'connectivity', 'path_length', 'efficiency', 'assortativity', 'modularity', 'laplacian_spectrum', 'k_core']\n",
      "2025-06-08 17:19:00 - INFO - GraphFeatureExtractor initialized with features: ['degree', 'clustering', 'centrality', 'connectivity', 'path_length', 'efficiency', 'assortativity', 'modularity', 'laplacian_spectrum', 'k_core']\n",
      "2025-06-08 17:19:00 - INFO - Dataset parameters:\n",
      "2025-06-08 17:19:00 - INFO -   - Root directory: data/graph_dataset_correlation_test\n",
      "2025-06-08 17:19:00 - INFO -   - Edge strategy: spatial\n",
      "2025-06-08 17:19:00 - INFO -   - Top-k neighbors: None\n",
      "2025-06-08 17:19:00 - INFO -   - Correlation threshold: 0.7\n",
      "2025-06-08 17:19:00 - INFO -   - Force reprocess: False\n",
      "2025-06-08 17:19:00 - INFO -   - Bandpass frequencies: (0.5, 50)\n",
      "2025-06-08 17:19:00 - INFO -   - Segment length: 3000\n",
      "2025-06-08 17:19:00 - INFO -   - Apply filtering: True\n",
      "2025-06-08 17:19:00 - INFO -   - Apply rereferencing: True\n",
      "2025-06-08 17:19:00 - INFO -   - Apply normalization: True\n",
      "2025-06-08 17:19:00 - INFO -   - Sampling rate: 250\n",
      "2025-06-08 17:19:00 - INFO -   - Test mode: True\n",
      "2025-06-08 17:19:00 - INFO -   - Extract graph features: True\n",
      "2025-06-08 17:19:00 - INFO - Initializing graph feature extractor...\n",
      "2025-06-08 17:19:00,319 - src.utils.graph_features - INFO - GraphFeatureExtractor initialized with features: ['degree', 'clustering', 'centrality', 'connectivity', 'path_length', 'efficiency', 'assortativity', 'modularity', 'laplacian_spectrum', 'k_core']\n",
      "2025-06-08 17:19:00 - INFO - GraphFeatureExtractor initialized with features: ['degree', 'clustering', 'centrality', 'connectivity', 'path_length', 'efficiency', 'assortativity', 'modularity', 'laplacian_spectrum', 'k_core']\n",
      "2025-06-08 17:19:00 - INFO - Graph feature types: ['degree', 'clustering', 'centrality', 'connectivity', 'path_length', 'efficiency', 'assortativity', 'modularity', 'laplacian_spectrum', 'k_core']\n",
      "2025-06-08 17:19:00 - INFO - Number of EEG channels: 19\n",
      "2025-06-08 17:19:00 - INFO - Setting up signal filters...\n",
      "2025-06-08 17:19:00 - INFO - Loading spatial distances from data/distances_3d.csv\n",
      "2025-06-08 17:19:00 - INFO - Loading spatial distances from data/distances_3d.csv\n",
      "2025-06-08 17:19:00 - INFO - Loaded 361 spatial distances in 0.01s\n",
      "2025-06-08 17:19:00 - INFO - Loaded 361 spatial distance pairs\n",
      "2025-06-08 17:19:00 - INFO - Graph feature types: ['degree', 'clustering', 'centrality', 'connectivity', 'path_length', 'efficiency', 'assortativity', 'modularity', 'laplacian_spectrum', 'k_core']\n",
      "2025-06-08 17:19:00 - INFO - Number of EEG channels: 19\n",
      "2025-06-08 17:19:00 - INFO - Setting up signal filters...\n",
      "2025-06-08 17:19:00 - INFO - Loading spatial distances from data/distances_3d.csv\n",
      "2025-06-08 17:19:00 - INFO - Loading spatial distances from data/distances_3d.csv\n",
      "2025-06-08 17:19:00 - INFO - Loaded 361 spatial distances in 0.01s\n",
      "2025-06-08 17:19:00 - INFO - Loaded 361 spatial distance pairs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modules to reload:\n",
      "\n",
      "\n",
      "Modules to skip:\n",
      "\n",
      "Length of test_dataset: 3612\n",
      " Eliminated IDs:[]\n"
     ]
    }
   ],
   "source": [
    "%aimport\n",
    "from src.data.dataset_graph import GraphEEGDataset\n",
    "\n",
    "# load training dataset\n",
    "dataset_corr_te = GraphEEGDataset(\n",
    "    root=test_dataset_correlation_dir,\n",
    "    clips=clips_te,\n",
    "    signal_folder=test_dir,\n",
    "    extracted_features_dir=extracted_features_dir,\n",
    "    use_selected_features=False,\n",
    "    embeddings_dir=embeddings_dir,\n",
    "    use_embeddings=False,\n",
    "    edge_strategy=\"spatial\",\n",
    "    spatial_distance_file=(\n",
    "        spatial_distance_file\n",
    "    ),\n",
    "    top_k=None,\n",
    "    force_reprocess=False,\n",
    "    bandpass_frequencies=(\n",
    "        low_bandpass_frequency,\n",
    "        high_bandpass_frequency,\n",
    "    ),\n",
    "    segment_length=3000,\n",
    "    apply_filtering=True,\n",
    "    apply_rereferencing=True,\n",
    "    apply_normalization=True,\n",
    "    sampling_rate=250,\n",
    "    # extract graph features\n",
    "    is_test=True, # NOTE: needed to let the dataset know that is okay to now have labels!\n",
    "    extract_graph_features=True,\n",
    "    graph_feature_types=None # collect all graph features\n",
    ")\n",
    "\n",
    "# Check the length of the dataset\n",
    "print(f\"Length of test_dataset: {len(dataset_corr_te)}\")\n",
    "print(f' Eliminated IDs:{dataset_corr_te.ids_to_eliminate}')\n",
    "clips_spatial_te = clips_te[~clips_te.index.isin(dataset_corr_te.ids_to_eliminate)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac9eebb",
   "metadata": {},
   "source": [
    "## Create + load correlation-based graph datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd45b398",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-08 17:19:00 - INFO - Initializing GraphEEGDataset...\n",
      "2025-06-08 17:19:00 - INFO - Dataset parameters:\n",
      "2025-06-08 17:19:00 - INFO -   - Root directory: data/graph_dataset_correlation_train\n",
      "2025-06-08 17:19:00 - INFO -   - Edge strategy: correlation\n",
      "2025-06-08 17:19:00 - INFO -   - Top-k neighbors: 5\n",
      "2025-06-08 17:19:00 - INFO -   - Correlation threshold: 0.7\n",
      "2025-06-08 17:19:00 - INFO -   - Force reprocess: False\n",
      "2025-06-08 17:19:00 - INFO -   - Bandpass frequencies: (0.5, 50)\n",
      "2025-06-08 17:19:00 - INFO -   - Segment length: 3000\n",
      "2025-06-08 17:19:00 - INFO -   - Apply filtering: True\n",
      "2025-06-08 17:19:00 - INFO -   - Apply rereferencing: True\n",
      "2025-06-08 17:19:00 - INFO -   - Apply normalization: True\n",
      "2025-06-08 17:19:00 - INFO -   - Sampling rate: 250\n",
      "2025-06-08 17:19:00 - INFO -   - Test mode: False\n",
      "2025-06-08 17:19:00 - INFO -   - Extract graph features: True\n",
      "2025-06-08 17:19:00 - INFO - Initializing graph feature extractor...\n",
      "2025-06-08 17:19:00,400 - src.utils.graph_features - INFO - GraphFeatureExtractor initialized with features: ['degree', 'clustering', 'centrality', 'connectivity', 'path_length', 'efficiency', 'assortativity', 'modularity', 'laplacian_spectrum', 'k_core']\n",
      "2025-06-08 17:19:00 - INFO - GraphFeatureExtractor initialized with features: ['degree', 'clustering', 'centrality', 'connectivity', 'path_length', 'efficiency', 'assortativity', 'modularity', 'laplacian_spectrum', 'k_core']\n",
      "2025-06-08 17:19:00 - INFO - Graph feature types: ['degree', 'clustering', 'centrality', 'connectivity', 'path_length', 'efficiency', 'assortativity', 'modularity', 'laplacian_spectrum', 'k_core']\n",
      "2025-06-08 17:19:00 - INFO - Number of EEG channels: 19\n",
      "2025-06-08 17:19:00 - INFO - Dataset parameters:\n",
      "2025-06-08 17:19:00 - INFO -   - Root directory: data/graph_dataset_correlation_train\n",
      "2025-06-08 17:19:00 - INFO -   - Edge strategy: correlation\n",
      "2025-06-08 17:19:00 - INFO -   - Top-k neighbors: 5\n",
      "2025-06-08 17:19:00 - INFO -   - Correlation threshold: 0.7\n",
      "2025-06-08 17:19:00 - INFO -   - Force reprocess: False\n",
      "2025-06-08 17:19:00 - INFO -   - Bandpass frequencies: (0.5, 50)\n",
      "2025-06-08 17:19:00 - INFO -   - Segment length: 3000\n",
      "2025-06-08 17:19:00 - INFO -   - Apply filtering: True\n",
      "2025-06-08 17:19:00 - INFO -   - Apply rereferencing: True\n",
      "2025-06-08 17:19:00 - INFO -   - Apply normalization: True\n",
      "2025-06-08 17:19:00 - INFO -   - Sampling rate: 250\n",
      "2025-06-08 17:19:00 - INFO -   - Test mode: False\n",
      "2025-06-08 17:19:00 - INFO -   - Extract graph features: True\n",
      "2025-06-08 17:19:00 - INFO - Initializing graph feature extractor...\n",
      "2025-06-08 17:19:00,400 - src.utils.graph_features - INFO - GraphFeatureExtractor initialized with features: ['degree', 'clustering', 'centrality', 'connectivity', 'path_length', 'efficiency', 'assortativity', 'modularity', 'laplacian_spectrum', 'k_core']\n",
      "2025-06-08 17:19:00 - INFO - GraphFeatureExtractor initialized with features: ['degree', 'clustering', 'centrality', 'connectivity', 'path_length', 'efficiency', 'assortativity', 'modularity', 'laplacian_spectrum', 'k_core']\n",
      "2025-06-08 17:19:00 - INFO - Graph feature types: ['degree', 'clustering', 'centrality', 'connectivity', 'path_length', 'efficiency', 'assortativity', 'modularity', 'laplacian_spectrum', 'k_core']\n",
      "2025-06-08 17:19:00 - INFO - Number of EEG channels: 19\n",
      "2025-06-08 17:19:00 - INFO - Setting up signal filters...\n",
      "2025-06-08 17:19:00 - INFO - Setting up signal filters...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modules to reload:\n",
      "\n",
      "\n",
      "Modules to skip:\n",
      "\n",
      "Length of train_dataset: 12986\n",
      " Eliminated IDs: []\n"
     ]
    }
   ],
   "source": [
    "%aimport\n",
    "from src.data.dataset_graph import GraphEEGDataset\n",
    "\n",
    "# dataset settings\n",
    "top_k = 5\n",
    "low_bandpass_frequency = 0.5\n",
    "high_bandpass_frequency = 50\n",
    "\n",
    "# additional settings\n",
    "oversampling_power = 1.0\n",
    "\n",
    "# load training dataset\n",
    "dataset_corr_tr = GraphEEGDataset(\n",
    "    root=train_dataset_correlation_dir,\n",
    "    clips=clips_tr,\n",
    "    signal_folder=train_dir,\n",
    "    extracted_features_dir=extracted_features_dir,\n",
    "    use_selected_features=False,\n",
    "    embeddings_dir=embeddings_dir,\n",
    "    use_embeddings=False,\n",
    "    edge_strategy=\"correlation\",\n",
    "    spatial_distance_file=None,\n",
    "    top_k=top_k,\n",
    "    force_reprocess=False,\n",
    "    bandpass_frequencies=(\n",
    "        low_bandpass_frequency,\n",
    "        high_bandpass_frequency,\n",
    "    ),\n",
    "    segment_length=3000,\n",
    "    apply_filtering=True,\n",
    "    apply_rereferencing=True,\n",
    "    apply_normalization=True,\n",
    "    sampling_rate=250,\n",
    "    # extract graph features\n",
    "    extract_graph_features=True,\n",
    "    graph_feature_types=None # collect all graph features\n",
    ")\n",
    "\n",
    "# Check the length of the dataset\n",
    "print(f\"Length of train_dataset: {len(dataset_corr_tr)}\")\n",
    "print(f' Eliminated IDs: {dataset_corr_tr.ids_to_eliminate}')\n",
    "clips_corr_tr = clips_tr[~clips_tr.index.isin(dataset_corr_tr.ids_to_eliminate)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0198413",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-08 17:19:00 - INFO - Initializing GraphEEGDataset...\n",
      "2025-06-08 17:19:00 - INFO - Dataset parameters:\n",
      "2025-06-08 17:19:00 - INFO -   - Root directory: data/graph_dataset_correlation_test\n",
      "2025-06-08 17:19:00 - INFO -   - Edge strategy: correlation\n",
      "2025-06-08 17:19:00 - INFO -   - Top-k neighbors: 5\n",
      "2025-06-08 17:19:00 - INFO -   - Correlation threshold: 0.7\n",
      "2025-06-08 17:19:00 - INFO -   - Force reprocess: False\n",
      "2025-06-08 17:19:00 - INFO -   - Bandpass frequencies: (0.5, 50)\n",
      "2025-06-08 17:19:00 - INFO -   - Segment length: 3000\n",
      "2025-06-08 17:19:00 - INFO -   - Apply filtering: True\n",
      "2025-06-08 17:19:00 - INFO -   - Apply rereferencing: True\n",
      "2025-06-08 17:19:00 - INFO -   - Apply normalization: True\n",
      "2025-06-08 17:19:00 - INFO -   - Sampling rate: 250\n",
      "2025-06-08 17:19:00 - INFO -   - Test mode: True\n",
      "2025-06-08 17:19:00 - INFO -   - Extract graph features: True\n",
      "2025-06-08 17:19:00 - INFO - Initializing graph feature extractor...\n",
      "2025-06-08 17:19:00,457 - src.utils.graph_features - INFO - GraphFeatureExtractor initialized with features: ['degree', 'clustering', 'centrality', 'connectivity', 'path_length', 'efficiency', 'assortativity', 'modularity', 'laplacian_spectrum', 'k_core']\n",
      "2025-06-08 17:19:00 - INFO - GraphFeatureExtractor initialized with features: ['degree', 'clustering', 'centrality', 'connectivity', 'path_length', 'efficiency', 'assortativity', 'modularity', 'laplacian_spectrum', 'k_core']\n",
      "2025-06-08 17:19:00 - INFO - Graph feature types: ['degree', 'clustering', 'centrality', 'connectivity', 'path_length', 'efficiency', 'assortativity', 'modularity', 'laplacian_spectrum', 'k_core']\n",
      "2025-06-08 17:19:00 - INFO - Number of EEG channels: 19\n",
      "2025-06-08 17:19:00 - INFO - Dataset parameters:\n",
      "2025-06-08 17:19:00 - INFO -   - Root directory: data/graph_dataset_correlation_test\n",
      "2025-06-08 17:19:00 - INFO -   - Edge strategy: correlation\n",
      "2025-06-08 17:19:00 - INFO -   - Top-k neighbors: 5\n",
      "2025-06-08 17:19:00 - INFO -   - Correlation threshold: 0.7\n",
      "2025-06-08 17:19:00 - INFO -   - Force reprocess: False\n",
      "2025-06-08 17:19:00 - INFO -   - Bandpass frequencies: (0.5, 50)\n",
      "2025-06-08 17:19:00 - INFO -   - Segment length: 3000\n",
      "2025-06-08 17:19:00 - INFO -   - Apply filtering: True\n",
      "2025-06-08 17:19:00 - INFO -   - Apply rereferencing: True\n",
      "2025-06-08 17:19:00 - INFO -   - Apply normalization: True\n",
      "2025-06-08 17:19:00 - INFO -   - Sampling rate: 250\n",
      "2025-06-08 17:19:00 - INFO -   - Test mode: True\n",
      "2025-06-08 17:19:00 - INFO -   - Extract graph features: True\n",
      "2025-06-08 17:19:00 - INFO - Initializing graph feature extractor...\n",
      "2025-06-08 17:19:00,457 - src.utils.graph_features - INFO - GraphFeatureExtractor initialized with features: ['degree', 'clustering', 'centrality', 'connectivity', 'path_length', 'efficiency', 'assortativity', 'modularity', 'laplacian_spectrum', 'k_core']\n",
      "2025-06-08 17:19:00 - INFO - GraphFeatureExtractor initialized with features: ['degree', 'clustering', 'centrality', 'connectivity', 'path_length', 'efficiency', 'assortativity', 'modularity', 'laplacian_spectrum', 'k_core']\n",
      "2025-06-08 17:19:00 - INFO - Graph feature types: ['degree', 'clustering', 'centrality', 'connectivity', 'path_length', 'efficiency', 'assortativity', 'modularity', 'laplacian_spectrum', 'k_core']\n",
      "2025-06-08 17:19:00 - INFO - Number of EEG channels: 19\n",
      "2025-06-08 17:19:00 - INFO - Setting up signal filters...\n",
      "2025-06-08 17:19:00 - INFO - Setting up signal filters...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modules to reload:\n",
      "\n",
      "\n",
      "Modules to skip:\n",
      "\n",
      "Length of test_dataset: 3612\n",
      " Eliminated IDs:[]\n"
     ]
    }
   ],
   "source": [
    "%aimport\n",
    "from src.data.dataset_graph import GraphEEGDataset\n",
    "\n",
    "# load training dataset\n",
    "dataset_corr_te = GraphEEGDataset(\n",
    "    root=test_dataset_correlation_dir,\n",
    "    clips=clips_te,\n",
    "    signal_folder=test_dir,\n",
    "    extracted_features_dir=extracted_features_dir,\n",
    "    use_selected_features=False,\n",
    "    embeddings_dir=embeddings_dir,\n",
    "    use_embeddings=False,\n",
    "    edge_strategy=\"correlation\",\n",
    "    spatial_distance_file=None,\n",
    "    top_k=top_k,\n",
    "    force_reprocess=False,\n",
    "    bandpass_frequencies=(\n",
    "        low_bandpass_frequency,\n",
    "        high_bandpass_frequency,\n",
    "    ),\n",
    "    segment_length=3000,\n",
    "    apply_filtering=True,\n",
    "    apply_rereferencing=True,\n",
    "    apply_normalization=True,\n",
    "    sampling_rate=250,\n",
    "    # extract graph features\n",
    "    is_test=True, # NOTE: needed to let the dataset know that is okay to now have labels!\n",
    "    extract_graph_features=True,\n",
    "    graph_feature_types=None # collect all graph features\n",
    ")\n",
    "\n",
    "# Check the length of the dataset\n",
    "print(f\"Length of test_dataset: {len(dataset_corr_te)}\")\n",
    "print(f' Eliminated IDs:{dataset_corr_te.ids_to_eliminate}')\n",
    "clips_corr_te = clips_te[~clips_te.index.isin(dataset_corr_te.ids_to_eliminate)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db2758d",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# remove the original clips from memory\n",
    "del clips_tr, clips_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d80bce",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SPATIAL DATASET SPLITTING ===\n",
      "Spatial dataset - Total: 12993, Train: 10394, Val: 2599\n",
      "Spatial dataset labels distribution before split:\n",
      "[17:23:13] Train labels: 0 -> 8374, 1 -> 2020\n",
      "[17:23:13] Val labels:   0 -> 2102, 1 -> 497\n",
      "\n",
      "Spatial dataset - Class weights: [0.00011942 0.00049505]\n",
      "Spatial dataset - Class distribution in train: [8374 2020]\n",
      "\n",
      "=== CORRELATION DATASET SPLITTING ===\n",
      "Correlation dataset - Total: 12986, Train: 10388, Val: 2598\n",
      "Correlation dataset labels distribution before split:\n",
      "[17:23:13] Train labels: 0 -> 8377, 1 -> 2011\n",
      "[17:23:13] Val labels:   0 -> 2098, 1 -> 500\n",
      "\n",
      "Correlation dataset - Class weights: [0.00011937 0.00049727]\n",
      "Correlation dataset - Class distribution in train: [8377 2011]\n",
      "\n",
      "=== SUMMARY ===\n",
      "Spatial: 10394 train, 2599 val\n",
      "Correlation: 10388 train, 2598 val\n",
      "\n",
      "=== DATA LOADERS CREATED ===\n",
      "Spatial - Train: 162 batches, Val: 41 batches, Test: 57 batches\n",
      "Correlation - Train: 162 batches, Val: 41 batches, Test: 203 batches\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from src.utils.general_funcs import labels_stats\n",
    "\n",
    "# Split settings\n",
    "TRAIN_RATIO = 0.8\n",
    "oversampling_power = 1.0\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "print(\"=== SPATIAL DATASET SPLITTING ===\")\n",
    "# Get total samples and split sizes for spatial dataset\n",
    "total_samples_spatial = len(dataset_spatial_tr)\n",
    "train_size_spatial = int(TRAIN_RATIO * total_samples_spatial)\n",
    "val_size_spatial = total_samples_spatial - train_size_spatial\n",
    "\n",
    "print(f\"Spatial dataset - Total: {total_samples_spatial}, Train: {train_size_spatial}, Val: {val_size_spatial}\")\n",
    "\n",
    "# Get labels for spatial dataset split\n",
    "y_spatial = clips_spatial_tr[\"label\"].values\n",
    "\n",
    "# Create initial train/val split using random permutation\n",
    "indices_spatial = torch.randperm(total_samples_spatial)\n",
    "train_indices_spatial = indices_spatial[:train_size_spatial].numpy()\n",
    "val_indices_spatial = indices_spatial[train_size_spatial:].numpy()\n",
    "\n",
    "print('Spatial dataset labels distribution before split:')\n",
    "labels_stats(y_spatial, train_indices_spatial, val_indices_spatial)\n",
    "\n",
    "# Create train and val datasets for spatial\n",
    "train_dataset_spatial = Subset(dataset_spatial_tr, train_indices_spatial)\n",
    "val_dataset_spatial = Subset(dataset_spatial_tr, val_indices_spatial)\n",
    "\n",
    "# Compute sample weights for oversampling - spatial\n",
    "train_labels_spatial = [clips_spatial_tr.iloc[i][\"label\"] for i in train_indices_spatial]\n",
    "class_counts_spatial = np.bincount(train_labels_spatial)\n",
    "class_weights_spatial = (1. / class_counts_spatial) ** oversampling_power\n",
    "sample_weights_spatial = [class_weights_spatial[label] for label in train_labels_spatial]\n",
    "\n",
    "# Define sampler for spatial\n",
    "sampler_spatial = WeightedRandomSampler(sample_weights_spatial, num_samples=len(sample_weights_spatial), replacement=True)\n",
    "\n",
    "print(f\"\\nSpatial dataset - Class weights: {class_weights_spatial}\")\n",
    "print(f\"Spatial dataset - Class distribution in train: {np.bincount(train_labels_spatial)}\")\n",
    "\n",
    "print(\"\\n=== CORRELATION DATASET SPLITTING ===\")\n",
    "\n",
    "# Get total samples and split sizes for correlation dataset\n",
    "total_samples_corr = len(dataset_corr_tr)\n",
    "train_size_corr = int(TRAIN_RATIO * total_samples_corr)\n",
    "val_size_corr = total_samples_corr - train_size_corr\n",
    "\n",
    "print(f\"Correlation dataset - Total: {total_samples_corr}, Train: {train_size_corr}, Val: {val_size_corr}\")\n",
    "\n",
    "# Get labels for correlation dataset split (should be same as spatial, but let's be explicit)\n",
    "y_corr = clips_corr_tr[\"label\"].values\n",
    "\n",
    "# Create initial train/val split using random permutation\n",
    "indices_corr = torch.randperm(total_samples_corr)\n",
    "train_indices_corr = indices_corr[:train_size_corr].numpy()\n",
    "val_indices_corr = indices_corr[train_size_corr:].numpy()\n",
    "\n",
    "print('Correlation dataset labels distribution before split:')\n",
    "labels_stats(y_corr, train_indices_corr, val_indices_corr)\n",
    "\n",
    "# Create train and val datasets for correlation\n",
    "train_dataset_corr = Subset(dataset_corr_tr, train_indices_corr)\n",
    "val_dataset_corr = Subset(dataset_corr_tr, val_indices_corr)\n",
    "\n",
    "# Compute sample weights for oversampling - correlation\n",
    "train_labels_corr = [clips_corr_tr.iloc[i][\"label\"] for i in train_indices_corr]\n",
    "class_counts_corr = np.bincount(train_labels_corr)\n",
    "class_weights_corr = (1. / class_counts_corr) ** oversampling_power\n",
    "sample_weights_corr = [class_weights_corr[label] for label in train_labels_corr]\n",
    "\n",
    "# Define sampler for correlation\n",
    "sampler_corr = WeightedRandomSampler(sample_weights_corr, num_samples=len(sample_weights_corr), replacement=True)\n",
    "\n",
    "print(f\"\\nCorrelation dataset - Class weights: {class_weights_corr}\")\n",
    "print(f\"Correlation dataset - Class distribution in train: {np.bincount(train_labels_corr)}\")\n",
    "\n",
    "print(\"\\n=== SUMMARY ===\")\n",
    "print(f\"Spatial: {len(train_dataset_spatial)} train, {len(val_dataset_spatial)} val\")\n",
    "print(f\"Correlation: {len(train_dataset_corr)} train, {len(val_dataset_corr)} val\")\n",
    "\n",
    "# Create GeoDataLoaders for spatial dataset\n",
    "train_loader_spatial = GeoDataLoader(\n",
    "    train_dataset_spatial,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    sampler=sampler_spatial,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "val_loader_spatial = GeoDataLoader(\n",
    "    val_dataset_spatial,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    drop_last=False\n",
    ")\n",
    "\n",
    "te_loader_spatial = GeoDataLoader(\n",
    "    dataset_corr_te, # Use full spatial test dataset\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    drop_last=False\n",
    ")\n",
    "\n",
    "# Create GeoDataLoaders for correlation dataset\n",
    "train_loader_corr = GeoDataLoader(\n",
    "    train_dataset_corr,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    sampler=sampler_corr,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "val_loader_corr = GeoDataLoader(\n",
    "    val_dataset_corr,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    drop_last=False\n",
    ")\n",
    "\n",
    "te_loader_corr = GeoDataLoader(\n",
    "    dataset_corr_tr,  # Use full correlation test dataset\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    drop_last=False\n",
    ")\n",
    "\n",
    "print(\"\\n=== DATA LOADERS CREATED ===\")\n",
    "print(f\"Spatial - Train: {len(train_loader_spatial)} batches, Val: {len(val_loader_spatial)} batches, Test: {len(te_loader_spatial)} batches\")\n",
    "print(f\"Correlation - Train: {len(train_loader_corr)} batches, Val: {len(val_loader_corr)} batches, Test: {len(te_loader_corr)} batches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6943f0d",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🌐 Selected SPATIAL dataset for training\n",
      "✅ Using spatial dataset:\n",
      "   Train batches: 162\n",
      "   Val batches: 41\n",
      "   Test batches: 57\n",
      "   Total samples in dataset: 12993\n",
      "   First batch - Nodes: torch.Size([1216, 3009]), Edges: torch.Size([2, 21888])\n",
      "   First batch - Labels: torch.Size([64]), Batch size: 64\n",
      "\n",
      "🚀 Ready to train with spatial dataset!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# ==============================================================================\n",
    "# DATASET SELECTION FOR TRAINING\n",
    "# ==============================================================================\n",
    "# Choose which dataset type to use for training:\n",
    "# - 'spatial': Uses spatial distance-based graph connections\n",
    "# - 'correlation': Uses correlation-based graph connections\n",
    "\n",
    "DATASET_TYPE = 'spatial'  # Change this to 'correlation' to train with correlation-based graphs\n",
    "\n",
    "if DATASET_TYPE == 'spatial':\n",
    "    print(\"🌐 Selected SPATIAL dataset for training\")\n",
    "    train_loader = train_loader_spatial\n",
    "    val_loader = val_loader_spatial\n",
    "    te_loader = te_loader_spatial\n",
    "    current_dataset = dataset_spatial_tr\n",
    "elif DATASET_TYPE == 'correlation':\n",
    "    print(\"🔗 Selected CORRELATION dataset for training\")\n",
    "    train_loader = train_loader_corr\n",
    "    val_loader = val_loader_corr\n",
    "    te_loader = te_loader_corr\n",
    "    current_dataset = dataset_corr_tr\n",
    "else:\n",
    "    raise ValueError(f\"Unknown dataset type: {DATASET_TYPE}. Choose 'spatial' or 'correlation'\")\n",
    "\n",
    "print(f\"✅ Using {DATASET_TYPE} dataset:\")\n",
    "print(f\"   Train batches: {len(train_loader)}\")\n",
    "print(f\"   Val batches: {len(val_loader)}\")\n",
    "print(f\"   Test batches: {len(te_loader)}\")\n",
    "print(f\"   Total samples in dataset: {len(current_dataset)}\")\n",
    "\n",
    "# Optional: Print first batch info to verify data loading\n",
    "try:\n",
    "    first_batch = next(iter(train_loader))\n",
    "    print(f\"   First batch - Nodes: {first_batch.x.shape}, Edges: {first_batch.edge_index.shape}\")\n",
    "    print(f\"   First batch - Labels: {first_batch.y.shape}, Batch size: {first_batch.num_graphs}\")\n",
    "except Exception as e:\n",
    "    print(f\"   Could not inspect first batch: {e}\")\n",
    "\n",
    "print(f\"\\n🚀 Ready to train with {DATASET_TYPE} dataset!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67042055",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modules to reload:\n",
      "\n",
      "\n",
      "Modules to skip:\n",
      "\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'data.dataset_graph'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhybrid\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcnn_bilstm_gcn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EEGCNNBiLSTMGCN\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrain\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_model\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m plot_training_loss\n\u001b[1;32m      8\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1e-4\u001b[39m,\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweight_decay\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1e-2\u001b[39m,\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpatience\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m100\u001b[39m,\n\u001b[1;32m     13\u001b[0m }\n",
      "File \u001b[0;32m~/NeuroGraphNet/src/utils/train.py:19\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Assuming Data and Batch are from PyTorch Geometric if used with GraphEEGDataset\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Batch \u001b[38;5;28;01mas\u001b[39;00m PyGBatch\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset_graph\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GraphEEGDataset \n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Import wandb with optional fallback\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'data.dataset_graph'"
     ]
    }
   ],
   "source": [
    "%aimport\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from src.layers.hybrid.cnn_bilstm_gcn import EEGCNNBiLSTMGCN\n",
    "from src.utils.train import train_model\n",
    "from src.utils.plot import plot_training_loss\n",
    "\n",
    "config = {\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"weight_decay\": 1e-2,\n",
    "    \"patience\": 10,\n",
    "    \"epochs\": 100,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "177fedb0",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def wrap_train(model, save_path):\n",
    "    model = model.to(device)\n",
    "    # optimizer = optim.Adam(model.parameters(), lr=config[\"learning_rate\"], weight_decay=config[\"weight_decay\"])\n",
    "    # optimizer = Lion(model.parameters(), lr=config[\"learning_rate\"], weight_decay=config[\"weight_decay\"])\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(), lr=1e-4, weight_decay=0.01, betas=(0.9, 0.999))\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.5, patience=5)\n",
    "    loss = nn.BCEWithLogitsLoss()  # Not weighted as we use a balanced sampler!\n",
    "\n",
    "    # train model\n",
    "    train_history, val_history = train_model(\n",
    "        wandb_config=None,\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        criterion=loss,\n",
    "        scheduler=scheduler,\n",
    "        optimizer=optimizer,\n",
    "        device=device,\n",
    "        num_epochs=config[\"epochs\"],\n",
    "        patience=config[\"patience\"],\n",
    "        save_path=save_path,\n",
    "        use_gnn=True,\n",
    "        # hidden attribute\n",
    "        try_load_checkpoint=True,\n",
    "    )\n",
    "    plot_training_loss(train_history[\"loss\"], val_history[\"loss\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720925b0",
   "metadata": {},
   "source": [
    "### Test 3 - First breakthrough model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b640647a",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "SAVE_PATH = CHECKPOINT_ROOT / \"cnn_bilstm_gcn_test_3.pt\"\n",
    "model = EEGCNNBiLSTMGCN(\n",
    "    # Parameters for the CNN_BiLSTM_Encoder (temporal encoder)\n",
    "    cnn_dropout_prob = 0.25,\n",
    "    lstm_hidden_dim = 128,\n",
    "    lstm_out_dim = 128,\n",
    "    lstm_dropout_prob = 0.25,\n",
    "    encoder_use_batch_norm= True,\n",
    "    encoder_use_layer_norm= False,\n",
    "    # Parameters for the EEGGCN (graph neural network)\n",
    "    gcn_hidden_channels = 128,\n",
    "    gcn_out_channels = 128,\n",
    "    gcn_pooling_type= \"mean\",\n",
    "    gcn_use_batch_norm = True,\n",
    "    gcn_num_layers = 3,\n",
    "    gcn_dropout_prob = 0.5,\n",
    "    num_channels = 19,\n",
    ")\n",
    "wrap_train(model, SAVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424f5b8b",
   "metadata": {},
   "source": [
    "### Test 4 - Smaller CGN output channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da6e3138",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "SAVE_PATH = CHECKPOINT_ROOT / \"cnn_bilstm_gcn_test_4.pt\"\n",
    "\n",
    "model = EEGCNNBiLSTMGCN(\n",
    "    # Parameters for the CNN_BiLSTM_Encoder (temporal encoder)\n",
    "    cnn_dropout_prob = 0.25,\n",
    "    lstm_hidden_dim = 128,\n",
    "    lstm_out_dim = 128,\n",
    "    lstm_dropout_prob = 0.25,\n",
    "    encoder_use_batch_norm= True,\n",
    "    encoder_use_layer_norm= False,\n",
    "    # Parameters for the EEGGCN (graph neural network)\n",
    "    gcn_hidden_channels = 128,\n",
    "    gcn_out_channels = 64,\n",
    "    gcn_pooling_type= \"mean\",\n",
    "    gcn_use_batch_norm = True,\n",
    "    gcn_num_layers = 3,\n",
    "    gcn_dropout_prob = 0.5,\n",
    "    num_channels = 19,\n",
    ")\n",
    "wrap_train(model, SAVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9eaaf2d",
   "metadata": {},
   "source": [
    "### Test 5 - Smaller GCN output channels + increased embedding length + Deeper GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed1335c2",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "SAVE_PATH = CHECKPOINT_ROOT / \"cnn_bilstm_gcn_test_5.pt\"\n",
    "model = EEGCNNBiLSTMGCN(\n",
    "    # Parameters for the CNN_BiLSTM_Encoder (temporal encoder)\n",
    "    cnn_dropout_prob = 0.25,\n",
    "    lstm_hidden_dim = 128,\n",
    "    lstm_out_dim = 128,\n",
    "    lstm_dropout_prob = 0.25,\n",
    "    encoder_use_batch_norm= True,\n",
    "    encoder_use_layer_norm= False,\n",
    "    # Parameters for the EEGGCN (graph neural network)\n",
    "    gcn_hidden_channels = 128,\n",
    "    gcn_out_channels = 64,\n",
    "    gcn_pooling_type= \"mean\",\n",
    "    gcn_use_batch_norm = True,\n",
    "    gcn_num_layers = 4,\n",
    "    gcn_dropout_prob = 0.5,\n",
    "    num_channels = 19,\n",
    ")\n",
    "wrap_train(model, SAVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da60626",
   "metadata": {},
   "source": [
    "\n",
    "### Test 6: slighly bigger GCN output channels\n",
    ">[HIGHEST F1 SCORE EVER RECORDED]\n",
    "```\n",
    "✅ Checkpoint loaded. Resuming from epoch 33. Best 'val_f1' score: 0.7346\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2a2ed81",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "SAVE_PATH = CHECKPOINT_ROOT / \"cnn_bilstm_gcn_test_6.pt\"\n",
    "model = EEGCNNBiLSTMGCN(\n",
    "    # Parameters for the CNN_BiLSTM_Encoder (temporal encoder)\n",
    "    cnn_dropout_prob = 0.25,\n",
    "    lstm_hidden_dim = 128,\n",
    "    lstm_out_dim = 128,\n",
    "    lstm_dropout_prob = 0.25,\n",
    "    encoder_use_batch_norm= True,\n",
    "    encoder_use_layer_norm= False,\n",
    "    # Parameters for the EEGGCN (graph neural network)\n",
    "    gcn_hidden_channels = 128,\n",
    "    gcn_out_channels = 96,\n",
    "    gcn_pooling_type= \"mean\",\n",
    "    gcn_use_batch_norm = True,\n",
    "    gcn_num_layers = 4,\n",
    "    gcn_dropout_prob = 0.5,\n",
    "    num_channels = 19,\n",
    ")\n",
    "wrap_train(model, SAVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bad429a",
   "metadata": {},
   "source": [
    "### Test 7B: Alternative architecture to improve generalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2f882bc",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "SAVE_PATH = CHECKPOINT_ROOT / \"cnn_bilstm_gcn_test_8.pt\"\n",
    "model = EEGCNNBiLSTMGCN(\n",
    "    # Parameters for the CNN_BiLSTM_Encoder (temporal encoder)\n",
    "    cnn_dropout_prob = 0.35, # slightly higher dropout to avoid overfitting\n",
    "    lstm_hidden_dim = 128,\n",
    "    lstm_out_dim = 128,\n",
    "    lstm_dropout_prob = 0.35, # slightly higher dropout to avoid overfitting\n",
    "    encoder_use_batch_norm= True,\n",
    "    encoder_use_layer_norm= False,\n",
    "    # Parameters for the EEGGCN (graph neural network)\n",
    "    gcn_hidden_channels = 128,\n",
    "    gcn_out_channels = 96,\n",
    "    gcn_pooling_type= \"mean\",\n",
    "    gcn_use_batch_norm = True,\n",
    "    gcn_num_layers = 4,\n",
    "    gcn_dropout_prob = 0.6, # slightly higher dropout to avoid overfitting\n",
    "    num_channels = 19,\n",
    ")\n",
    "wrap_train(model, SAVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077b4f3c",
   "metadata": {},
   "source": [
    "### Test 7C: slightly bigger GCN layers\n",
    "\n",
    "BEST MODEL YET!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c3ccd1",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "SAVE_PATH = CHECKPOINT_ROOT / \"lstm_gnn_generalizable_bigger.pt\"\n",
    "model = EEGCNNBiLSTMGCN(\n",
    "    # Parameters for the CNN_BiLSTM_Encoder (temporal encoder)\n",
    "    cnn_dropout_prob = 0.25, # slightly higher dropout to avoid overfitting\n",
    "    lstm_hidden_dim = 128,\n",
    "    lstm_out_dim = 128,\n",
    "    lstm_dropout_prob = 0.25, # slightly higher dropout to avoid overfitting\n",
    "    encoder_use_batch_norm = True,\n",
    "    encoder_use_layer_norm = False,\n",
    "    # Parameters for the EEGGCN (graph neural network)\n",
    "    gcn_hidden_channels = 192,\n",
    "    gcn_out_channels = 128,\n",
    "    gcn_pooling_type = \"mean\",\n",
    "    gcn_use_batch_norm = True,\n",
    "    gcn_num_layers = 4,\n",
    "    gcn_dropout_prob = 0.6, # slightly higher dropout to avoid overfitting\n",
    "    num_channels = 19,\n",
    ")\n",
    "wrap_train(model, SAVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6355457",
   "metadata": {},
   "source": [
    "### Test 7D: even bigger GCN layers\n",
    "\n",
    "Comparable performance to best model. We might need to increase the number of GCN layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed9d736",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "SAVE_PATH = CHECKPOINT_ROOT / \"lstm_gnn_generalizable_even_bigger.pt\"\n",
    "model = EEGCNNBiLSTMGCN(\n",
    "    # Parameters for the CNN_BiLSTM_Encoder (temporal encoder)\n",
    "    cnn_dropout_prob = 0.25, # slightly higher dropout to avoid overfitting\n",
    "    lstm_hidden_dim = 128,\n",
    "    lstm_out_dim = 128,\n",
    "    lstm_dropout_prob = 0.25, # slightly higher dropout to avoid overfitting\n",
    "    encoder_use_batch_norm = True,\n",
    "    encoder_use_layer_norm = False,\n",
    "    # Parameters for the EEGGCN (graph neural network)\n",
    "    gcn_hidden_channels = 224,\n",
    "    gcn_out_channels = 192,\n",
    "    gcn_pooling_type = \"mean\",\n",
    "    gcn_use_batch_norm = True,\n",
    "    gcn_num_layers = 4,\n",
    "    gcn_dropout_prob = 0.6, # slightly higher dropout to avoid overfitting\n",
    "    num_channels = 19,\n",
    ")\n",
    "wrap_train(model, SAVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50956294",
   "metadata": {},
   "source": [
    "### Test 7E: increased number of GCN layers\n",
    "\n",
    "Assumption: the previous model was unable to learn enough, maybe the GCN was unable to capture\n",
    "\n",
    "```\n",
    "Epochs:   9%| | 9/100 [17:54<3:23:31, 134.20s/it, train_loss=0.4532, val_loss=0.3489, best_val_f1=0.6695, lr=5.00e-05, b2025-06-07 17:01:05 - INFO - \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9b1c57",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "SAVE_PATH = CHECKPOINT_ROOT / \"lstm_gnn_generalizable_even_more_bigger.pt\"\n",
    "model_generalizable_even_more_bigger = EEGCNNBiLSTMGCN(\n",
    "    # Parameters for the CNN_BiLSTM_Encoder (temporal encoder)\n",
    "    cnn_dropout_prob = 0.25,\n",
    "    lstm_hidden_dim = 128,\n",
    "    lstm_out_dim = 128,\n",
    "    lstm_dropout_prob = 0.25,\n",
    "    # Parameters for the EEGGCN (graph neural network)\n",
    "    gcn_hidden_channels = 224,\n",
    "    gcn_out_channels = 192,\n",
    "    gcn_num_layers = 5,\n",
    "    gcn_dropout_prob = 0.6, # slightly higher dropout to avoid overfitting\n",
    "    num_classes = 1,\n",
    "    num_channels = 19,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08442186",
   "metadata": {},
   "source": [
    "### Test 7F: Increased number of BiLSTM layers + Test 7E architecture\n",
    "\n",
    "Assumpion: we saw a drammatical increase in accuracy by increasing the number of GCN layers. This hints that the model was now able to learn the most from the embeddings. To improve the performance even further without having to increase the number of GCN layers even more (overall reduce complexity, improve generalization), we will try to increase the number of BiLSTM layers. \n",
    "\n",
    "Using multiple BiLSTM layers will allow embeddings to be processed in a more complex way, potentially capturing more intricate relationships in the data. The GCN layers will take care of the graph structure, while the BiLSTM layers will enhance the temporal dependencies and relationships in the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b963a5a",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "SAVE_PATH = CHECKPOINT_ROOT / \"lstm_gnn_generalizable_even_more_bigger.pt\"\n",
    "model_generalizable_even_more_bigger = EEGCNNBiLSTMGCN(\n",
    "    # Parameters for the CNN_BiLSTM_Encoder (temporal encoder)\n",
    "    cnn_dropout_prob = 0.25,\n",
    "    lstm_hidden_dim = 128,\n",
    "    lstm_out_dim = 128,\n",
    "    lstm_dropout_prob = 0.25,\n",
    "    lstm_num_layers = 2,\n",
    "    # Parameters for the EEGGCN (graph neural network)\n",
    "    gcn_hidden_channels = 224,\n",
    "    gcn_out_channels = 192,\n",
    "    gcn_num_layers = 5,\n",
    "    gcn_dropout_prob = 0.6, # slightly higher dropout to avoid overfitting\n",
    "    num_classes = 1,\n",
    "    num_channels = 19,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3663332c",
   "metadata": {},
   "source": [
    "```\n",
    "Epochs:   1%|▊                                                                                  | 1/100 [00:00<?, ?it/s]2025-06-07 18:55:16 - INFO -\n",
    "Epochs:   2%| | 2/100 [04:35<7:29:19, 275.10s/it, train_loss=0.6212, val_loss=0.4619, best_val_f1=0.4055, lr=1.00e-04, b2025-06-07 18:59:51 - INFO -\n",
    "Epochs:   3%| | 3/100 [09:09<7:23:49, 274.53s/it, train_loss=0.5819, val_loss=0.4295, best_val_f1=0.4055, lr=1.00e-04, b2025-06-07 19:04:25 - INFO -\n",
    "Epochs:   4%| | 4/100 [13:42<7:18:31, 274.08s/it, train_loss=0.5628, val_loss=0.4437, best_val_f1=0.4055, lr=1.00e-04, b2025-06-07 19:08:59 - INFO -\n",
    "Epochs:   5%| | 5/100 [18:16<7:13:28, 273.78s/it, train_loss=0.5452, val_loss=0.3942, best_val_f1=0.4858, lr=1.00e-04, b2025-06-07 19:13:32 - INFO -\n",
    "Epochs:   6%| | 6/100 [22:49<7:08:41, 273.63s/it, train_loss=0.5334, val_loss=0.4563, best_val_f1=0.4858, lr=1.00e-04, b2025-06-07 19:18:05 - INFO -\n",
    "Epochs:   7%| | 7/100 [27:22<7:04:01, 273.57s/it, train_loss=0.5319, val_loss=0.3738, best_val_f1=0.5137, lr=1.00e-04, b2025-06-07 19:22:39 - INFO -\n",
    "Epochs:   8%| | 8/100 [31:56<6:59:20, 273.48s/it, train_loss=0.5181, val_loss=0.4369, best_val_f1=0.5695, lr=1.00e-04, b2025-06-07 19:27:12 - INFO -\n",
    "Epochs:   9%| | 9/100 [36:29<6:54:50, 273.52s/it, train_loss=0.5220, val_loss=0.4202, best_val_f1=0.5695, lr=1.00e-04, b2025-06-07 19:31:46 - INFO -\n",
    "Epochs:  10%| | 10/100 [41:03<6:50:17, 273.52s/it, train_loss=0.5286, val_loss=0.4167, best_val_f1=0.5695, lr=1.00e-04, 2025-06-07 19:36:19 - INFO -\n",
    "Epochs:  11%| | 11/100 [45:36<6:45:44, 273.53s/it, train_loss=0.5065, val_loss=0.3864, best_val_f1=0.5695, lr=1.00e-04, 2025-06-07 19:40:53 - INFO -\n",
    "Epochs:  12%| | 12/100 [50:10<6:41:03, 273.45s/it, train_loss=0.5158, val_loss=0.5175, best_val_f1=0.5695, lr=5.00e-05, 2025-06-07 19:45:26 - INFO -\n",
    "Epochs:  13%|▏| 13/100 [54:43<6:36:23, 273.37s/it, train_loss=0.5035, val_loss=0.3785, best_val_f1=0.5940, lr=5.00e-05, 2025-06-07 19:49:59 - INFO -\n",
    "Epochs:  14%|▏| 14/100 [59:16<6:31:50, 273.38s/it, train_loss=0.4842, val_loss=0.3838, best_val_f1=0.5981, lr=5.00e-05, 2025-06-07 19:54:33 - INFO -\n",
    "Epochs:  15%|▏| 15/100 [1:03:50<6:27:17, 273.38s/it, train_loss=0.4644, val_loss=0.3493, best_val_f1=0.6106, lr=5.00e-052025-06-07 19:59:06 - INFO -\n",
    "Epochs:  16%|▏| 16/100 [1:08:23<6:22:46, 273.41s/it, train_loss=0.4887, val_loss=0.3737, best_val_f1=0.6106, lr=5.00e-052025-06-07 20:03:39 - INFO -\n",
    "Epochs:  17%|▏| 17/100 [1:12:57<6:18:12, 273.41s/it, train_loss=0.4775, val_loss=0.3565, best_val_f1=0.6106, lr=5.00e-052025-06-07 20:08:13 - INFO -\n",
    "Epochs:  18%|▏| 18/100 [1:17:30<6:13:42, 273.44s/it, train_loss=0.4635, val_loss=0.3704, best_val_f1=0.6106, lr=2.50e-052025-06-07 20:12:46 - INFO -\n",
    "Epochs:  19%|▏| 19/100 [1:22:04<6:09:15, 273.53s/it, train_loss=0.4501, val_loss=0.3635, best_val_f1=0.6131, lr=2.50e-052025-06-07 20:17:20 - INFO -\n",
    "Epochs:  20%|▏| 20/100 [1:26:37<6:04:39, 273.49s/it, train_loss=0.4379, val_loss=0.3638, best_val_f1=0.6179, lr=2.50e-052025-06-07 20:21:53 - INFO -\n",
    "Epochs:  21%|▏| 21/100 [1:31:10<6:00:01, 273.43s/it, train_loss=0.4494, val_loss=0.3543, best_val_f1=0.6179, lr=2.50e-052025-06-07 20:26:27 - INFO -\n",
    "Epochs:  22%|▏| 22/100 [1:35:44<5:55:26, 273.42s/it, train_loss=0.4616, val_loss=0.3616, best_val_f1=0.6659, lr=2.50e-052025-06-07 20:31:00 - INFO -\n",
    "Epochs:  23%|▏| 23/100 [1:40:17<5:50:54, 273.44s/it, train_loss=0.4381, val_loss=0.3532, best_val_f1=0.6659, lr=2.50e-052025-06-07 20:35:34 - INFO -\n",
    "Epochs:  24%|▏| 24/100 [1:44:51<5:46:22, 273.45s/it, train_loss=0.4423, val_loss=0.3635, best_val_f1=0.6659, lr=1.25e-052025-06-07 20:40:07 - INFO -\n",
    "Epochs:  25%|▎| 25/100 [1:49:24<5:41:52, 273.49s/it, train_loss=0.4291, val_loss=0.3473, best_val_f1=0.6659, lr=1.25e-052025-06-07 20:44:41 - INFO -\n",
    "Epochs:  26%|▎| 26/100 [1:53:58<5:37:12, 273.42s/it, train_loss=0.4403, val_loss=0.3380, best_val_f1=0.6659, lr=1.25e-052025-06-07 20:49:14 - INFO -\n",
    "Epochs:  27%|▎| 27/100 [1:58:31<5:32:38, 273.40s/it, train_loss=0.4312, val_loss=0.3374, best_val_f1=0.6659, lr=1.25e-052025-06-07 20:53:47 - INFO -\n",
    "Epochs:  28%|▎| 28/100 [2:03:05<5:28:07, 273.44s/it, train_loss=0.4393, val_loss=0.3441, best_val_f1=0.6659, lr=1.25e-052025-06-07 20:58:21 - INFO -\n",
    "Epochs:  29%|▎| 29/100 [2:07:38<5:23:35, 273.46s/it, train_loss=0.4226, val_loss=0.3392, best_val_f1=0.6659, lr=1.25e-052025-06-07 21:02:54 - INFO -\n",
    "Epochs:  30%|▎| 30/100 [2:12:11<5:19:02, 273.46s/it, train_loss=0.4240, val_loss=0.3525, best_val_f1=0.6659, lr=6.25e-062025-06-07 21:07:28 - INFO -\n",
    "Epochs:  31%|▎| 31/100 [2:16:45<5:14:28, 273.46s/it, train_loss=0.4249, val_loss=0.3492, best_val_f1=0.6659, lr=6.25e-062025-06-07 21:12:01 - INFO -\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a84badf",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'EEGCNNBiLSTMGCN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m SAVE_PATH \u001b[38;5;241m=\u001b[39m CHECKPOINT_ROOT \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlstm_gnn_generalizable_optimized.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m model_generalizable_optimized \u001b[38;5;241m=\u001b[39m \u001b[43mEEGCNNBiLSTMGCN\u001b[49m(\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# Parameters for the CNN_BiLSTM_Encoder (temporal encoder)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     cnn_dropout_prob \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.25\u001b[39m,\n\u001b[1;32m      5\u001b[0m     lstm_hidden_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m160\u001b[39m,\n\u001b[1;32m      6\u001b[0m     lstm_out_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m128\u001b[39m,\n\u001b[1;32m      7\u001b[0m     lstm_dropout_prob \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.25\u001b[39m,\n\u001b[1;32m      8\u001b[0m     lstm_num_layers \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# Parameters for the EEGGCN (graph neural network)\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     gcn_hidden_channels \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m192\u001b[39m,\n\u001b[1;32m     11\u001b[0m     gcn_out_channels \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m128\u001b[39m,\n\u001b[1;32m     12\u001b[0m     gcn_num_layers \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m,\n\u001b[1;32m     13\u001b[0m     gcn_dropout_prob \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;66;03m# slightly higher dropout to avoid overfitting\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     num_channels \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m19\u001b[39m,\n\u001b[1;32m     15\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'EEGCNNBiLSTMGCN' is not defined"
     ]
    }
   ],
   "source": [
    "SAVE_PATH = CHECKPOINT_ROOT / \"lstm_gnn_generalizable_optimized.pt\"\n",
    "model_generalizable_optimized = EEGCNNBiLSTMGCN(\n",
    "    # Parameters for the CNN_BiLSTM_Encoder (temporal encoder)\n",
    "    cnn_dropout_prob = 0.25,\n",
    "    lstm_hidden_dim = 160,\n",
    "    lstm_out_dim = 128,\n",
    "    lstm_dropout_prob = 0.25,\n",
    "    lstm_num_layers = 2,\n",
    "    # Parameters for the EEGGCN (graph neural network)\n",
    "    gcn_hidden_channels = 192,\n",
    "    gcn_out_channels = 128,\n",
    "    gcn_num_layers = 4,\n",
    "    gcn_dropout_prob = 0.5, # slightly higher dropout to avoid overfitting\n",
    "    num_channels = 19,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1c4b3a",
   "metadata": {},
   "source": [
    "### Test 8: Narrow but Deep GCN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff01da2a",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "SAVE_PATH = CHECKPOINT_ROOT / \"lstm_gnn_narrow_deep_model.pt\"\n",
    "narrow_deep_model = EEGCNNBiLSTMGCN(\n",
    "    # --- Simplify the Temporal Encoder ---\n",
    "    cnn_dropout_prob = 0.2,\n",
    "    lstm_hidden_dim = 64,  # Reduced\n",
    "    lstm_out_dim = 64,     # Reduced\n",
    "    lstm_dropout_prob = 0.2,\n",
    "    # --- Focus on the GCN ---\n",
    "    gcn_hidden_channels = 128, # Keep GCN capacity high\n",
    "    gcn_out_channels = 64,\n",
    "    gcn_num_layers = 5,      # Try going even deeper\n",
    "    gcn_dropout_prob = 0.5,\n",
    "    num_classes = 1,\n",
    "    num_channels = 19,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59ef8b3",
   "metadata": {},
   "source": [
    "### Test 9: First best model, with wider + deeper GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a1b36f",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "SAVE_PATH = CHECKPOINT_ROOT / \"lstm_gnn_new_old_best_model.pt\"\n",
    "new_old_best_model = EEGCNNBiLSTMGCN(\n",
    "    # Parameters for the CNN_BiLSTM_Encoder (temporal encoder)\n",
    "    cnn_dropout_prob = 0.25,\n",
    "    lstm_hidden_dim = 128,\n",
    "    lstm_out_dim = 128,\n",
    "    lstm_dropout_prob = 0.25,\n",
    "    # Parameters for the EEGGCN (graph neural network)\n",
    "    gcn_hidden_channels = 128,\n",
    "    gcn_out_channels = 128, # from 64 to 128\n",
    "    gcn_num_layers = 4, # from 3 to 4\n",
    "    gcn_dropout_prob = 0.5,\n",
    "    num_classes = 1,\n",
    "    num_channels = 19,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351da028",
   "metadata": {},
   "source": [
    "### Best model + attention BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e32174c",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "%aimport src.layers.hybrid.cnn_bilstm_attention_gcn\n",
    "from src.layers.hybrid.cnn_bilstm_attention_gcn import EEGCNNBiLSTMAttentionGNN\n",
    "\n",
    "SAVE_PATH = CHECKPOINT_ROOT / \"lstm_gnn_attention.pt\"\n",
    "model_first_attention = EEGCNNBiLSTMAttentionGNN(\n",
    "    # Parameters for the CNN_BiLSTM_Encoder (temporal encoder)\n",
    "    cnn_dropout_prob = 0.25, # slightly higher dropout to avoid overfitting\n",
    "    lstm_hidden_dim = 128,\n",
    "    lstm_out_dim = 128,\n",
    "    lstm_dropout_prob = 0.25, # slightly higher dropout to avoid overfitting\n",
    "    encoder_use_batch_norm= True,\n",
    "    encoder_use_layer_norm= False,\n",
    "    # Parameters for the EEGGCN (graph neural network)\n",
    "    gcn_hidden_channels = 192,\n",
    "    gcn_out_channels = 128,\n",
    "    gcn_num_layers = 4,\n",
    "    gcn_dropout_prob = 0.6, # slightly higher dropout to avoid overfitting\n",
    "    gcn_pooling_type= \"mean\",\n",
    "    gcn_use_batch_norm = True,\n",
    "    num_channels = 19,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a8a5fd",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "%aimport\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from src.utils.train import train_model\n",
    "\n",
    "model = model_small_gcn_bigger_embedding\n",
    "model = model.to(device)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=config[\"learning_rate\"], weight_decay=config[\"weight_decay\"])\n",
    "# optimizer = Lion(model.parameters(), lr=config[\"learning_rate\"], weight_decay=config[\"weight_decay\"])\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=0.01, betas=(0.9, 0.999))\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "loss = nn.BCEWithLogitsLoss() # Not weighted as we use a balanced sampler!\n",
    "\n",
    "# empty cache in order to free up VRAM (if available)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# train model\n",
    "train_history, val_history = train_model(\n",
    "    wandb_config=None,\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    criterion=loss,\n",
    "    scheduler=scheduler,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    num_epochs=config[\"epochs\"],\n",
    "    patience=config[\"patience\"],\n",
    "    save_path=SAVE_PATH,\n",
    "    use_gnn=True,\n",
    "    # hidden attribute\n",
    "    try_load_checkpoint=True,\n",
    ")\n",
    "\n",
    "from src.utils.plot import plot_training_loss\n",
    "\n",
    "plot_training_loss(train_history[\"loss\"], val_history[\"loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0eb2d79",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# torch cuda clear cache\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63329a79",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from src.utils.plot import plot_training_loss\n",
    "\n",
    "plot_training_loss(train_history[\"loss\"], val_history[\"loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fdd646",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "print(\"=== CREATING DATA LOADERS ===\")\n",
    "\n",
    "# Create data loaders for SPATIAL dataset\n",
    "print(\"Creating spatial data loaders...\")\n",
    "train_loader_spatial = GeoDataLoader(\n",
    "    train_dataset_spatial,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    sampler=sampler_spatial,\n",
    "    shuffle=False,  # Don't shuffle when using sampler\n",
    "    num_workers=2,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True,\n",
    "    prefetch_factor=4\n",
    ")\n",
    "\n",
    "val_loader_spatial = GeoDataLoader(\n",
    "    val_dataset_spatial,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True,\n",
    "    prefetch_factor=4\n",
    ")\n",
    "\n",
    "te_loader_spatial = GeoDataLoader(\n",
    "    dataset_corr_te,  # Using correlation test dataset for consistency\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True,\n",
    "    prefetch_factor=4\n",
    ")\n",
    "\n",
    "print(f\"Spatial - Train batches: {len(train_loader_spatial)}\")\n",
    "print(f\"Spatial - Val batches: {len(val_loader_spatial)}\")\n",
    "print(f\"Spatial - Test batches: {len(te_loader_spatial)}\")\n",
    "\n",
    "# Create data loaders for CORRELATION dataset\n",
    "print(\"\\nCreating correlation data loaders...\")\n",
    "train_loader_corr = GeoDataLoader(\n",
    "    train_dataset_corr,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    sampler=sampler_corr,\n",
    "    shuffle=False,  # Don't shuffle when using sampler\n",
    "    num_workers=2,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True,\n",
    "    prefetch_factor=4\n",
    ")\n",
    "\n",
    "val_loader_corr = GeoDataLoader(\n",
    "    val_dataset_corr,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True,\n",
    "    prefetch_factor=4\n",
    ")\n",
    "\n",
    "te_loader_corr = GeoDataLoader(\n",
    "    dataset_corr_te,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True,\n",
    "    prefetch_factor=4\n",
    ")\n",
    "\n",
    "print(f\"Correlation - Train batches: {len(train_loader_corr)}\")\n",
    "print(f\"Correlation - Val batches: {len(val_loader_corr)}\")\n",
    "print(f\"Correlation - Test batches: {len(te_loader_corr)}\")\n",
    "\n",
    "print(\"\\n✅ All data loaders created successfully!\")\n",
    "print(\"\\nYou can now use:\")\n",
    "print(\"  - train_loader_spatial, val_loader_spatial, te_loader_spatial for spatial graph training\")\n",
    "print(\"  - train_loader_corr, val_loader_corr, te_loader_corr for correlation graph training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a56808",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# DATASET VERIFICATION AND COMPARISON\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"=== DATASET COMPARISON ===\")\n",
    "print(f\"Spatial dataset size: {len(dataset_spatial_tr)} samples\")\n",
    "print(f\"Correlation dataset size: {len(dataset_corr_tr)} samples\")\n",
    "print(f\"Test dataset size: {len(dataset_corr_te)} samples\")\n",
    "\n",
    "# Verify split consistency\n",
    "print(\"\\n=== SPLIT VERIFICATION ===\")\n",
    "print(f\"Spatial splits - Train: {len(train_dataset_spatial)}, Val: {len(val_dataset_spatial)}\")\n",
    "print(f\"Correlation splits - Train: {len(train_dataset_corr)}, Val: {len(val_dataset_corr)}\")\n",
    "\n",
    "# Check split ratios\n",
    "spatial_train_ratio = len(train_dataset_spatial) / len(dataset_spatial_tr)\n",
    "corr_train_ratio = len(train_dataset_corr) / len(dataset_corr_tr)\n",
    "print(f\"\\nTrain ratios - Spatial: {spatial_train_ratio:.3f}, Correlation: {corr_train_ratio:.3f}\")\n",
    "\n",
    "# Verify labels are balanced\n",
    "print(\"\\n=== LABEL BALANCE VERIFICATION ===\")\n",
    "print(\"Spatial train labels:\", np.bincount([clips_tr.iloc[i]['label'] for i in train_indices_spatial]))\n",
    "print(\"Spatial val labels:\", np.bincount([clips_tr.iloc[i]['label'] for i in val_indices_spatial]))\n",
    "print(\"Correlation train labels:\", np.bincount([clips_tr.iloc[i]['label'] for i in train_indices_corr]))\n",
    "print(\"Correlation val labels:\", np.bincount([clips_tr.iloc[i]['label'] for i in val_indices_corr]))\n",
    "\n",
    "print(\"\\n✅ All splits created successfully and verified!\")\n",
    "print(\"\\n📝 Note: To train with different datasets, change DATASET_TYPE in the cell above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e14ad1f",
   "metadata": {},
   "source": [
    "## Training Instructions\n",
    "\n",
    "### Dataset Selection\n",
    "You can now train with either dataset type by changing the `DATASET_TYPE` variable:\n",
    "\n",
    "- **Spatial**: `DATASET_TYPE = 'spatial'` - Uses spatial distance-based graph connections\n",
    "- **Correlation**: `DATASET_TYPE = 'correlation'` - Uses correlation-based graph connections\n",
    "\n",
    "### Available Data Loaders\n",
    "\n",
    "#### For Spatial Dataset:\n",
    "- `train_loader_spatial` - Training data with weighted sampling for class balance\n",
    "- `val_loader_spatial` - Validation data\n",
    "- `te_loader_spatial` - Test data\n",
    "\n",
    "#### For Correlation Dataset:\n",
    "- `train_loader_corr` - Training data with weighted sampling for class balance\n",
    "- `val_loader_corr` - Validation data\n",
    "- `te_loader_corr` - Test data\n",
    "\n",
    "### Split Details\n",
    "- **Train/Validation ratio**: 80/20\n",
    "- **Random seed**: 42 (for reproducibility)\n",
    "- **Class balancing**: WeightedRandomSampler with oversampling power = 1.0\n",
    "- **Batch size**: 64\n",
    "\n",
    "### Training Tips\n",
    "1. The `train_loader`, `val_loader`, and `te_loader` variables are automatically set based on your `DATASET_TYPE` selection\n",
    "2. Both datasets use the same preprocessing pipeline but different graph construction strategies\n",
    "3. The correlation dataset uses top-k=5 connections, while spatial uses distance-based connections\n",
    "4. All data loaders include proper error handling and batch verification"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
