{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NeuroGraphNet\n",
    "\n",
    "*A graph-based deep learning framework for EEG seizure detection, designed to improve accuracy and interpretability by leveraging Graph Neural Networks (GNNs) to capture spatial and temporal brain dynamics.*\n",
    "\n",
    "<hr />\n",
    "\n",
    "This notebook presents **NeuroGraphNet**, a model that applies Graph Neural Networks to EEG data for seizure detection. The primary goal is to **compare the performance and interpretability of graph-based methods versus traditional deep learning approaches**. Through this comparison, we aim to demonstrate the advantages of incorporating brain connectivity information into the learning process.\n",
    "\n",
    "**Authors**: Luca Di Bello, Guillaume AndrÃ© BÃ©lissent, Abdessalem Ben Ali, Beatriz Izquierdo GonzÃ¡lez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric.loader import DataLoader as GeoDataLoader\n",
    "from src.utils.seeder import seed_everything\n",
    "\n",
    "# set seaborn theme\n",
    "sns.set_theme()\n",
    "\n",
    "# create useful constants\n",
    "RANDOM_SEED = 42\n",
    "IS_SCITAS = False # set to True if running on SCITAS cluster\n",
    "LOCAL_DATA_ROOT = Path(\"./data\")\n",
    "DATA_ROOT = Path(\"/home/ogut/data\") if IS_SCITAS else LOCAL_DATA_ROOT\n",
    "CHECKPOINT_ROOT = Path(\"./.checkpoints\")\n",
    "SUBMISSION_ROOT = Path(\"./.submissions\")\n",
    "\n",
    "# create directories if they do not exist\n",
    "CHECKPOINT_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "SUBMISSION_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# set dataset root\n",
    "seed_everything(RANDOM_SEED)\n",
    "\n",
    "# setup torch device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load clips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â³ Loading EEG segment tablesâ€¦\n",
      "âœ”ï¸ Loaded: 12993 train rows, 3614 test rows (took 0.0s)\n"
     ]
    }
   ],
   "source": [
    "from src.utils.signal import time_filtering, normalize\n",
    "%aimport src.utils.signal\n",
    "from src.utils.index import ensure_eeg_multiindex\n",
    "\n",
    "start = time.time()\n",
    "print(\"â³ Loading EEG segment tablesâ€¦\")\n",
    "clips_tr = pd.read_parquet(DATA_ROOT / \"train\" / \"segments.parquet\").dropna()\n",
    "clips_te = pd.read_parquet(DATA_ROOT / \"test\" / \"segments.parquet\").dropna()\n",
    "\n",
    "# load clips with label\n",
    "clips_tr = ensure_eeg_multiindex(clips_tr, id_col_name='id')\n",
    "clips_te = ensure_eeg_multiindex(clips_te, id_col_name='id')\n",
    "\n",
    "print(f\"âœ”ï¸ Loaded: {len(clips_tr)} train rows, {len(clips_te)} test rows \"\n",
    "      f\"(took {time.time()-start:.1f}s)\")\n",
    "# NOTE: Merge clips for sanity checks\n",
    "clips = pd.concat([clips_tr, clips_te]).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train extracted features shape: (12993, 228)\n",
      "Test extracted features shape: (3614, 228)\n"
     ]
    }
   ],
   "source": [
    "# print feature shapes\n",
    "X_train = np.load(LOCAL_DATA_ROOT / \"extracted_features\" / \"X_train.npy\", allow_pickle=True)\n",
    "X_test = np.load(LOCAL_DATA_ROOT / \"extracted_features\" / \"X_test.npy\", allow_pickle=True)\n",
    "y_train = np.load(LOCAL_DATA_ROOT / \"labels\" / \"y_train.npy\", allow_pickle=True)\n",
    "sample_subject_array = np.load(LOCAL_DATA_ROOT / \"extracted_features\" / \"sample_subject_array_train.npy\",allow_pickle=True)\n",
    "\n",
    "# sanity checks to ensure validity of the data\n",
    "assert X_train.shape[0]  == y_train.shape[0], \"Mismatch in number of training samples and labels\"\n",
    "assert X_train.shape[1] == X_test.shape[1], \"Mismatch in number of features between train and test sets\"\n",
    "assert clips_tr.shape[0] == y_train.shape[0], \"Mismatch in number of training samples and segments\"\n",
    "assert X_train.shape[0] == sample_subject_array.shape[0], \"Mismatch in number of training samples and subjects\"\n",
    "assert clips_tr.shape[0] == sample_subject_array.shape[0], \"Mismatch in number of training segments and subjects\"\n",
    "\n",
    "print(\"Train extracted features shape:\", X_train.shape)\n",
    "print(\"Test extracted features shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------- Extracted features -----------------------------------------------#\n",
    "channels = ['FP1', 'FP2', 'F3', 'F4', 'C3', 'C4', 'P3', 'P4', 'O1', 'O2', 'F7', 'F8', 'T3', 'T4', 'T5', 'T6', 'FZ', 'CZ', 'PZ']\n",
    "features = [\n",
    "    \"rms\", \"linelen\", \"hj_mob\", \"hj_cmp\", \"spec_ent\",\n",
    "    \"alpha_pow\", \"beta_pow\", \"theta_pow\", \"gamma_pow\",\n",
    "    \"rel_alpha\", \"rel_theta\", \"theta_alpha_ratio\"\n",
    "]\n",
    "n_features = len(features)\n",
    "n_channels = len(channels)\n",
    "\n",
    "feature_names = [f\"{ch} - {ft}\" for ch in channels for ft in features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating timeseries dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Initializing EEGTimeSeriesDataset in SIGNAL mode.\n",
      "   - Sampling rate: 250 Hz\n",
      "   - Derived segment length: 3000 timesteps.\n",
      "   - Segment length: 3000 timesteps.\n",
      "   - Processing 12993 segments from clips_df row by row...\n",
      "     - Processing clip/segment 1299/12993...\n"
     ]
    }
   ],
   "source": [
    "%aimport src.utils.timeseries_eeg_dataset\n",
    "from src.utils.timeseries_eeg_dataset import TimeseriesEEGDataset\n",
    "\n",
    "LOCAL_DATA_ROOT = Path(\"./data\")\n",
    "\n",
    "timeseries_datasets_tr = {\n",
    "    \"signal\": TimeseriesEEGDataset(\n",
    "        root=str(LOCAL_DATA_ROOT / \"timeseries_dataset_train_signal\"),\n",
    "        signal_folder=str(DATA_ROOT / 'train'),\n",
    "        clips_df=clips_tr,\n",
    "        mode='signal',\n",
    "    ),\n",
    "    \"features\": TimeseriesEEGDataset(\n",
    "        root=str(LOCAL_DATA_ROOT / \"timeseries_dataset_train_features\"),\n",
    "        signal_folder=str(DATA_ROOT / 'train'),\n",
    "        clips_df=clips_tr,\n",
    "        mode='features',\n",
    "        feature_file_path=str(LOCAL_DATA_ROOT / \"extracted_features\" / \"X_train.npy\"),\n",
    "    ),\n",
    "    \"embedding\": TimeseriesEEGDataset(\n",
    "        root=str(LOCAL_DATA_ROOT / \"timeseries_dataset_train_embedding\"),\n",
    "        signal_folder=str(DATA_ROOT / 'train'),\n",
    "        clips_df=clips_tr,\n",
    "        mode='embedding',\n",
    "        embedding_file_path=str(LOCAL_DATA_ROOT / \"embeddings\" / \"X_train_embedding.npy\"),\n",
    "        labels_for_embedding_file_path=str(LOCAL_DATA_ROOT / \"labels\" / \"y_train.npy\")\n",
    "    ),\n",
    "}\n",
    "\n",
    "# timeseries_datasets_te = {\n",
    "#     'signal': TimeseriesEEGDataset(\n",
    "#         clips_df=clips_te,\n",
    "#         mode='signal',\n",
    "#         feature_file_path=None,\n",
    "#         embedding_file_path=None,\n",
    "#         labels_for_embedding_file_path=None,\n",
    "#         signal_folder=str(DATA_ROOT / 'test'),\n",
    "#     ),\n",
    "#     'features': TimeseriesEEGDataset(\n",
    "#         clips_df=clips_te,\n",
    "#         mode='features',\n",
    "#         feature_file_path=LOCAL_DATA_ROOT / \"extracted_features\" / \"X_test.npy\",\n",
    "#         embedding_file_path=None,\n",
    "#         labels_for_embedding_file_path=None,\n",
    "#         signal_folder=None,\n",
    "#     ),\n",
    "#     'embedding': TimeseriesEEGDataset(\n",
    "#         clips_df=clips_te,\n",
    "#         mode='embedding',\n",
    "#         feature_file_path=None,\n",
    "#         embedding_file_path=LOCAL_DATA_ROOT / \"embeddings\" / \"X_test_embedding.npy\",\n",
    "#         labels_for_embedding_file_path=None,\n",
    "#         signal_folder=None,\n",
    "#     ),\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating graph dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Initializing GraphEEGDataset in FEATURE mode.\n",
      "   - Root: data/graph_dataset_train\n",
      "   - Mode: FEATURE\n",
      "   - Edge strategy: full\n",
      "   - Node Feature Normalization: True\n",
      "âš™ï¸ process() called for FEATURE mode. Target processed directory: data/graph_dataset_train/processed\n",
      "   - Starting processing from pre-extracted features...\n",
      "   - Total feature sets to process: 12993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     - Processing feature item 1299/12993...\n",
      "     - Processing feature item 2598/12993...\n",
      "     - Processing feature item 2598/12993...\n",
      "     - Processing feature item 3897/12993...\n",
      "     - Processing feature item 3897/12993...\n",
      "     - Processing feature item 5196/12993...\n",
      "     - Processing feature item 5196/12993...\n",
      "     - Processing feature item 6495/12993...\n",
      "     - Processing feature item 6495/12993...\n",
      "     - Processing feature item 7794/12993...\n",
      "     - Processing feature item 7794/12993...\n",
      "     - Processing feature item 9093/12993...\n",
      "     - Processing feature item 9093/12993...\n",
      "     - Processing feature item 10392/12993...\n",
      "     - Processing feature item 10392/12993...\n",
      "     - Processing feature item 11691/12993...\n",
      "     - Processing feature item 11691/12993...\n",
      "     - Processing feature item 12990/12993...\n",
      "     - Processing feature item 12993/12993...\n",
      "   âœ… Processed and saved 12993 items from features.\n",
      "ðŸ process() finished. Total items processed and saved in this run for feature mode: 12993\n",
      "   - Found 12993 existing processed files for feature mode.\n",
      "ðŸ GraphEEGDataset initialization complete. Current mode: FEATURE. Known processed items: 12993\n",
      "ðŸš€ Initializing GraphEEGDataset in FEATURE mode.\n",
      "   - Root: data/graph_dataset_train\n",
      "   - Mode: FEATURE\n",
      "   - Edge strategy: spatial\n",
      "   - Node Feature Normalization: True\n",
      "   - Loading spatial distances...\n",
      "     - Loaded 180 unique spatial distances relevant to defined channels.\n",
      "âš™ï¸ process() called for FEATURE mode. Target processed directory: data/graph_dataset_train/processed\n",
      "   - Starting processing from pre-extracted features...\n",
      "   - Total feature sets to process: 12993\n",
      "     - Processing feature item 12990/12993...\n",
      "     - Processing feature item 12993/12993...\n",
      "   âœ… Processed and saved 12993 items from features.\n",
      "ðŸ process() finished. Total items processed and saved in this run for feature mode: 12993\n",
      "   - Found 12993 existing processed files for feature mode.\n",
      "ðŸ GraphEEGDataset initialization complete. Current mode: FEATURE. Known processed items: 12993\n",
      "ðŸš€ Initializing GraphEEGDataset in FEATURE mode.\n",
      "   - Root: data/graph_dataset_train\n",
      "   - Mode: FEATURE\n",
      "   - Edge strategy: spatial\n",
      "   - Node Feature Normalization: True\n",
      "   - Loading spatial distances...\n",
      "     - Loaded 180 unique spatial distances relevant to defined channels.\n",
      "âš™ï¸ process() called for FEATURE mode. Target processed directory: data/graph_dataset_train/processed\n",
      "   - Starting processing from pre-extracted features...\n",
      "   - Total feature sets to process: 12993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Processing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     - Processing feature item 1299/12993...\n",
      "     - Processing feature item 2598/12993...\n",
      "     - Processing feature item 2598/12993...\n",
      "     - Processing feature item 3897/12993...\n",
      "     - Processing feature item 3897/12993...\n",
      "     - Processing feature item 5196/12993...\n",
      "     - Processing feature item 5196/12993...\n",
      "     - Processing feature item 6495/12993...\n",
      "     - Processing feature item 6495/12993...\n",
      "     - Processing feature item 7794/12993...\n",
      "     - Processing feature item 7794/12993...\n",
      "     - Processing feature item 9093/12993...\n",
      "     - Processing feature item 9093/12993...\n",
      "     - Processing feature item 10392/12993...\n",
      "     - Processing feature item 10392/12993...\n",
      "     - Processing feature item 11691/12993...\n",
      "     - Processing feature item 11691/12993...\n",
      "     - Processing feature item 12990/12993...\n",
      "     - Processing feature item 12993/12993...\n",
      "   âœ… Processed and saved 12993 items from features.\n",
      "ðŸ process() finished. Total items processed and saved in this run for feature mode: 12993\n",
      "   - Found 12993 existing processed files for feature mode.\n",
      "ðŸ GraphEEGDataset initialization complete. Current mode: FEATURE. Known processed items: 12993\n",
      "ðŸš€ Initializing GraphEEGDataset in FEATURE mode.\n",
      "   - Root: data/graph_dataset_train\n",
      "   - Mode: FEATURE\n",
      "   - Edge strategy: spatial\n",
      "   - Node Feature Normalization: True\n",
      "   - Loading spatial distances...\n",
      "     - Loaded 180 unique spatial distances relevant to defined channels.\n",
      "âš™ï¸ process() called for FEATURE mode. Target processed directory: data/graph_dataset_train/processed\n",
      "   - Starting processing from pre-extracted features...\n",
      "   - Total feature sets to process: 12993\n",
      "     - Processing feature item 12990/12993...\n",
      "     - Processing feature item 12993/12993...\n",
      "   âœ… Processed and saved 12993 items from features.\n",
      "ðŸ process() finished. Total items processed and saved in this run for feature mode: 12993\n",
      "   - Found 12993 existing processed files for feature mode.\n",
      "ðŸ GraphEEGDataset initialization complete. Current mode: FEATURE. Known processed items: 12993\n",
      "ðŸš€ Initializing GraphEEGDataset in FEATURE mode.\n",
      "   - Root: data/graph_dataset_train\n",
      "   - Mode: FEATURE\n",
      "   - Edge strategy: spatial\n",
      "   - Node Feature Normalization: True\n",
      "   - Loading spatial distances...\n",
      "     - Loaded 180 unique spatial distances relevant to defined channels.\n",
      "âš™ï¸ process() called for FEATURE mode. Target processed directory: data/graph_dataset_train/processed\n",
      "   - Starting processing from pre-extracted features...\n",
      "   - Total feature sets to process: 12993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Processing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     - Processing feature item 1299/12993...\n",
      "     - Processing feature item 2598/12993...\n",
      "     - Processing feature item 2598/12993...\n",
      "     - Processing feature item 3897/12993...\n",
      "     - Processing feature item 3897/12993...\n",
      "     - Processing feature item 5196/12993...\n",
      "     - Processing feature item 5196/12993...\n",
      "     - Processing feature item 6495/12993...\n",
      "     - Processing feature item 6495/12993...\n",
      "     - Processing feature item 7794/12993...\n",
      "     - Processing feature item 7794/12993...\n",
      "     - Processing feature item 9093/12993...\n",
      "     - Processing feature item 9093/12993...\n",
      "     - Processing feature item 10392/12993...\n",
      "     - Processing feature item 10392/12993...\n",
      "     - Processing feature item 11691/12993...\n",
      "     - Processing feature item 11691/12993...\n",
      "     - Processing feature item 12990/12993...\n",
      "     - Processing feature item 12993/12993...\n",
      "   âœ… Processed and saved 12993 items from features.\n",
      "ðŸ process() finished. Total items processed and saved in this run for feature mode: 12993\n",
      "   - Found 12993 existing processed files for feature mode.\n",
      "ðŸ GraphEEGDataset initialization complete. Current mode: FEATURE. Known processed items: 12993\n",
      "ðŸš€ Initializing GraphEEGDataset in FEATURE mode.\n",
      "   - Root: data/graph_dataset_test\n",
      "   - Mode: FEATURE\n",
      "   - Edge strategy: full\n",
      "   - Node Feature Normalization: True\n",
      "âš™ï¸ process() called for FEATURE mode. Target processed directory: data/graph_dataset_test/processed\n",
      "   - Starting processing from pre-extracted features...\n",
      "   - Total feature sets to process: 3614\n",
      "   âš ï¸ Warning: Labels for features will be None or use a default. 'label' column not in clips_df or length mismatch (3614 vs 3614).\n",
      "     - Processing feature item 361/3614...\n",
      "     - Processing feature item 12990/12993...\n",
      "     - Processing feature item 12993/12993...\n",
      "   âœ… Processed and saved 12993 items from features.\n",
      "ðŸ process() finished. Total items processed and saved in this run for feature mode: 12993\n",
      "   - Found 12993 existing processed files for feature mode.\n",
      "ðŸ GraphEEGDataset initialization complete. Current mode: FEATURE. Known processed items: 12993\n",
      "ðŸš€ Initializing GraphEEGDataset in FEATURE mode.\n",
      "   - Root: data/graph_dataset_test\n",
      "   - Mode: FEATURE\n",
      "   - Edge strategy: full\n",
      "   - Node Feature Normalization: True\n",
      "âš™ï¸ process() called for FEATURE mode. Target processed directory: data/graph_dataset_test/processed\n",
      "   - Starting processing from pre-extracted features...\n",
      "   - Total feature sets to process: 3614\n",
      "   âš ï¸ Warning: Labels for features will be None or use a default. 'label' column not in clips_df or length mismatch (3614 vs 3614).\n",
      "     - Processing feature item 361/3614...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Processing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     - Processing feature item 722/3614...\n",
      "     - Processing feature item 1083/3614...\n",
      "     - Processing feature item 1444/3614...\n",
      "     - Processing feature item 1805/3614...\n",
      "     - Processing feature item 1444/3614...\n",
      "     - Processing feature item 1805/3614...\n",
      "     - Processing feature item 2166/3614...\n",
      "     - Processing feature item 2527/3614...\n",
      "     - Processing feature item 2166/3614...\n",
      "     - Processing feature item 2527/3614...\n",
      "     - Processing feature item 2888/3614...\n",
      "     - Processing feature item 3249/3614...\n",
      "     - Processing feature item 2888/3614...\n",
      "     - Processing feature item 3249/3614...\n",
      "     - Processing feature item 3610/3614...\n",
      "     - Processing feature item 3614/3614...\n",
      "   âœ… Processed and saved 3614 items from features.\n",
      "ðŸ process() finished. Total items processed and saved in this run for feature mode: 3614\n",
      "   - Found 3614 existing processed files for feature mode.\n",
      "ðŸ GraphEEGDataset initialization complete. Current mode: FEATURE. Known processed items: 3614\n",
      "ðŸš€ Initializing GraphEEGDataset in FEATURE mode.\n",
      "   - Root: data/graph_dataset_test\n",
      "   - Mode: FEATURE\n",
      "   - Edge strategy: spatial\n",
      "   - Node Feature Normalization: True\n",
      "   - Loading spatial distances...\n",
      "     - Loaded 180 unique spatial distances relevant to defined channels.\n",
      "âš™ï¸ process() called for FEATURE mode. Target processed directory: data/graph_dataset_test/processed\n",
      "   - Starting processing from pre-extracted features...\n",
      "   - Total feature sets to process: 3614\n",
      "   âš ï¸ Warning: Labels for features will be None or use a default. 'label' column not in clips_df or length mismatch (3614 vs 3614).\n",
      "     - Processing feature item 361/3614...\n",
      "     - Processing feature item 3610/3614...\n",
      "     - Processing feature item 3614/3614...\n",
      "   âœ… Processed and saved 3614 items from features.\n",
      "ðŸ process() finished. Total items processed and saved in this run for feature mode: 3614\n",
      "   - Found 3614 existing processed files for feature mode.\n",
      "ðŸ GraphEEGDataset initialization complete. Current mode: FEATURE. Known processed items: 3614\n",
      "ðŸš€ Initializing GraphEEGDataset in FEATURE mode.\n",
      "   - Root: data/graph_dataset_test\n",
      "   - Mode: FEATURE\n",
      "   - Edge strategy: spatial\n",
      "   - Node Feature Normalization: True\n",
      "   - Loading spatial distances...\n",
      "     - Loaded 180 unique spatial distances relevant to defined channels.\n",
      "âš™ï¸ process() called for FEATURE mode. Target processed directory: data/graph_dataset_test/processed\n",
      "   - Starting processing from pre-extracted features...\n",
      "   - Total feature sets to process: 3614\n",
      "   âš ï¸ Warning: Labels for features will be None or use a default. 'label' column not in clips_df or length mismatch (3614 vs 3614).\n",
      "     - Processing feature item 361/3614...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Processing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     - Processing feature item 722/3614...\n",
      "     - Processing feature item 1083/3614...\n",
      "     - Processing feature item 1444/3614...\n",
      "     - Processing feature item 1805/3614...\n",
      "     - Processing feature item 1444/3614...\n",
      "     - Processing feature item 1805/3614...\n",
      "     - Processing feature item 2166/3614...\n",
      "     - Processing feature item 2527/3614...\n",
      "     - Processing feature item 2166/3614...\n",
      "     - Processing feature item 2527/3614...\n",
      "     - Processing feature item 2888/3614...\n",
      "     - Processing feature item 3249/3614...\n",
      "     - Processing feature item 2888/3614...\n",
      "     - Processing feature item 3249/3614...\n",
      "     - Processing feature item 3610/3614...\n",
      "     - Processing feature item 3614/3614...\n",
      "   âœ… Processed and saved 3614 items from features.\n",
      "ðŸ process() finished. Total items processed and saved in this run for feature mode: 3614\n",
      "   - Found 3614 existing processed files for feature mode.\n",
      "ðŸ GraphEEGDataset initialization complete. Current mode: FEATURE. Known processed items: 3614\n",
      "ðŸš€ Initializing GraphEEGDataset in FEATURE mode.\n",
      "   - Root: data/graph_dataset_test\n",
      "   - Mode: FEATURE\n",
      "   - Edge strategy: correlation\n",
      "   - Node Feature Normalization: True\n",
      "âš™ï¸ process() called for FEATURE mode. Target processed directory: data/graph_dataset_test/processed\n",
      "   - Starting processing from pre-extracted features...\n",
      "   - Total feature sets to process: 3614\n",
      "   âš ï¸ Warning: Labels for features will be None or use a default. 'label' column not in clips_df or length mismatch (3614 vs 3614).\n",
      "     - Processing feature item 361/3614...\n",
      "     - Processing feature item 3610/3614...\n",
      "     - Processing feature item 3614/3614...\n",
      "   âœ… Processed and saved 3614 items from features.\n",
      "ðŸ process() finished. Total items processed and saved in this run for feature mode: 3614\n",
      "   - Found 3614 existing processed files for feature mode.\n",
      "ðŸ GraphEEGDataset initialization complete. Current mode: FEATURE. Known processed items: 3614\n",
      "ðŸš€ Initializing GraphEEGDataset in FEATURE mode.\n",
      "   - Root: data/graph_dataset_test\n",
      "   - Mode: FEATURE\n",
      "   - Edge strategy: correlation\n",
      "   - Node Feature Normalization: True\n",
      "âš™ï¸ process() called for FEATURE mode. Target processed directory: data/graph_dataset_test/processed\n",
      "   - Starting processing from pre-extracted features...\n",
      "   - Total feature sets to process: 3614\n",
      "   âš ï¸ Warning: Labels for features will be None or use a default. 'label' column not in clips_df or length mismatch (3614 vs 3614).\n",
      "     - Processing feature item 361/3614...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Processing...\n",
      "/Users/lucadibello/Developer/NeuroGraphNet/.venv/lib/python3.13/site-packages/numpy/lib/_function_base_impl.py:3045: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     - Processing feature item 722/3614...\n",
      "     - Processing feature item 1083/3614...\n",
      "     - Processing feature item 1444/3614...\n",
      "     - Processing feature item 1805/3614...\n",
      "     - Processing feature item 1444/3614...\n",
      "     - Processing feature item 1805/3614...\n",
      "     - Processing feature item 2166/3614...\n",
      "     - Processing feature item 2527/3614...\n",
      "     - Processing feature item 2166/3614...\n",
      "     - Processing feature item 2527/3614...\n",
      "     - Processing feature item 2888/3614...\n",
      "     - Processing feature item 3249/3614...\n",
      "     - Processing feature item 2888/3614...\n",
      "     - Processing feature item 3249/3614...\n",
      "     - Processing feature item 3610/3614...\n",
      "     - Processing feature item 3614/3614...\n",
      "   âœ… Processed and saved 3614 items from features.\n",
      "ðŸ process() finished. Total items processed and saved in this run for feature mode: 3614\n",
      "   - Found 3614 existing processed files for feature mode.\n",
      "ðŸ GraphEEGDataset initialization complete. Current mode: FEATURE. Known processed items: 3614\n",
      "Graph training datasets created:\n",
      "  full: GraphEEGDataset(12993) (length: 12993)\n",
      "     INFO: Attempting torch.load with weights_only=False for data/graph_dataset_train/processed/data_feat_0.pt\n",
      "    First training sample: Data(x=[19, 12], edge_index=[2, 342], y=[1], original_idx=[1])\n",
      "  spatial: GraphEEGDataset(12993) (length: 12993)\n",
      "     INFO: Attempting torch.load with weights_only=False for data/graph_dataset_train/processed/data_feat_0.pt\n",
      "    First training sample: Data(x=[19, 12], edge_index=[2, 342], y=[1], original_idx=[1])\n",
      "  correlation: GraphEEGDataset(12993) (length: 12993)\n",
      "     INFO: Attempting torch.load with weights_only=False for data/graph_dataset_train/processed/data_feat_0.pt\n",
      "    First training sample: Data(x=[19, 12], edge_index=[2, 342], y=[1], original_idx=[1])\n",
      "\n",
      "Graph test datasets created:\n",
      "  full: GraphEEGDataset(3614) (length: 3614)\n",
      "     INFO: Attempting torch.load with weights_only=False for data/graph_dataset_test/processed/data_feat_0.pt\n",
      "    First test sample: Data(x=[19, 12], edge_index=[2, 342], original_idx=[1]), Label (y): None\n",
      "  spatial: GraphEEGDataset(3614) (length: 3614)\n",
      "     INFO: Attempting torch.load with weights_only=False for data/graph_dataset_test/processed/data_feat_0.pt\n",
      "    First test sample: Data(x=[19, 12], edge_index=[2, 342], original_idx=[1]), Label (y): None\n",
      "  correlation: GraphEEGDataset(3614) (length: 3614)\n",
      "     INFO: Attempting torch.load with weights_only=False for data/graph_dataset_test/processed/data_feat_0.pt\n",
      "    First test sample: Data(x=[19, 12], edge_index=[2, 342], original_idx=[1]), Label (y): None\n",
      "     - Processing feature item 3610/3614...\n",
      "     - Processing feature item 3614/3614...\n",
      "   âœ… Processed and saved 3614 items from features.\n",
      "ðŸ process() finished. Total items processed and saved in this run for feature mode: 3614\n",
      "   - Found 3614 existing processed files for feature mode.\n",
      "ðŸ GraphEEGDataset initialization complete. Current mode: FEATURE. Known processed items: 3614\n",
      "Graph training datasets created:\n",
      "  full: GraphEEGDataset(12993) (length: 12993)\n",
      "     INFO: Attempting torch.load with weights_only=False for data/graph_dataset_train/processed/data_feat_0.pt\n",
      "    First training sample: Data(x=[19, 12], edge_index=[2, 342], y=[1], original_idx=[1])\n",
      "  spatial: GraphEEGDataset(12993) (length: 12993)\n",
      "     INFO: Attempting torch.load with weights_only=False for data/graph_dataset_train/processed/data_feat_0.pt\n",
      "    First training sample: Data(x=[19, 12], edge_index=[2, 342], y=[1], original_idx=[1])\n",
      "  correlation: GraphEEGDataset(12993) (length: 12993)\n",
      "     INFO: Attempting torch.load with weights_only=False for data/graph_dataset_train/processed/data_feat_0.pt\n",
      "    First training sample: Data(x=[19, 12], edge_index=[2, 342], y=[1], original_idx=[1])\n",
      "\n",
      "Graph test datasets created:\n",
      "  full: GraphEEGDataset(3614) (length: 3614)\n",
      "     INFO: Attempting torch.load with weights_only=False for data/graph_dataset_test/processed/data_feat_0.pt\n",
      "    First test sample: Data(x=[19, 12], edge_index=[2, 342], original_idx=[1]), Label (y): None\n",
      "  spatial: GraphEEGDataset(3614) (length: 3614)\n",
      "     INFO: Attempting torch.load with weights_only=False for data/graph_dataset_test/processed/data_feat_0.pt\n",
      "    First test sample: Data(x=[19, 12], edge_index=[2, 342], original_idx=[1]), Label (y): None\n",
      "  correlation: GraphEEGDataset(3614) (length: 3614)\n",
      "     INFO: Attempting torch.load with weights_only=False for data/graph_dataset_test/processed/data_feat_0.pt\n",
      "    First test sample: Data(x=[19, 12], edge_index=[2, 342], original_idx=[1]), Label (y): None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from src.utils.graph_eeg_dataset import GraphEEGDataset\n",
    "\n",
    "LOCAL_DATA_ROOT = Path(\"./data\")\n",
    "\n",
    "graph_datasets_tr = {\n",
    "    'full': GraphEEGDataset(\n",
    "        root=str(LOCAL_DATA_ROOT / 'graph_dataset_train'),\n",
    "        clips_df=clips_tr,\n",
    "        signal_folder=str(DATA_ROOT / 'train'),\n",
    "        extracted_features_array=X_train,\n",
    "        use_extracted_features=True,\n",
    "        edge_strategy='full',\n",
    "        spatial_distance_file=str(LOCAL_DATA_ROOT / 'distances_3d.csv'),\n",
    "        force_reprocess=False,\n",
    "        prefetch_data=False,\n",
    "    ),\n",
    "    'spatial': GraphEEGDataset(\n",
    "        root=str(LOCAL_DATA_ROOT / 'graph_dataset_train'),\n",
    "        clips_df=clips_tr,\n",
    "        signal_folder=str(DATA_ROOT / 'train'),\n",
    "        extracted_features_array=X_train,\n",
    "        use_extracted_features=True,\n",
    "        edge_strategy='spatial',\n",
    "        spatial_distance_file=str(LOCAL_DATA_ROOT / 'distances_3d.csv'),\n",
    "        force_reprocess=False,\n",
    "        prefetch_data=False,\n",
    "    ),\n",
    "    'correlation': GraphEEGDataset(\n",
    "        root=str(LOCAL_DATA_ROOT / 'graph_dataset_train'),\n",
    "        clips_df=clips_tr,\n",
    "        signal_folder=str(DATA_ROOT / 'train'),\n",
    "        extracted_features_array=X_train,\n",
    "        use_extracted_features=True,\n",
    "        edge_strategy='spatial',\n",
    "        spatial_distance_file=str(LOCAL_DATA_ROOT / 'distances_3d.csv'),\n",
    "        force_reprocess=False,\n",
    "        prefetch_data=False,\n",
    "    ),\n",
    "}\n",
    "\n",
    "graph_datasets_te = {\n",
    "    'full': GraphEEGDataset(\n",
    "        root=str(LOCAL_DATA_ROOT / 'graph_dataset_test'),\n",
    "        clips_df=clips_te,\n",
    "        signal_folder=str(DATA_ROOT / 'test'),\n",
    "        extracted_features_array=X_test,\n",
    "        use_extracted_features=True,\n",
    "        edge_strategy='full',\n",
    "        spatial_distance_file=str(LOCAL_DATA_ROOT / 'distances_3d.csv'),\n",
    "        force_reprocess=False, # Force reprocess for test dataset\n",
    "        prefetch_data=False,\n",
    "    ),\n",
    "    'spatial': GraphEEGDataset(\n",
    "        root=str(LOCAL_DATA_ROOT / 'graph_dataset_test'),\n",
    "        clips_df=clips_te,\n",
    "        signal_folder=str(DATA_ROOT / 'test'),\n",
    "        extracted_features_array=X_test,\n",
    "        use_extracted_features=True,\n",
    "        edge_strategy='spatial',\n",
    "        spatial_distance_file=str(LOCAL_DATA_ROOT / 'distances_3d.csv'),\n",
    "        force_reprocess=False, # Force reprocess for test dataset\n",
    "        prefetch_data=False,\n",
    "    ),\n",
    "    'correlation': GraphEEGDataset(\n",
    "        root=str(LOCAL_DATA_ROOT / 'graph_dataset_test'),\n",
    "        clips_df=clips_te,\n",
    "        signal_folder=str(DATA_ROOT / 'test'),\n",
    "        extracted_features_array=X_test,\n",
    "        use_extracted_features=True,\n",
    "        edge_strategy='correlation',\n",
    "        spatial_distance_file=str(LOCAL_DATA_ROOT / 'distances_3d.csv'),\n",
    "        force_reprocess=False, # Force reprocess for test dataset\n",
    "        prefetch_data=False,\n",
    "    )\n",
    "}\n",
    "\n",
    "print(\"Graph training datasets created:\")\n",
    "for key, ds in graph_datasets_tr.items():\n",
    "    print(f\"  {key}: {ds} (length: {len(ds)})\")\n",
    "    if len(ds) > 0:\n",
    "        sample = ds[0]\n",
    "        print(f\"    First training sample: {sample}\")\n",
    "\n",
    "print(\"\\nGraph test datasets created:\")\n",
    "for key, ds in graph_datasets_te.items():\n",
    "    print(f\"  {key}: {ds} (length: {len(ds)})\")\n",
    "    if len(ds) > 0:\n",
    "        sample = ds[0]\n",
    "        print(f\"    First test sample: {sample}, Label (y): {getattr(sample, 'y', None)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'full': GraphEEGDataset(12993), 'spatial': GraphEEGDataset(12993), 'correlation': GraphEEGDataset(12993)}\n",
      "{'full': GraphEEGDataset(3614), 'spatial': GraphEEGDataset(3614), 'correlation': GraphEEGDataset(3614)}\n"
     ]
    }
   ],
   "source": [
    "print(graph_datasets_tr)\n",
    "print(graph_datasets_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full: Train size = 10394, Val size = 2599\n",
      "spatial: Train size = 10394, Val size = 2599\n",
      "correlation: Train size = 10394, Val size = 2599\n",
      "{'full': <torch.utils.data.dataset.Subset object at 0x10689ae40>, 'spatial': <torch.utils.data.dataset.Subset object at 0x30cf387d0>, 'correlation': <torch.utils.data.dataset.Subset object at 0x30c3bbe10>}\n",
      "{'full': <torch.utils.data.dataset.Subset object at 0x30cf38410>, 'spatial': <torch.utils.data.dataset.Subset object at 0x30c3bb820>, 'correlation': <torch.utils.data.dataset.Subset object at 0x30a74b770>}\n",
      "{'full': GraphEEGDataset(3614), 'spatial': GraphEEGDataset(3614), 'correlation': GraphEEGDataset(3614)}\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "# split training dataset into train/val sets if not already done\n",
    "if not 'graph_datasets_val' in locals():\n",
    "    TRAIN_RATIO = 0.8\n",
    "    TRAIN_SIZE = int(len(graph_datasets_tr[\"full\"]) * TRAIN_RATIO)\n",
    "    VAL_SIZE = len(graph_datasets_tr[\"full\"]) - TRAIN_SIZE\n",
    "\n",
    "    # Store original datasets before reassigning\n",
    "    original_graph_datasets_tr = graph_datasets_tr\n",
    "    \n",
    "    # Split each training graph dataset into train/val\n",
    "    graph_datasets_tr = {}\n",
    "    graph_datasets_val = {}\n",
    "    for key, ds in original_graph_datasets_tr.items():\n",
    "        tr, val = random_split(ds, [TRAIN_SIZE, VAL_SIZE], generator=torch.Generator().manual_seed(RANDOM_SEED))\n",
    "        graph_datasets_tr[key] = tr\n",
    "        graph_datasets_val[key] = val\n",
    "        print(f\"{key}: Train size = {len(tr)}, Val size = {len(val)}\")\n",
    "assert 'graph_datasets_tr' in locals(), \"Training datasets not created\"\n",
    "\n",
    "print(graph_datasets_tr)\n",
    "print(graph_datasets_val)\n",
    "print(graph_datasets_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â€”â€”â€” create data loaders â€”â€”â€”\n",
    "print(\"â³ Creating DataLoadersâ€¦\")\n",
    "dl_start = time.time()\n",
    "# Create DataLoaders for each graph dataset kind\n",
    "common_loader_kwargs = dict(\n",
    "    batch_size=512,\n",
    "    num_workers=16,\n",
    "    persistent_workers=True,\n",
    "    pin_memory=True,\n",
    "    prefetch_factor=8,\n",
    ")\n",
    "\n",
    "train_loader = {}\n",
    "val_loader = {}\n",
    "test_loader = {}\n",
    "\n",
    "for kind in graph_datasets_tr.keys():\n",
    "    train_loader[kind] = GeoDataLoader(graph_datasets_tr[kind], shuffle=True,  **common_loader_kwargs) # type: ignore\n",
    "    val_loader[kind]   = GeoDataLoader(graph_datasets_val[kind], shuffle=False, **common_loader_kwargs) # type: ignore\n",
    "    test_loader[kind]  = GeoDataLoader(graph_datasets_te[kind], shuffle=False, **common_loader_kwargs) # type: ignore\n",
    "    print(f\"  {kind}: Train loader size = {len(train_loader[kind])}, \"\n",
    "            f\"Val loader size = {len(val_loader[kind])}, \"\n",
    "            f\"Test loader size = {len(test_loader[kind])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traditional approaches (no additional features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%aimport src.utils.train\n",
    "from src.utils.train import train_model, evaluate_model\n",
    "from src.utils.plot import plot_training_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. LSTM classifier (baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%aimport src.layers.lstm\n",
    "from src.layers.lstm import LSTM\n",
    "\n",
    "LSTM_SAVE_PATH = CHECKPOINT_ROOT / \"lstm_best_model.pt\"\n",
    "LSTM_SUBMISSION_PATH = SUBMISSION_ROOT / \"lstm_submission.csv\"\n",
    "\n",
    "# build model with current parameters\n",
    "lstm_model = LSTM(input_dim=12,\n",
    "                hidden_dim=64,\n",
    "                num_layers=4,\n",
    "                dropout=0.1)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"Using {torch.cuda.device_count()} GPUs for this combination.\")\n",
    "    lstm_model = nn.DataParallel(lstm_model)\n",
    "lstm_model = lstm_model.to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()  # Assuming this remains constant\n",
    "optimizer = optim.Adam(lstm_model.parameters(), lr=3e-4)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=5, factor=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_SAVE_PATH = CHECKPOINT_ROOT / \"lstm_best_model.pt\"\n",
    "LSTM_SUBMISSION_PATH = SUBMISSION_ROOT / \"lstm_submission.csv\"\n",
    "\n",
    "# train model on training set (or load existing)\n",
    "train_history, val_history = train_model(\n",
    "        lstm_model, train_loader, val_loader,\n",
    "        criterion, optimizer, device,\n",
    "        save_path=LSTM_SAVE_PATH,\n",
    "        num_epochs=300,\n",
    "        patience=10,\n",
    "        monitor=\"val_loss\",\n",
    "        scheduler=scheduler,\n",
    "        overwrite=True,\n",
    "        use_gnn=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_loss(train_history[\"loss\"], val_history[\"loss\"], \"LSTM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Bidirectional LSTM with early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.layers.lstm import BiLSTM\n",
    "\n",
    "# Create model and fit it\n",
    "bi_lstm_model = BiLSTM(input_dim=19, hidden_dim=64, num_layers=3, dropout=0.2)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"Using {torch.cuda.device_count()} GPUs\")\n",
    "    bi_lstm_model = nn.DataParallel(bi_lstm_model)   # splits batches across all GPUs\n",
    "bi_lstm_model = bi_lstm_model.to(device)         # CPU or GPU\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(bi_lstm_model.parameters(), lr=1e-3)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, factor=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BI_LSTM_SAVE_PATH = CHECKPOINT_ROOT / \"bi_lstm_best_model.pt\"\n",
    "BI_LSTM_SUBMISSION_PATH = SUBMISSION_ROOT / \"bi_lstm_submission.csv\"\n",
    "\n",
    "# train model on training set (or load existing)\n",
    "train_history, val_history = train_model(\n",
    "        bi_lstm_model, train_loader, val_loader,\n",
    "        criterion, optimizer, device,\n",
    "        save_path=BI_LSTM_SAVE_PATH,\n",
    "        num_epochs=300,\n",
    "        patience=10,\n",
    "        monitor=\"val_loss\",\n",
    "        scheduler=scheduler,\n",
    "        overwrite=True,\n",
    "        use_gnn=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_loss(train_history[\"loss\"], val_history[\"loss\"], \"BiLSTM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model on test set and generate submission file\n",
    "evaluate_model(\n",
    "    bi_lstm_model, test_loader, device,\n",
    "    save_path=BI_LSTM_SAVE_PATH,\n",
    "    submission_path=BI_LSTM_SUBMISSION_PATH,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. LSTM with Attention and early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.layers.lstm import LSTMAttention\n",
    "\n",
    "# Create model and fit it\n",
    "attention_lstm_model = LSTMAttention(input_dim=19, hidden_dim=64, num_layers=3, dropout=0.2)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"Using {torch.cuda.device_count()} GPUs\")\n",
    "    attention_lstm_model = nn.DataParallel(attention_lstm_model)   # splits batches across all GPUs\n",
    "attention_lstm_model = attention_lstm_model.to(device)         # CPU or GPU\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(\n",
    "    attention_lstm_model.parameters(),\n",
    "    lr=1e-3,\n",
    "    weight_decay=1e-5\n",
    ")\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min',\n",
    "    patience=5,\n",
    "    factor=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ATTENTION_LSTM_SAVE_PATH = CHECKPOINT_ROOT / \"attention_lstm_best_model.pt\"\n",
    "ATTENTION_LSTM_SUBMISSION_PATH = SUBMISSION_ROOT / \"attention_lstm_submission.csv\"\n",
    "\n",
    "# train model on training set (or load existing)\n",
    "train_history, val_history = train_model(\n",
    "        attention_lstm_model, train_loader, val_loader,\n",
    "        criterion, optimizer, device,\n",
    "        save_path=ATTENTION_LSTM_SAVE_PATH,\n",
    "        num_epochs=300,\n",
    "        patience=10,\n",
    "        monitor=\"val_loss\",\n",
    "        scheduler=scheduler,\n",
    "        overwrite=False,\n",
    "        use_gnn=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_loss(train_history[\"loss\"], val_history[\"loss\"], \"LSTM with Attention\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model on test set and generate submission file\n",
    "evaluate_model(\n",
    "    attention_lstm_model, test_loader, device,\n",
    "    checkpoint_path=ATTENTION_LSTM_SAVE_PATH,\n",
    "    submission_path=ATTENTION_LSTM_SUBMISSION_PATH,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. EEG CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%aimport src.layers.cnn\n",
    "from src.layers.cnn import EEG_CNN\n",
    "\n",
    "eeg_cnn_model = EEG_CNN(\n",
    "    input_channels=19,\n",
    "    dropout=0.3\n",
    ")\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"Using {torch.cuda.device_count()} GPUs\")\n",
    "    eeg_cnn_model = nn.DataParallel(eeg_cnn_model)\n",
    "eeg_cnn_model = eeg_cnn_model.to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(eeg_cnn_model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min',\n",
    "    patience=5,\n",
    "    factor=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EEG_CNN_SAVE_PATH = CHECKPOINT_ROOT / \"eeg_cnn_best_model.pt\"\n",
    "EEG_CNN_SUBMISSION_PATH = SUBMISSION_ROOT / \"eeg_cnn_submission.csv\"\n",
    "\n",
    "# train model on training set (or load existing)\n",
    "train_history, val_history = train_model(\n",
    "        eeg_cnn_model, train_loader, val_loader,\n",
    "        criterion, optimizer, device,\n",
    "        save_path=EEG_CNN_SUBMISSION_PATH,\n",
    "        num_epochs=300,\n",
    "        patience=10,\n",
    "        monitor=\"val_loss\",\n",
    "        scheduler=scheduler,\n",
    "        overwrite=True,\n",
    "        use_gnn=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_loss(train_history[\"loss\"], val_history[\"loss\"], \"EEG CNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%aimport src.utils.train\n",
    "from src.utils.train import evaluate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model on test set and generate submission file\n",
    "evaluate_model(\n",
    "    eeg_cnn_model, test_loader, device,\n",
    "    checkpoint_path=EEG_CNN_SAVE_PATH,\n",
    "    submission_path=EEG_CNN_SUBMISSION_PATH\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. EEG CNN LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%aimport src.layers.cnn\n",
    "from src.layers.cnn import EEG_CNN_LSTM\n",
    "\n",
    "cnn_lstm_model = EEG_CNN_LSTM(\n",
    "    input_channels=19,\n",
    "    cnn_output_channels=128,\n",
    "    lstm_hidden_dim=128, \n",
    "    fc_dropout=0.3,\n",
    "    lstm_dropout=0.3,\n",
    "    num_classes=1,\n",
    "    bidirectional_lstm=False # unidirectional\n",
    ")\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"Using {torch.cuda.device_count()} GPUs\")\n",
    "    cnn_lstm_model = nn.DataParallel(cnn_lstm_model)\n",
    "cnn_lstm_model = cnn_lstm_model.to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(cnn_lstm_model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min',\n",
    "    patience=5,\n",
    "    factor=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_LSTM_SAVE_PATH = CHECKPOINT_ROOT / \"cnn_lstm_best_model.pt\"\n",
    "CNN_LSTM_SUBMISSION_PATH = SUBMISSION_ROOT / \"cnn_lstm_submission.csv\"\n",
    "\n",
    "# train model on training set (or load existing)\n",
    "train_history, val_history = train_model(\n",
    "        cnn_lstm_model, train_loader, val_loader,\n",
    "        criterion, optimizer, device,\n",
    "        save_path=CNN_LSTM_SAVE_PATH,\n",
    "        num_epochs=300,\n",
    "        patience=30,\n",
    "        monitor=\"val_loss\",\n",
    "        scheduler=scheduler,\n",
    "        overwrite=True,\n",
    "        use_gnn=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_loss(train_history[\"loss\"], val_history[\"loss\"], \"EEG CNN + LSTM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model on test set and generate submission file\n",
    "evaluate_model(\n",
    "    cnn_lstm_model, test_loader, device,\n",
    "    save_path=CNN_LSTM_SAVE_PATH,\n",
    "    submission_path=CNN_LSTM_SUBMISSION_PATH\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. EEG CNN BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%aimport layers.cnn\n",
    "from layers.cnn import EEG_CNN_LSTM\n",
    "\n",
    "cnn_bi_lstm_model = EEG_CNN_LSTM(\n",
    "    input_channels=19,\n",
    "    cnn_output_channels=128,\n",
    "    lstm_hidden_dim=128, \n",
    "    fc_dropout=0.3,\n",
    "    lstm_dropout=0.3,\n",
    "    num_classes=1,\n",
    "    bidirectional_lstm=True\n",
    ")\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"Using {torch.cuda.device_count()} GPUs\")\n",
    "    cnn_bi_lstm_model = nn.DataParallel(cnn_bi_lstm_model)\n",
    "cnn_bi_lstm_model = cnn_bi_lstm_model.to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(cnn_bi_lstm_model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min',\n",
    "    patience=5,\n",
    "    factor=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_BI_LSTM_SAVE_PATH = CHECKPOINT_ROOT / \"cnn_bi_lstm_best_model.pt\"\n",
    "CNN_BI_LSTM_SUBMISSION_PATH = SUBMISSION_ROOT / \"cnn_bi_lstm_submission.csv\"\n",
    "\n",
    "# train model on training set (or load existing)\n",
    "train_history, val_history = train_model(\n",
    "    cnn_bi_lstm_model, train_loader, val_loader,\n",
    "    criterion, optimizer, device,\n",
    "    save_path=CNN_BI_LSTM_SAVE_PATH,\n",
    "    num_epochs=300,\n",
    "    patience=30,\n",
    "    monitor=\"val_loss\",\n",
    "    scheduler=scheduler,\n",
    "    overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_loss(train_history[\"loss\"], val_history[\"loss\"], \"EEG CNN + BiLSTM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model on test set and generate submission file\n",
    "evaluate_model(\n",
    "    cnn_bi_lstm_model, test_loader, device,\n",
    "    save_path=CNN_BI_LSTM_SAVE_PATH,\n",
    "    submission_path=CNN_BI_LSTM_SUBMISSION_PATH\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from layers.eeggcn import EEGGCN\n",
    "\n",
    "# Get number of time points (in_channels) from first sample\n",
    "eeg_gnc_model = EEGGCN(\n",
    "    in_channels=19,\n",
    "    hidden_channels=128,\n",
    "    out_channels=32,\n",
    "    num_classes=2,\n",
    "    num_conv_layers=3,\n",
    "    dropout=0.5\n",
    ")\n",
    "if torch.cuda.device_count() > 1:\n",
    "    eeg_gnc_model = nn.DataParallel(eeg_gnc_model)\n",
    "eeg_gnc_model = eeg_gnc_model.to(device)\n",
    "\n",
    "# Set up optimizer + scheduler\n",
    "optimizer = optim.Adam(eeg_gnc_model.parameters(), lr=0.001, weight_decay=5e-4)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.5, patience=5, verbose=True\n",
    ")\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "EEGGCN_SAVE_PATH = CHECKPOINT_ROOT / \"eeggcn_best_model.pt\"\n",
    "EEGCN_SUBMISSION_PATH = SUBMISSION_ROOT / \"eeggcn_submission.csv\"\n",
    "\n",
    "# train model on training set (or load existing)\n",
    "train_history, val_history = train_model(\n",
    "    eeg_gnc_model, train_loader, val_loader,\n",
    "    criterion, optimizer, device,\n",
    "    save_path=EEGGCN_SAVE_PATH,\n",
    "    num_epochs=300,\n",
    "    patience=30,\n",
    "    monitor=\"val_loss\",\n",
    "    scheduler=scheduler,\n",
    "    overwrite=True,\n",
    ")\n",
    "\n",
    "# plot losses if any\n",
    "plt.figure()\n",
    "plt.plot(train_history[\"loss\"], label=\"train\")\n",
    "plt.plot(val_history[\"loss\"],   label=\"val\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(\n",
    "    eeg_gnc_model, test_loader, device,\n",
    "    save_path       = Path(\"eeggcn_attn.pt\"),\n",
    "    submission_path = Path(\"eeggcn_submission.csv\"),\n",
    "    threshold       = 0.5,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
